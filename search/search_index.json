{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"SLKB Pipeline SLKB: Synthetic lethality knowledge base for gene combination double knockout experiments Synthetic lethality knowledge base (SLKB) is dedicated to curating CRISPR dual knockdown/out experiments (CDKO) aimed to identify synthetic lethal (SL) interactions between two genes. SLKB pipeline supports the following functions: 1) Storing user CDKO experiments under a generalized experimental design 2) Implementing and evaluating different SL scoring methods 3) Enabling data visualization and browsing 4) Support for SL target identification Following SLKB pipeline, yielding results can be loaded within SLKB web app for full experience. Using SLKB Users can get started through the shared jupyter notebook file . Pipeline with it's full details can be browsed within the documentation . Database Schema Accessible Tables The schema has the following tables for access: cdko_experiment_design cdko_original_sl_results cdko_sgrna_counts horlbeck_score median_b_score median_nb_score sgrna_derived_b_score sgrna_derived_nb_score gemini_score mageck_score Additionally, two views are available: joined_counts: Join of counts table with experiment_design table calculated_sl_table: Join of all scoring tables and gene pair information Calculated Scores Table Interactive Website Located under the pipeline subdirectory.","title":"SLKB Pipeline"},{"location":"index.html#slkb-pipeline","text":"","title":"SLKB Pipeline"},{"location":"index.html#slkb-synthetic-lethality-knowledge-base-for-gene-combination-double-knockout-experiments","text":"Synthetic lethality knowledge base (SLKB) is dedicated to curating CRISPR dual knockdown/out experiments (CDKO) aimed to identify synthetic lethal (SL) interactions between two genes. SLKB pipeline supports the following functions: 1) Storing user CDKO experiments under a generalized experimental design 2) Implementing and evaluating different SL scoring methods 3) Enabling data visualization and browsing 4) Support for SL target identification Following SLKB pipeline, yielding results can be loaded within SLKB web app for full experience.","title":"SLKB: Synthetic lethality knowledge base for gene combination double knockout experiments"},{"location":"index.html#using-slkb","text":"Users can get started through the shared jupyter notebook file . Pipeline with it's full details can be browsed within the documentation .","title":"Using SLKB"},{"location":"index.html#database-schema","text":"","title":"Database Schema"},{"location":"index.html#accessible-tables","text":"The schema has the following tables for access: cdko_experiment_design cdko_original_sl_results cdko_sgrna_counts horlbeck_score median_b_score median_nb_score sgrna_derived_b_score sgrna_derived_nb_score gemini_score mageck_score Additionally, two views are available: joined_counts: Join of counts table with experiment_design table calculated_sl_table: Join of all scoring tables and gene pair information","title":"Accessible Tables"},{"location":"index.html#calculated-scores-table","text":"","title":"Calculated Scores Table"},{"location":"index.html#interactive-website","text":"Located under the pipeline subdirectory.","title":"Interactive Website"},{"location":"API.html","text":"API File Formats A demo data is available for loading. Additional details can be found in the pipeline . demo_data = SLKB.load_demo_data() Params : None. Returns : demo_data. A list of 3 items: sequence file, counts, fle, and score file. Functions For Data Insertion to KB generate_database Creates a sqlite3 or mysql database, using SLKB schema. SLKB.create_SLKB(engine = 'sqlite:///SLKB_sqlite3', db_type = 'sqlite3') Params : engine: sqlalchemy url object. (Default: sqlite:///SLKB_sqlite3) db_type: Type of database to use schema for, currently available in mysql and sqlite3. (Default: sqlite3) Returns : None. extract_SLKB_webapp Extracts the SLKB webapp to the specified location. SLKB.extract_SLKB_webapp(location = os.getcwd()) Params : location: Location to extract SLKB files. (Default: Current working directory) Returns : None. prepare_study_for_export Prepares the counts, scores, and sequences files for insertion into the DB. db_inserts = SLKB.prepare_study_for_export(score_ref, sequence_ref = None, counts_ref = None, study_controls = None, study_conditions = None, can_control_be_substring = True, remove_unrelated_counts = False) Params : score_ref: A pandas table that adheres to the scores table template. sequence_ref: A pandas table that adheres to the sequence table template (default: None). counts_ref: A pandas table that adheres to the counts table template (default: None). study_controls: A list of control targets of the sgRNAs (default: None). study_conditions: A list of two lists; first list contains the replicate names of initial time point, and second list contains the same for final time point (default: None). can_control_be_substring: Can the controls be a substring of gene targets (in case of possible name conventions: default: True) remove_unrelated_counts = Remove dual counts with targets that are outside of supplied scores targets? (default: False) Returns : A dictionary of three items: scores_ref: Contains the procesed scores table (if supplied) sequences_ref: Contains the procesed sequences table (if supplied) counts_ref: Contains the procesed counts table (if supplied) insert_study_to_db Inserts the counts to the designated DB. SLKB.insert_study_to_db(SLKB_engine, db_inserts) Params : SLKB_engine: SQLAlchemy engine link db_inserts: Processed data, obtained via prepare_study_for_export Returns : None Scoring Functions Median-B/NB Score Calculates Median B/NB Scores. median_res = SLKB.run_median_scores(curr_counts, curr_study, curr_cl, full_normalization = False, re_run = False, store_loc = os.getcwd(), save_dir = 'MEDIAN_Files') Params : curr_counts: Counts to calculate scores to.) curr_study: String, name of study to analyze data for. curr_cl: String, name of cell line to analyze data for. full_normalization: Whether to normalize counts across the whole sample or according to target type (Default: False) re_run: Boolean. Recreate and rerun the results instead of loading for subsequent analyses (Default: False) store_loc: String: Directory to store the MAGeCK files to. (Default: current working directory) save_dir: String: Folder name to store the MAGeCK files to. (Default: 'MEDIAN_Files') Returns : median_res: A dictionary of two pandas dataframes: Median-B and Median-NB. sgRNA-Derived-B/NB Score Calculates sgRNA Derived N/NB scores. sgRNA_res = SLKB.run_sgrna_scores(curr_counts, curr_study, curr_cl, full_normalization = False, re_run = False, store_loc = os.getcwd(), save_dir = 'sgRNA-DERIVED_Files') Params : curr_counts: Counts to calculate scores to.) curr_study: String, name of study to analyze data for. curr_cl: String, name of cell line to analyze data for. full_normalization: Whether to normalize counts across the whole sample or according to target type (Default: False) re_run: Boolean. Recreate and rerun the results instead of loading for subsequent analyses (Default: False) store_loc: String: Directory to store the MAGeCK files to. (Default: current working directory) save_dir: String: Folder name to store the MAGeCK files to. (Default: 'sgRNA-DERIVED_Files') Returns : sgRNA_res: A dictionary of two pandas dataframes: sgRNA_derived_B and sgRNA_derived_NB. MAGeCK Score Calculates MAGeCK Score. Score files will created at the designated store location and save directory. mageck_res = SLKB.run_mageck_score(curr_counts.copy(), curr_study, curr_cl, store_loc = os.getcwd(), save_dir = 'MAGECK_Files', command_line_params = [],re_run = False) Params : * curr_counts: Counts to calculate scores to.) * curr_study: String, name of study to analyze data for. * curr_cl: String, name of cell line to analyze data for. * store_loc: String: Directory to store the MAGeCK files to. (Default: current working directory) * save_dir: String: Folder name to store the MAGeCK files to. (Default: 'MAGECK_Files') * command_line_params: Optional list to load programming environment(s) to be able to run mageck tool (i.e. loading path, activating python environment). * re_run: Boolean. Recreate and rerun the results instead of loading for subsequent analyses (Default: False) Returns : mageck_res: A dict that contains a pandas dataframe for MAGeCK Score. Horlbeck Score Calculates Horlbeck score. Score files will created at the designated store location and save directory. horlbeck_res = SLKB.run_horlbeck_score(curr_counts.copy(), curr_study = curr_study, curr_cl = curr_cl, store_loc = os.getcwd(), save_dir = 'HORLBECK_Files', do_preprocessing = True, re_run = False) Params : * curr_counts: Counts to calculate scores to.) * curr_study: String, name of study to analyze data for. * curr_cl: String, name of cell line to analyze data for. * store_loc: String: Directory to store the MAGeCK files to. (Default: current working directory) * save_dir: String: Folder name to store the MAGeCK files to. (Default: 'Horlbeck_Files') * do_preprocessing: Boolean. Run Horlbeck preprocessing (Default: True) * re_run: Boolean. Recreate and rerun the results instead of loading for subsequent analyses (Default: False) Returns : horlbeck_res: A dict that contains a pandas dataframe for Horlbeck Score. GEMINI Score Calculates GEMINI Score. Score files will created at the designated store location and save directory. gemini_res = run_gemini_score(curr_counts.copy(), curr_study = curr_study, curr_cl = curr_cl, store_loc = os.getcwd(), save_dir = 'GEMINI_Files', command_line_params = cmd_params, re_run = False) Params : * curr_counts: Counts to calculate scores to.) * curr_study: String, name of study to analyze data for. * curr_cl: String, name of cell line to analyze data for. * store_loc: String: Directory to store the MAGeCK files to. (Default: current working directory) * save_dir: String: Folder name to store the MAGeCK files to. (Default: 'GEMINI_Files') * command_line_params: Optional list to load programming environment(s) to be able to run GEMINI through R (i.e. loading path, activating R environment). * re_run: Boolean. Recreate and rerun the results instead of loading for subsequent analyses (Default: False) Returns : gemini_res: A dict that contains a pandas dataframe for GEMINI Score. check_if_added_to_table If running the scoring methods multiple times, the method may be useful in skipping over the computation if there are gene pair records already in the database. SLKB.check_if_added_to_table(curr_counts, score_name, SLKB_engine) Params : curr_counts: Counts to calculate the scores to. score_name: Table to insert the scores to. Must be any of the 7 scoring table names: HORLBECK_SCORE MEDIAN_B_SCORE MEDIAN_NB_SCORE GEMINI_SCORE MAGECK_SCORE SGRNA_DERIVED_B_SCORE SGRNA_DERIVED_NB_SCORE Returns : Boolean. True if records are inserted into the DB, False otherwise. query_results_table Obtain SL Scores from the specified scoring table. result = SLKB.query_result_table(curr_counts, table_name, curr_study, curr_cl, engine_link) Params : curr_counts: Counts to obtain the scores from. table_name: Must be any of the 7 scoring table names: horlbeck_score median_b_score median_nb_score sgrna_derived_b_score sgrna_derived_nb_score gemini_score mageck_score curr_study: String, name of the study to obtain the results for. curr_cl: String, name of the cell line to obtain the results for. engine_link: SQLAlchemy connection for the database. Returns : result: A pandas dataframe of the inserted results. Includes annotations for gene pair, study origin, and cell line origin. \u00a9 Copyright 2023, The Ohio State University, College of Medicine, Department of Biomedical Informatics","title":"API"},{"location":"API.html#api","text":"","title":"API"},{"location":"API.html#file-formats","text":"A demo data is available for loading. Additional details can be found in the pipeline . demo_data = SLKB.load_demo_data() Params : None. Returns : demo_data. A list of 3 items: sequence file, counts, fle, and score file.","title":"File Formats"},{"location":"API.html#functions-for-data-insertion-to-kb","text":"","title":"Functions For Data Insertion to KB"},{"location":"API.html#generate_database","text":"Creates a sqlite3 or mysql database, using SLKB schema. SLKB.create_SLKB(engine = 'sqlite:///SLKB_sqlite3', db_type = 'sqlite3') Params : engine: sqlalchemy url object. (Default: sqlite:///SLKB_sqlite3) db_type: Type of database to use schema for, currently available in mysql and sqlite3. (Default: sqlite3) Returns : None.","title":"generate_database"},{"location":"API.html#extract_slkb_webapp","text":"Extracts the SLKB webapp to the specified location. SLKB.extract_SLKB_webapp(location = os.getcwd()) Params : location: Location to extract SLKB files. (Default: Current working directory) Returns : None.","title":"extract_SLKB_webapp"},{"location":"API.html#prepare_study_for_export","text":"Prepares the counts, scores, and sequences files for insertion into the DB. db_inserts = SLKB.prepare_study_for_export(score_ref, sequence_ref = None, counts_ref = None, study_controls = None, study_conditions = None, can_control_be_substring = True, remove_unrelated_counts = False) Params : score_ref: A pandas table that adheres to the scores table template. sequence_ref: A pandas table that adheres to the sequence table template (default: None). counts_ref: A pandas table that adheres to the counts table template (default: None). study_controls: A list of control targets of the sgRNAs (default: None). study_conditions: A list of two lists; first list contains the replicate names of initial time point, and second list contains the same for final time point (default: None). can_control_be_substring: Can the controls be a substring of gene targets (in case of possible name conventions: default: True) remove_unrelated_counts = Remove dual counts with targets that are outside of supplied scores targets? (default: False) Returns : A dictionary of three items: scores_ref: Contains the procesed scores table (if supplied) sequences_ref: Contains the procesed sequences table (if supplied) counts_ref: Contains the procesed counts table (if supplied)","title":"prepare_study_for_export"},{"location":"API.html#insert_study_to_db","text":"Inserts the counts to the designated DB. SLKB.insert_study_to_db(SLKB_engine, db_inserts) Params : SLKB_engine: SQLAlchemy engine link db_inserts: Processed data, obtained via prepare_study_for_export Returns : None","title":"insert_study_to_db"},{"location":"API.html#scoring-functions","text":"","title":"Scoring Functions"},{"location":"API.html#median-bnb-score","text":"Calculates Median B/NB Scores. median_res = SLKB.run_median_scores(curr_counts, curr_study, curr_cl, full_normalization = False, re_run = False, store_loc = os.getcwd(), save_dir = 'MEDIAN_Files') Params : curr_counts: Counts to calculate scores to.) curr_study: String, name of study to analyze data for. curr_cl: String, name of cell line to analyze data for. full_normalization: Whether to normalize counts across the whole sample or according to target type (Default: False) re_run: Boolean. Recreate and rerun the results instead of loading for subsequent analyses (Default: False) store_loc: String: Directory to store the MAGeCK files to. (Default: current working directory) save_dir: String: Folder name to store the MAGeCK files to. (Default: 'MEDIAN_Files') Returns : median_res: A dictionary of two pandas dataframes: Median-B and Median-NB.","title":"Median-B/NB Score"},{"location":"API.html#sgrna-derived-bnb-score","text":"Calculates sgRNA Derived N/NB scores. sgRNA_res = SLKB.run_sgrna_scores(curr_counts, curr_study, curr_cl, full_normalization = False, re_run = False, store_loc = os.getcwd(), save_dir = 'sgRNA-DERIVED_Files') Params : curr_counts: Counts to calculate scores to.) curr_study: String, name of study to analyze data for. curr_cl: String, name of cell line to analyze data for. full_normalization: Whether to normalize counts across the whole sample or according to target type (Default: False) re_run: Boolean. Recreate and rerun the results instead of loading for subsequent analyses (Default: False) store_loc: String: Directory to store the MAGeCK files to. (Default: current working directory) save_dir: String: Folder name to store the MAGeCK files to. (Default: 'sgRNA-DERIVED_Files') Returns : sgRNA_res: A dictionary of two pandas dataframes: sgRNA_derived_B and sgRNA_derived_NB.","title":"sgRNA-Derived-B/NB Score"},{"location":"API.html#mageck-score","text":"Calculates MAGeCK Score. Score files will created at the designated store location and save directory. mageck_res = SLKB.run_mageck_score(curr_counts.copy(), curr_study, curr_cl, store_loc = os.getcwd(), save_dir = 'MAGECK_Files', command_line_params = [],re_run = False) Params : * curr_counts: Counts to calculate scores to.) * curr_study: String, name of study to analyze data for. * curr_cl: String, name of cell line to analyze data for. * store_loc: String: Directory to store the MAGeCK files to. (Default: current working directory) * save_dir: String: Folder name to store the MAGeCK files to. (Default: 'MAGECK_Files') * command_line_params: Optional list to load programming environment(s) to be able to run mageck tool (i.e. loading path, activating python environment). * re_run: Boolean. Recreate and rerun the results instead of loading for subsequent analyses (Default: False) Returns : mageck_res: A dict that contains a pandas dataframe for MAGeCK Score.","title":"MAGeCK Score"},{"location":"API.html#horlbeck-score","text":"Calculates Horlbeck score. Score files will created at the designated store location and save directory. horlbeck_res = SLKB.run_horlbeck_score(curr_counts.copy(), curr_study = curr_study, curr_cl = curr_cl, store_loc = os.getcwd(), save_dir = 'HORLBECK_Files', do_preprocessing = True, re_run = False) Params : * curr_counts: Counts to calculate scores to.) * curr_study: String, name of study to analyze data for. * curr_cl: String, name of cell line to analyze data for. * store_loc: String: Directory to store the MAGeCK files to. (Default: current working directory) * save_dir: String: Folder name to store the MAGeCK files to. (Default: 'Horlbeck_Files') * do_preprocessing: Boolean. Run Horlbeck preprocessing (Default: True) * re_run: Boolean. Recreate and rerun the results instead of loading for subsequent analyses (Default: False) Returns : horlbeck_res: A dict that contains a pandas dataframe for Horlbeck Score.","title":"Horlbeck Score"},{"location":"API.html#gemini-score","text":"Calculates GEMINI Score. Score files will created at the designated store location and save directory. gemini_res = run_gemini_score(curr_counts.copy(), curr_study = curr_study, curr_cl = curr_cl, store_loc = os.getcwd(), save_dir = 'GEMINI_Files', command_line_params = cmd_params, re_run = False) Params : * curr_counts: Counts to calculate scores to.) * curr_study: String, name of study to analyze data for. * curr_cl: String, name of cell line to analyze data for. * store_loc: String: Directory to store the MAGeCK files to. (Default: current working directory) * save_dir: String: Folder name to store the MAGeCK files to. (Default: 'GEMINI_Files') * command_line_params: Optional list to load programming environment(s) to be able to run GEMINI through R (i.e. loading path, activating R environment). * re_run: Boolean. Recreate and rerun the results instead of loading for subsequent analyses (Default: False) Returns : gemini_res: A dict that contains a pandas dataframe for GEMINI Score.","title":"GEMINI Score"},{"location":"API.html#check_if_added_to_table","text":"If running the scoring methods multiple times, the method may be useful in skipping over the computation if there are gene pair records already in the database. SLKB.check_if_added_to_table(curr_counts, score_name, SLKB_engine) Params : curr_counts: Counts to calculate the scores to. score_name: Table to insert the scores to. Must be any of the 7 scoring table names: HORLBECK_SCORE MEDIAN_B_SCORE MEDIAN_NB_SCORE GEMINI_SCORE MAGECK_SCORE SGRNA_DERIVED_B_SCORE SGRNA_DERIVED_NB_SCORE Returns : Boolean. True if records are inserted into the DB, False otherwise.","title":"check_if_added_to_table"},{"location":"API.html#query_results_table","text":"Obtain SL Scores from the specified scoring table. result = SLKB.query_result_table(curr_counts, table_name, curr_study, curr_cl, engine_link) Params : curr_counts: Counts to obtain the scores from. table_name: Must be any of the 7 scoring table names: horlbeck_score median_b_score median_nb_score sgrna_derived_b_score sgrna_derived_nb_score gemini_score mageck_score curr_study: String, name of the study to obtain the results for. curr_cl: String, name of the cell line to obtain the results for. engine_link: SQLAlchemy connection for the database. Returns : result: A pandas dataframe of the inserted results. Includes annotations for gene pair, study origin, and cell line origin. \u00a9 Copyright 2023, The Ohio State University, College of Medicine, Department of Biomedical Informatics","title":"query_results_table"},{"location":"Contact%20%26%20Reference.html","text":"Contact & Reference If you would like to cite SLKB, please use the following citations: [In Process] [In Process]","title":"Contact & Reference"},{"location":"Contact%20%26%20Reference.html#contact-reference","text":"If you would like to cite SLKB, please use the following citations: [In Process] [In Process]","title":"Contact &amp; Reference"},{"location":"installation.html","text":"Installation Installing from PyPI (Recommended - Upon Release) pip install SLKB Creating from source After creating your desired environment, run the following under package folder python setup.py sdist pip install dist/SLKB-1.0.0.tar.gz --user Requirements The project requires several packages to work appropriately. These packages and their versions can be found within requirements.txt or alternatively down below. pandas==1.5.3 numpy==1.21.0 SQLAlchemy==2.0.12 scipy==1.7.3 ipykernel==6.9.1 ipython==8.2.0 ipython-genutils==0.2.0 ipywidgets==7.6.5 jupyterlab==3.3.2 mysql-connector-python==8.0.29","title":"Installation"},{"location":"installation.html#installation","text":"","title":"Installation"},{"location":"installation.html#installing-from-pypi-recommended-upon-release","text":"pip install SLKB","title":"Installing from PyPI (Recommended - Upon Release)"},{"location":"installation.html#creating-from-source","text":"After creating your desired environment, run the following under package folder python setup.py sdist pip install dist/SLKB-1.0.0.tar.gz --user","title":"Creating from source"},{"location":"installation.html#requirements","text":"The project requires several packages to work appropriately. These packages and their versions can be found within requirements.txt or alternatively down below. pandas==1.5.3 numpy==1.21.0 SQLAlchemy==2.0.12 scipy==1.7.3 ipykernel==6.9.1 ipython==8.2.0 ipython-genutils==0.2.0 ipywidgets==7.6.5 jupyterlab==3.3.2 mysql-connector-python==8.0.29","title":"Requirements"},{"location":"pipeline.html","text":"Pipeline Before getting started Make sure that your SLKB pipeline package is appropriately installed. In order to run GEMINI Score and MAGeCK Score, you need to follow two additional steps: GEMINI Score: Make sure that you have an R environment with GEMINI installed (version >= 2.1.1), and ggplot2 (will be installed alongside GEMINI). MAGeCK Score: Make sure that you have MAGECK installed into your system path. If you cannot change your system path and/or need to load R environment seperately (e.g. working on HPC systems), this will be covered later. You can check whether you can access your R environment and MAGeCK on your computer. import shutil shutil.which('R') ## should yield accessed R environment location shutil.which('mageck') ## should yield MAGeCK location SLKB Pipeline Template A template has been prepared that follows through the guide's steps. Feel free to install it from its GitHub link following SLKB package's installation. Starting with a local database (SLKB Schema) First, we start with creating a local database to store the CRISPR synthetic lethality data at hand. SLKB supports mysql and sqlite3 at this time. A URL object is passed that will then create the database via stored schemas. url_object = sqlalchemy.URL.create( \"mysql+mysqlconnector\", username=\"root\", password=\"password\", # plain (unescaped) text host=\"localhost\", port = '3306', database=\"SLKB_mysql\", ) url_object = 'sqlite:///SLKB_sqlite3' SLKB_engine = sqlalchemy.create_engine(url_object, pool_size = 0) # create the database at the url_object SLKB.create_SLKB(engine = SLKB_engine, db_type = 'sqlite3') # or mysql Preparing Data for Insert sgRNA sequences Sequences reference file consists of 3 columns: sgRNA_guide_name: Name of your sgRNA guide sgRNA_guide_sequence: Sequence for your sgRNA guide sgRNA_guide_name: Target gene of the sgRNA guide Example: sgRNA_guide_name sgRNA_guide_sequence sgRNA_guide_target 0Safe-safe-ACOC-204550.4522 GTGTATTTGGCTTCCAAAA control 0Safe-safe-ACOC-204550.4525 GCATGGCCTCCACTTGCAA control AKT3-1 GTAAGGTAAATCCACATCTTG AKT3 Dual sgRNA counts Counts file contains X columns. Make sure that your counts annotation matches with the prior sequence information. guide_1: Name of your sgRNA guide at first location gene_1: Target of your sgRNA guide at first location (CONTROL if targeting control) guide_2: Name of your sgRNA guide at second location gene_2: Target of your sgRNA guide at second location (CONTROL if targeting control) study_origin: Study identifier of the added data (i.e. PubmedID, MYCDKO) cell_line_origin: Cell line identifier of the added data (e.g. 22Rv1) study_conditions: Replicate names combined, separated by ';' count_replicates: sgRNA counts from each replicate combined, separated by ';' Example: guide_1 guide_2 gene_1 gene_2 count_replicates cell_line_origin study_conditions study_origin 0Safe-safe-ACOC-204550.4522 0Safe-safe-ACOC-204550.4522 0Safe-safe-ACOC 0Safe-safe-ACOC 22;17;36;43 22Rv1 T0_1;T0_2;T12_1;T12_2 36060092 0Safe-safe-ACOC-204550.4522 0Safe-safe-ACOC-204550.4525 0Safe-safe-ACOC 0Safe-safe-ACOC 57;73;107;98 22Rv1 T0_1;T0_2;T12_1;T12_2 36060092 0Safe-safe-ACOC-204550.4522 AKT3-1 0Safe-safe-ACOC AKT3 47;45;68;85 22Rv1 T0_1;T0_2;T12_1;T12_2 36060092 Calculated SL Scores If you have calculated the gene level SL scores for your data already, you can add them here with the following columns. Otherwise, leave empty. gene_1 gene_2 study_origin cell_line_origin SL_score SL_score_cutoff (If NaN, no cutoff applied) statistical_score statistical_score_cutoff (If NaN, no cutoff applied) Example: gene_1 gene_2 study_origin cell_line_origin SL_score SL_score_cutoff statistical_score statistical_score_cutoff AKT3 AR 36060092 22Rv1 -0.977141 -0.361 NaN NaN Accessing Database Database contents can be accessed externally, and also to insert records. In this pipeline, sqlalchemy will be used to load in the database we have just created. The following codes need to be ran to ensure score calculation is correct. SLKB_engine = sqlalchemy.create_engine(db_engine) Inserting Data to Database Following data preperation, the data is now ready to be processed. We will need to declare two additonal variables before calling the processing function: control_list: List of control targets. These need to be included at counts reference; gene_1, gene_2 names to use as controls timepoint_list: A list of two elements; T0 replicates and TEnd replicates. Make sure that the replicate names align. Example: sequence_ref = ... counts_ref = ... scores_ref = ... study_controls = ['CONTROL'] study_conditions = [['T0_rep1', 'T0_rep2', 'T0_rep3'], ['TEnd_rep1', 'TEnd_rep2', 'TEnd_rep3']] db_inserts = SLKB.prepare_study_for_export(sequence_ref = sequence_ref, counts_ref = counts_ref, scores_ref = scores_ref, study_controls = study_controls, study_conditions = study_conditions) If passed checks successfully, you will notice that db_inserts contains the 3 items: sequence, counts, and score reference. In the event no scores reference was given, a dummy score of 0 was given to each possible gene pair. This is done in order to make sure that gene pairs are unique to each study and cell line. If SL scores are supplied, by default, SL scores and statistical scores below the specified threshold are deemed as SL (column SL_or_not). Otherwise, they are not SL. You can customize this behavior by accessing the yielding db_inserts['scores_ref']. By default, control genes supplied in scores file are removed. Finally, data can be inserted to the database. SLKB.insert_study_to_db(SLKB_engine, db_inserts) Calculating SL Scores and Inserting to Database Score calculation methods are independent of each other. They can be ran in any order. The details of each scoring method are located in the original paper. Each score is accompanied with two helper functions; checking whether scores have been added to the database and inserting scores to the database. check insert Initial steps SL scores for the gene pairs are calculated for each cell line individually under each study and cell line. First, we filter the counts to obtain the study counts, followed by the cell line counts. # read the data # experiment design experiment_design = pd.read_sql_query(con=SLKB_engine.connect(), sql=sqlalchemy.text('SELECT * from CDKO_EXPERIMENT_DESIGN'.lower()), index_col = 'sgRNA_id') experiment_design.reset_index(drop = True, inplace = True) experiment_design.index.rename('sgRNA_id', inplace = True) # counts counts = pd.read_sql_query(con=SLKB_engine.connect(), sql=sqlalchemy.text('SELECT * from joined_counts'.lower()), index_col = 'sgRNA_pair_id') # scores scores = pd.read_sql_query(con=SLKB_engine.connect(), sql=sqlalchemy.text('SELECT * from CDKO_ORIGINAL_SL_RESULTS'.lower()), index_col = 'id') scores.reset_index(drop = True, inplace = True) scores.index.rename('gene_pair_id', inplace = True) For all scores, files will be created in the process. You can specify the location to save your files (default: current working directory). This is done in order to enable quick loading to database for repeated analyses. GEMINI Score and MAGeCK score require file generation in order to run. In the event of updated counts file (e.g., adding additional counts), setting the parameter re_run=TRUE will restart the analysis from scratch. Median-B/NB Score if check_if_added_to_table(curr_counts.copy(), 'median_nb_score', SLKB_engine): median_res = SLKB.run_median_scores(curr_counts.copy(), curr_study = curr_study, curr_cl = curr_cl, store_loc = os.getcwd(), save_dir = 'MEDIAN_Files') SLKB.add_table_to_db(curr_counts.copy(), median_res['MEDIAN_NB_SCORE'], 'median_nb_score', SLKB_engine) if median_res['MEDIAN_B_SCORE'] is not None: SLKB.add_table_to_db(curr_counts.copy(), median_res['MEDIAN_B_SCORE'], 'median_b_score', SLKB_engine) sgRNA-Derived-B/NB Score if not check_if_added_to_table(curr_counts.copy(), 'sgrna_derived_nb_score', SLKB_engine): sgRNA_res = SLKB.run_sgrna_scores(curr_counts.copy(), curr_study = curr_study, curr_cl = curr_cl, store_loc = os.getcwd(), save_dir = 'sgRNA-DERIVED_Files') SLKB.add_table_to_db(curr_counts.copy(), sgRNA_res['SGRNA_DERIVED_NB_SCORE'], 'sgrna_derived_nb_score', SLKB_engine) if sgRNA_res['SGRNA_DERIVED_B_SCORE'] is not None: SLKB.add_table_to_db(curr_counts.copy(), sgRNA_res['SGRNA_DERIVED_B_SCORE'], 'sgrna_derived_b_score', SLKB_engine) MAGeCK Score In MAGeCK score, files will be created in process. You can specify the location to save your files (default: current working directory). If you wish to re-run to store new results in its stead, set re_run to True. MAGeCK is run through a script file at the designated location. If you need to load in any packages or set path to your mageck installation, please supply them to cmd_params. cmd_params = [] if not check_if_added_to_table(curr_counts.copy(), 'mageck_score', SLKB_engine): mageck_res = SLKB.run_mageck_score(curr_counts.copy(), curr_study = curr_study, curr_cl = curr_cl, store_loc = os.getcwd(), save_dir = 'MAGECK_Files', command_line_params = cmd_params,re_run = False) SLKB.add_table_to_db(curr_counts.copy(), mageck_res['MAGECK_SCORE'], 'mageck_score', SLKB_engine) Horlbeck Score In Horlbeck score, files will be created in process. You can specify the location to save your files (default: current working directory). If you wish to re-run to store new results in its stead, set re_run to True. if not check_if_added_to_table(curr_counts.copy(), 'horlbeck_score', SLKB_engine): horlbeck_res = SLKB.run_horlbeck_score(curr_counts.copy(), curr_study = curr_study, curr_cl = curr_cl, store_loc = os.getcwd(), save_dir = 'HORLBECK_Files', do_preprocessing = True, re_run = False) SLKB.add_table_to_db(curr_counts.copy(), horlbeck_res['HORLBECK_SCORE'], 'horlbeck_score', SLKB_engine) GEMINI Score In GEMINI score, files will be created in process. You can specify the location to save your files (default: current working directory). Scores will be stored following GEMINI analysis for quick inserts to the database. If you wish to re-run to store new results in its stead, set re_run to True. Similarly to MAGeCK, GEMINI is run through a script file at the designated location. If you need to load in any packages or set path to your mageck installation, please supply them to cmd_params. cmd_params = ['module load R/4.1.0'] if not check_if_added_to_table(curr_counts.copy(), 'gemini_score', SLKB_engine): gemini_res = SLKB.run_gemini_score(curr_counts.copy(), curr_study = curr_study, curr_cl = curr_cl, store_loc = os.getcwd(), save_dir = 'GEMINI_Files', command_line_params = cmd_params, re_run = False) SLKB.add_table_to_db(curr_counts.copy(), gemini_res['GEMINI_SCORE'], 'gemini_score', SLKB_engine) Query Results (For one table) Following the score calculations, the query is relatively easy. In this snippet of code, we will access the scores for one of the tables. score = SLKB.query_result_table(curr_counts.copy(), 'median_b_score', curr_study, curr_cl, SLKB_engine) Query Results (For all tables) Here, we will query all scores using the view within the database. all_scores = pd.read_sql_query(con=SLKB_engine.connect(), sql=sqlalchemy.text('SELECT * from calculated_sl_table')) Further Analyses SLKB web application is available for download to help analyze your generated data. You can access the website at the following link , and it's code at the link . To use user generated data, check server.r within the web app.","title":"Pipeline"},{"location":"pipeline.html#pipeline","text":"","title":"Pipeline"},{"location":"pipeline.html#before-getting-started","text":"Make sure that your SLKB pipeline package is appropriately installed. In order to run GEMINI Score and MAGeCK Score, you need to follow two additional steps: GEMINI Score: Make sure that you have an R environment with GEMINI installed (version >= 2.1.1), and ggplot2 (will be installed alongside GEMINI). MAGeCK Score: Make sure that you have MAGECK installed into your system path. If you cannot change your system path and/or need to load R environment seperately (e.g. working on HPC systems), this will be covered later. You can check whether you can access your R environment and MAGeCK on your computer. import shutil shutil.which('R') ## should yield accessed R environment location shutil.which('mageck') ## should yield MAGeCK location","title":"Before getting started"},{"location":"pipeline.html#slkb-pipeline-template","text":"A template has been prepared that follows through the guide's steps. Feel free to install it from its GitHub link following SLKB package's installation.","title":"SLKB Pipeline Template"},{"location":"pipeline.html#starting-with-a-local-database-slkb-schema","text":"First, we start with creating a local database to store the CRISPR synthetic lethality data at hand. SLKB supports mysql and sqlite3 at this time. A URL object is passed that will then create the database via stored schemas. url_object = sqlalchemy.URL.create( \"mysql+mysqlconnector\", username=\"root\", password=\"password\", # plain (unescaped) text host=\"localhost\", port = '3306', database=\"SLKB_mysql\", ) url_object = 'sqlite:///SLKB_sqlite3' SLKB_engine = sqlalchemy.create_engine(url_object, pool_size = 0) # create the database at the url_object SLKB.create_SLKB(engine = SLKB_engine, db_type = 'sqlite3') # or mysql","title":"Starting with a local database (SLKB Schema)"},{"location":"pipeline.html#preparing-data-for-insert","text":"","title":"Preparing Data for Insert"},{"location":"pipeline.html#sgrna-sequences","text":"Sequences reference file consists of 3 columns: sgRNA_guide_name: Name of your sgRNA guide sgRNA_guide_sequence: Sequence for your sgRNA guide sgRNA_guide_name: Target gene of the sgRNA guide Example: sgRNA_guide_name sgRNA_guide_sequence sgRNA_guide_target 0Safe-safe-ACOC-204550.4522 GTGTATTTGGCTTCCAAAA control 0Safe-safe-ACOC-204550.4525 GCATGGCCTCCACTTGCAA control AKT3-1 GTAAGGTAAATCCACATCTTG AKT3","title":"sgRNA sequences"},{"location":"pipeline.html#dual-sgrna-counts","text":"Counts file contains X columns. Make sure that your counts annotation matches with the prior sequence information. guide_1: Name of your sgRNA guide at first location gene_1: Target of your sgRNA guide at first location (CONTROL if targeting control) guide_2: Name of your sgRNA guide at second location gene_2: Target of your sgRNA guide at second location (CONTROL if targeting control) study_origin: Study identifier of the added data (i.e. PubmedID, MYCDKO) cell_line_origin: Cell line identifier of the added data (e.g. 22Rv1) study_conditions: Replicate names combined, separated by ';' count_replicates: sgRNA counts from each replicate combined, separated by ';' Example: guide_1 guide_2 gene_1 gene_2 count_replicates cell_line_origin study_conditions study_origin 0Safe-safe-ACOC-204550.4522 0Safe-safe-ACOC-204550.4522 0Safe-safe-ACOC 0Safe-safe-ACOC 22;17;36;43 22Rv1 T0_1;T0_2;T12_1;T12_2 36060092 0Safe-safe-ACOC-204550.4522 0Safe-safe-ACOC-204550.4525 0Safe-safe-ACOC 0Safe-safe-ACOC 57;73;107;98 22Rv1 T0_1;T0_2;T12_1;T12_2 36060092 0Safe-safe-ACOC-204550.4522 AKT3-1 0Safe-safe-ACOC AKT3 47;45;68;85 22Rv1 T0_1;T0_2;T12_1;T12_2 36060092","title":"Dual sgRNA counts"},{"location":"pipeline.html#calculated-sl-scores","text":"If you have calculated the gene level SL scores for your data already, you can add them here with the following columns. Otherwise, leave empty. gene_1 gene_2 study_origin cell_line_origin SL_score SL_score_cutoff (If NaN, no cutoff applied) statistical_score statistical_score_cutoff (If NaN, no cutoff applied) Example: gene_1 gene_2 study_origin cell_line_origin SL_score SL_score_cutoff statistical_score statistical_score_cutoff AKT3 AR 36060092 22Rv1 -0.977141 -0.361 NaN NaN","title":"Calculated SL Scores"},{"location":"pipeline.html#accessing-database","text":"Database contents can be accessed externally, and also to insert records. In this pipeline, sqlalchemy will be used to load in the database we have just created. The following codes need to be ran to ensure score calculation is correct. SLKB_engine = sqlalchemy.create_engine(db_engine)","title":"Accessing Database"},{"location":"pipeline.html#inserting-data-to-database","text":"Following data preperation, the data is now ready to be processed. We will need to declare two additonal variables before calling the processing function: control_list: List of control targets. These need to be included at counts reference; gene_1, gene_2 names to use as controls timepoint_list: A list of two elements; T0 replicates and TEnd replicates. Make sure that the replicate names align. Example: sequence_ref = ... counts_ref = ... scores_ref = ... study_controls = ['CONTROL'] study_conditions = [['T0_rep1', 'T0_rep2', 'T0_rep3'], ['TEnd_rep1', 'TEnd_rep2', 'TEnd_rep3']] db_inserts = SLKB.prepare_study_for_export(sequence_ref = sequence_ref, counts_ref = counts_ref, scores_ref = scores_ref, study_controls = study_controls, study_conditions = study_conditions) If passed checks successfully, you will notice that db_inserts contains the 3 items: sequence, counts, and score reference. In the event no scores reference was given, a dummy score of 0 was given to each possible gene pair. This is done in order to make sure that gene pairs are unique to each study and cell line. If SL scores are supplied, by default, SL scores and statistical scores below the specified threshold are deemed as SL (column SL_or_not). Otherwise, they are not SL. You can customize this behavior by accessing the yielding db_inserts['scores_ref']. By default, control genes supplied in scores file are removed. Finally, data can be inserted to the database. SLKB.insert_study_to_db(SLKB_engine, db_inserts)","title":"Inserting Data to Database"},{"location":"pipeline.html#calculating-sl-scores-and-inserting-to-database","text":"Score calculation methods are independent of each other. They can be ran in any order. The details of each scoring method are located in the original paper. Each score is accompanied with two helper functions; checking whether scores have been added to the database and inserting scores to the database. check insert","title":"Calculating SL Scores and Inserting to Database"},{"location":"pipeline.html#initial-steps","text":"SL scores for the gene pairs are calculated for each cell line individually under each study and cell line. First, we filter the counts to obtain the study counts, followed by the cell line counts. # read the data # experiment design experiment_design = pd.read_sql_query(con=SLKB_engine.connect(), sql=sqlalchemy.text('SELECT * from CDKO_EXPERIMENT_DESIGN'.lower()), index_col = 'sgRNA_id') experiment_design.reset_index(drop = True, inplace = True) experiment_design.index.rename('sgRNA_id', inplace = True) # counts counts = pd.read_sql_query(con=SLKB_engine.connect(), sql=sqlalchemy.text('SELECT * from joined_counts'.lower()), index_col = 'sgRNA_pair_id') # scores scores = pd.read_sql_query(con=SLKB_engine.connect(), sql=sqlalchemy.text('SELECT * from CDKO_ORIGINAL_SL_RESULTS'.lower()), index_col = 'id') scores.reset_index(drop = True, inplace = True) scores.index.rename('gene_pair_id', inplace = True) For all scores, files will be created in the process. You can specify the location to save your files (default: current working directory). This is done in order to enable quick loading to database for repeated analyses. GEMINI Score and MAGeCK score require file generation in order to run. In the event of updated counts file (e.g., adding additional counts), setting the parameter re_run=TRUE will restart the analysis from scratch.","title":"Initial steps"},{"location":"pipeline.html#median-bnb-score","text":"if check_if_added_to_table(curr_counts.copy(), 'median_nb_score', SLKB_engine): median_res = SLKB.run_median_scores(curr_counts.copy(), curr_study = curr_study, curr_cl = curr_cl, store_loc = os.getcwd(), save_dir = 'MEDIAN_Files') SLKB.add_table_to_db(curr_counts.copy(), median_res['MEDIAN_NB_SCORE'], 'median_nb_score', SLKB_engine) if median_res['MEDIAN_B_SCORE'] is not None: SLKB.add_table_to_db(curr_counts.copy(), median_res['MEDIAN_B_SCORE'], 'median_b_score', SLKB_engine)","title":"Median-B/NB Score"},{"location":"pipeline.html#sgrna-derived-bnb-score","text":"if not check_if_added_to_table(curr_counts.copy(), 'sgrna_derived_nb_score', SLKB_engine): sgRNA_res = SLKB.run_sgrna_scores(curr_counts.copy(), curr_study = curr_study, curr_cl = curr_cl, store_loc = os.getcwd(), save_dir = 'sgRNA-DERIVED_Files') SLKB.add_table_to_db(curr_counts.copy(), sgRNA_res['SGRNA_DERIVED_NB_SCORE'], 'sgrna_derived_nb_score', SLKB_engine) if sgRNA_res['SGRNA_DERIVED_B_SCORE'] is not None: SLKB.add_table_to_db(curr_counts.copy(), sgRNA_res['SGRNA_DERIVED_B_SCORE'], 'sgrna_derived_b_score', SLKB_engine)","title":"sgRNA-Derived-B/NB Score"},{"location":"pipeline.html#mageck-score","text":"In MAGeCK score, files will be created in process. You can specify the location to save your files (default: current working directory). If you wish to re-run to store new results in its stead, set re_run to True. MAGeCK is run through a script file at the designated location. If you need to load in any packages or set path to your mageck installation, please supply them to cmd_params. cmd_params = [] if not check_if_added_to_table(curr_counts.copy(), 'mageck_score', SLKB_engine): mageck_res = SLKB.run_mageck_score(curr_counts.copy(), curr_study = curr_study, curr_cl = curr_cl, store_loc = os.getcwd(), save_dir = 'MAGECK_Files', command_line_params = cmd_params,re_run = False) SLKB.add_table_to_db(curr_counts.copy(), mageck_res['MAGECK_SCORE'], 'mageck_score', SLKB_engine)","title":"MAGeCK Score"},{"location":"pipeline.html#horlbeck-score","text":"In Horlbeck score, files will be created in process. You can specify the location to save your files (default: current working directory). If you wish to re-run to store new results in its stead, set re_run to True. if not check_if_added_to_table(curr_counts.copy(), 'horlbeck_score', SLKB_engine): horlbeck_res = SLKB.run_horlbeck_score(curr_counts.copy(), curr_study = curr_study, curr_cl = curr_cl, store_loc = os.getcwd(), save_dir = 'HORLBECK_Files', do_preprocessing = True, re_run = False) SLKB.add_table_to_db(curr_counts.copy(), horlbeck_res['HORLBECK_SCORE'], 'horlbeck_score', SLKB_engine)","title":"Horlbeck Score"},{"location":"pipeline.html#gemini-score","text":"In GEMINI score, files will be created in process. You can specify the location to save your files (default: current working directory). Scores will be stored following GEMINI analysis for quick inserts to the database. If you wish to re-run to store new results in its stead, set re_run to True. Similarly to MAGeCK, GEMINI is run through a script file at the designated location. If you need to load in any packages or set path to your mageck installation, please supply them to cmd_params. cmd_params = ['module load R/4.1.0'] if not check_if_added_to_table(curr_counts.copy(), 'gemini_score', SLKB_engine): gemini_res = SLKB.run_gemini_score(curr_counts.copy(), curr_study = curr_study, curr_cl = curr_cl, store_loc = os.getcwd(), save_dir = 'GEMINI_Files', command_line_params = cmd_params, re_run = False) SLKB.add_table_to_db(curr_counts.copy(), gemini_res['GEMINI_SCORE'], 'gemini_score', SLKB_engine)","title":"GEMINI Score"},{"location":"pipeline.html#query-results-for-one-table","text":"Following the score calculations, the query is relatively easy. In this snippet of code, we will access the scores for one of the tables. score = SLKB.query_result_table(curr_counts.copy(), 'median_b_score', curr_study, curr_cl, SLKB_engine)","title":"Query Results (For one table)"},{"location":"pipeline.html#query-results-for-all-tables","text":"Here, we will query all scores using the view within the database. all_scores = pd.read_sql_query(con=SLKB_engine.connect(), sql=sqlalchemy.text('SELECT * from calculated_sl_table'))","title":"Query Results (For all tables)"},{"location":"pipeline.html#further-analyses","text":"SLKB web application is available for download to help analyze your generated data. You can access the website at the following link , and it's code at the link . To use user generated data, check server.r within the web app.","title":"Further Analyses"},{"location":"website.html","text":"SLKB Web Application SLKB can be freely accessed and queried at the following link .","title":"SLKB Web Application"},{"location":"website.html#slkb-web-application","text":"SLKB can be freely accessed and queried at the following link .","title":"SLKB Web Application"}]}