{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLKB Pipeline\n",
    "\n",
    "Here, we will go over the discussed pipeline using a Toy Data. Feel free to use this file to analyze your dataset. The file is divided into 3 main parts: (1) Data creation, (2) Score calculation, (3) Query Results\n",
    "\n",
    "## Before getting started\n",
    "\n",
    "Make sure an R environment with GEMINI, and mageck tool are located in your path. To see whether you can run their respective scores or not, you can run the following command:\n",
    "\n",
    "```\n",
    "import shutil\n",
    "shutil.which('R') ## should yield accessed R environment location\n",
    "shutil.which('mageck') ## should yield MAGeCK location\n",
    "```\n",
    "\n",
    "In additon, make sure to install SLKB python package. The details can be located at its [website](https://www.google.com)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First, we load in our packages\n",
    "import SLKB\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import sqlalchemy\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import subprocess\n",
    "import shlex\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1 - Data Preperation\n",
    "\n",
    "First, we start by installing a pickle file that contains the toy data. Not all input files are required. For score calculation, only sequences and counts files are sufficient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from\n",
    "\n",
    "sequences_ref = urllib.request.urlopen(pickle_loc).read()\n",
    "counts_ref = urllib.request.urlopen(pickle_loc).read()\n",
    "scores_ref = urllib.request.urlopen(pickle_loc).read()\n",
    "\n",
    "# let us create a local sqlite3 database to store our results in, and connect to it\n",
    "\n",
    "db_engine = create_SLKB(location = os.getcwd(), name = 'myCDKO_db')\n",
    "SLKB_engine = sqlalchemy.create_engine(db_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(counts_ref.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sequences_ref.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores_ref.head(15))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inserting to DB\n",
    "\n",
    "After each data is prepared, the study is ready to be inserted into the database. The ```prepare_study_for_export``` function will go over the data and prepare the data for insertion. It will produce errors where necessary, make sure that your files match with the template. \n",
    "\n",
    "Make sure your control gene list is set up properly to correctly categorize the counts file. The counts file will produce a ```target_type``` column that contains three categories:\n",
    "1. Dual - Both sgRNAs targeting different genes.\n",
    "2. Single - Both sgRNAs targeting the same gene (i.e., gene_1 + gene_1, or gene_1 + control)\n",
    "3. Control - Both sgRNAs targeting controls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_controls = ['CONTROL']\n",
    "study_conditions = [['T0_rep1', 'T0_rep2', 'T0_rep3'],\n",
    "                    ['TEnd_rep1', 'TEnd_rep2', 'TEnd_rep3']]\n",
    "\n",
    "db_inserts = prepare_study_for_export(sequence_ref = sequence_ref.copy(), \n",
    "                                      counts_ref = counts_ref.copy(),\n",
    "                                      scores_ref = scores_ref.copy(),\n",
    "                                      study_controls = study_controls,\n",
    "                                      study_conditions = study_conditions)\n",
    "\n",
    "print(db_inserts['score_ref'].head(15))\n",
    "print(db_inserts['sequences_ref'].head(15))\n",
    "print(db_inserts['counts_ref'].head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, insert the data to the database\n",
    "insert_study_to_db(SLKB_engine, db_inserts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2 - Score Calculation\n",
    "\n",
    "Here, we calculate the scores and add them to the database. First, we start by querying the data we just deposited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "\n",
    "# experiment design\n",
    "experiment_design = pd.read_sql_table('CDKO_EXPERIMENT_DESIGN', SLKB_engine, index_col = 'sgRNA_id')\n",
    "experiment_design.reset_index(drop = True, inplace = True)\n",
    "experiment_design.index.rename('sgRNA_id', inplace = True)\n",
    "\n",
    "# counts\n",
    "counts = pd.read_sql_table('CDKO_SGRNA_COUNTS', SLKB_engine, index_col = 'sgRNA_pair_id')\n",
    "counts.reset_index(drop = True, inplace = True)\n",
    "counts.index.rename('sgRNA_pair_id', inplace = True)\n",
    "\n",
    "# scores\n",
    "scores = pd.read_sql_table('CDKO_ORIGINAL_SL_RESULTS', SLKB_engine, index_col = 'id')\n",
    "scores.reset_index(drop = True, inplace = True)\n",
    "scores.index.rename('gene_pair_id', inplace = True)\n",
    "\n",
    "# join the tables together\n",
    "counts = counts.merge(experiment_design, how = 'left', left_on = 'guide_1_id', right_index = True, suffixes = ('', '_g1'))\n",
    "counts = counts.merge(experiment_design, how = 'left', left_on = 'guide_2_id', right_index = True, suffixes = ('', '_g2'))\n",
    "# rename\n",
    "counts = counts.rename({'sgRNA_guide_name': 'sgRNA_guide_name_g1',\n",
    "                        'sgRNA_guide_seq': 'sgRNA_guide_seq_g1',\n",
    "                        'sgRNA_target_name': 'sgRNA_target_name_g1',\n",
    "                        'study_origin_x': 'study_origin',\n",
    "                        'cell_line_origin_x': 'cell_line_origin'}, axis = 1)\n",
    "\n",
    "\n",
    "curr_counts = counts[(counts['study_origin'] == 'myStudy') & (counts['cell_line_origin'] == 'myCL')]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Median B/NB Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_if_added_to_table(curr_counts.copy(), 'MEDIAN_NB_SCORE', SLKB_engine):\n",
    "    median_res = run_median_scores(curr_counts.copy())\n",
    "    add_table_to_db(curr_counts.copy(), median_res['MEDIAN_NB_SCORE'], 'MEDIAN_NB_SCORE', SLKB_engine)\n",
    "    if median_res['MEDIAN_B_SCORE'] is not None:\n",
    "        add_table_to_db(curr_counts.copy(), median_res['MEDIAN_B_SCORE'], 'MEDIAN_B_SCORE', SLKB_engine)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sgRNA Derived B/NB Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not check_if_added_to_table(curr_counts.copy(), 'SGRA_DERIVED_NB_SCORE', SLKB_engine):\n",
    "    sgRNA_res = run_sgrna_scores(curr_counts.copy())\n",
    "    add_table_to_db(curr_counts.copy(), sgRNA_res['SGRA_DERIVED_NB_SCORE'], 'SGRA_DERIVED_NB_SCORE', SLKB_engine)\n",
    "    if sgRNA_res['SGRA_DERIVED_B_SCORE'] is not None:\n",
    "        add_table_to_db(curr_counts.copy(), sgRNA_res['SGRA_DERIVED_B_SCORE'], 'SGRA_DERIVED_B_SCORE', SLKB_engine)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Horlbeck Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not check_if_added_to_table(curr_counts.copy(), 'HORLBECK_SCORE', SLKB_engine):\n",
    "    horlbeck_res = run_horlbeck_score(curr_counts.copy(), curr_study = curr_study, curr_cl = curr_cl, store_loc = os.getcwd(), save_dir = 'HORLBECK_Files', do_preprocessing = True, re_run = False)\n",
    "    add_table_to_db(curr_counts.copy(), horlbeck_res['HORLBECK_SCORE'], 'HORLBECK_SCORE', SLKB_engine)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GEMINI Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd_params = ['module load R/4.1.0']\n",
    "if not check_if_added_to_table(curr_counts.copy(), 'GEMINI_SCORE', SLKB_engine):\n",
    "    gemini_res = run_gemini_score(curr_counts.copy(), curr_study = curr_study, curr_cl = curr_cl, store_loc = os.getcwd(), save_dir = 'GEMINI_Files', command_line_params = cmd_params, re_run = False)\n",
    "    add_table_to_db(curr_counts.copy(), gemini_res['GEMINI_SCORE'], 'GEMINI_SCORE', SLKB_engine)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAGeCK Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd_params = ['conda activate myEnv']\n",
    "if not check_if_added_to_table(curr_counts.copy(), 'MAGECK_SCORE', SLKB_engine):\n",
    "    mageck_res = run_mageck_score(curr_counts.copy(), curr_study = curr_study, curr_cl = curr_cl, store_loc = os.getcwd(), save_dir = 'MAGECK_Files', command_line_params = cmd_params,re_run = False)\n",
    "    add_table_to_db(curr_counts.copy(), mageck_res['MAGECK_SCORE'], 'MAGECK_SCORE', SLKB_engine)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3 - Query Results\n",
    "\n",
    "Finally, we can query the data to produce the calculation table.\n",
    "\n",
    "![table](../../docs/images/Calculation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "\n",
    "# experiment design\n",
    "experiment_design = pd.read_sql_table('CDKO_EXPERIMENT_DESIGN', SLKB_engine, index_col = 'sgRNA_id')\n",
    "experiment_design.drop(['study_origin'], axis = 1, inplace = True)\n",
    "experiment_design.reset_index(drop = True, inplace = True)\n",
    "experiment_design.index.rename('sgRNA_id', inplace = True)\n",
    "\n",
    "# counts\n",
    "counts = pd.read_sql_table('CDKO_SGRNA_COUNTS', SLKB_engine, index_col = 'sgRNA_pair_id')\n",
    "counts.reset_index(drop = True, inplace = True)\n",
    "counts.index.rename('sgRNA_pair_id', inplace = True)\n",
    "\n",
    "# scores\n",
    "scores = pd.read_sql_table('CDKO_ORIGINAL_SL_RESULTS', SLKB_engine, index_col = 'gene_pair_id')\n",
    "\n",
    "# join the tables together\n",
    "counts = counts.merge(scores, how = 'left', left_on = 'gene_pair_id', right_index = True)\n",
    "counts = counts.merge(experiment_design, how = 'left', left_on = 'guide_1_id', right_index = True, suffixes = ('', '_g1'))\n",
    "counts = counts.merge(experiment_design, how = 'left', left_on = 'guide_2_id', right_index = True, suffixes = ('', '_g2'))\n",
    "# rename\n",
    "counts = counts.rename({'sgRNA_guide_name': 'sgRNA_guide_name_g1',\n",
    "                        'sgRNA_guide_seq': 'sgRNA_guide_seq_g1',\n",
    "                        'sgRNA_target_name': 'sgRNA_target_name_g1',\n",
    "                        'study_origin_x': 'study_origin',\n",
    "                        'cell_line_origin_x': 'cell_line_origin'}, axis = 1)\n",
    "\n",
    "experiment_design = pd.read_sql_table('CDKO_EXPERIMENT_DESIGN', SLKB_engine, index_col = 'sgRNA_id')\n",
    "experiment_design.reset_index(drop = True, inplace = True)\n",
    "experiment_design.index.rename('sgRNA_id', inplace = True)\n",
    "\n",
    "# tables to obtain the data from\n",
    "all_results_tables = ['HORLBECK_SCORE', \n",
    "                      'MAGECK_SCORE', \n",
    "                      'MEDIAN_NB_SCORE', \n",
    "                      'MEDIAN_B_SCORE', \n",
    "                      'SGRA_DERIVED_NB_SCORE', \n",
    "                      'SGRA_DERIVED_B_SCORE', \n",
    "                      'GEMINI_SCORE']\n",
    "\n",
    "#################\n",
    "\n",
    "all_scores = []\n",
    "for curr_study in available_studies:\n",
    "    print('Working on study: ' + curr_study)\n",
    "\n",
    "    # get study counts and seq\n",
    "    study_counts = counts.loc[counts['study_origin'] == study_name_to_pubmed_id[curr_study]].copy()\n",
    "\n",
    "    curr_seq_ids = np.array(sorted(list(set(study_counts['guide_1_id'].tolist() + study_counts['guide_2_id'].tolist()))))\n",
    "    study_sequences = experiment_design.loc[curr_seq_ids]\n",
    "\n",
    "    # the analysis runs for each individual cell line\n",
    "    available_cell_lines = set(study_counts['cell_line_origin'])\n",
    "\n",
    "\n",
    "    for curr_cl in available_cell_lines:\n",
    "        # store results here\n",
    "        study_scores = []\n",
    "    \n",
    "        print('Working on cell line: ' + curr_cl)\n",
    "        curr_counts = study_counts.loc[study_counts['cell_line_origin'] == curr_cl].copy()\n",
    "        \n",
    "        for table_name in all_results_tables:\n",
    "            # add the result of the table to the list\n",
    "            study_scores.append(query_result_table(curr_counts.copy(), table_name, curr_study, curr_cl, SLKB_engine))\n",
    "    \n",
    "        # remove duplicate annotation columns\n",
    "        study_scores = pd.concat(study_scores, axis = 1, ignore_index = False)\n",
    "        study_scores = study_scores.loc[:,~study_scores.columns.duplicated(keep = 'last')].copy()\n",
    "        \n",
    "        # make sure the annotations are all filled\n",
    "        study_scores['gene_pair'] = study_scores.index\n",
    "        study_scores['study_origin'] = curr_study\n",
    "        study_scores['cell_line_origin'] = curr_cl\n",
    "        \n",
    "        # reset the index, gene_pair -> id\n",
    "        study_scores.reset_index(drop = True, inplace = True)\n",
    "\n",
    "        # add to big table \n",
    "        all_scores.append(study_scores)\n",
    "    \n",
    "    print('-----')\n",
    "    \n",
    "print('Done getting all data!')\n",
    "    \n",
    "# combine the scores at the end\n",
    "all_scores = pd.concat(all_scores, axis = 0, ignore_index = True)\n",
    "\n",
    "# add individual genes\n",
    "all_scores['gene_1'] = [i.split('|')[0] for i in all_scores['gene_pair']]\n",
    "all_scores['gene_2'] = [i.split('|')[1] for i in all_scores['gene_pair']]\n",
    "\n",
    "# sort such that all annotations are at the front\n",
    "all_columns = sorted(list(all_scores.columns))\n",
    "annotation_columns = ['gene_pair', 'gene_1', 'gene_2', 'study_origin', 'cell_line_origin']\n",
    "\n",
    "# get the final scores\n",
    "all_scores = all_scores.loc[:, annotation_columns + [i for i in all_columns if i not in annotation_columns]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to current directory\n",
    "all_scores.to_csv(os.path.join(os.getcwd(), 'all_scores.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6 (default, Mar 10 2023, 20:16:38) \n[Clang 14.0.3 (clang-1403.0.22.14.1)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
