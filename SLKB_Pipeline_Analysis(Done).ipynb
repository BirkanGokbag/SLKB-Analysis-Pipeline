{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a499a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "from itertools import chain\n",
    "import pickle\n",
    "import sqlalchemy\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from scipy import optimize\n",
    "from scipy.stats import sem\n",
    "import subprocess\n",
    "import shlex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f86f0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.engine import Engine\n",
    "from sqlalchemy import event\n",
    "\n",
    "@event.listens_for(Engine, \"connect\")\n",
    "def set_sqlite_pragma(dbapi_connection, connection_record):\n",
    "    cursor = dbapi_connection.cursor()\n",
    "    cursor.execute(\"PRAGMA foreign_keys=ON\")\n",
    "    cursor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fb2e67",
   "metadata": {},
   "source": [
    "## Extract Original SL Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf91a1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the datasets\n",
    "data_locs = \"/users/PAS1376/bg12/SyntheticLethality/SyntheticLethalityReview/Project/ml_inputs\"\n",
    "learning_goals_loc_general =  os.path.join(data_locs, \"learning_goals\")\n",
    "learning_goals_loc_general = '/users/PAS1376/bg12/SyntheticLethality - NewDB/data'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41cda183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the database\n",
    "SLKB_engine = sqlalchemy.create_engine('sqlite:///SLKB_sqlite3')\n",
    "#SLKB_engine_session = sessionmaker(bind=SLKB_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8ef19d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_metadata = sqlalchemy.MetaData(bind=SLKB_engine)\n",
    "db_metadata.reflect(SLKB_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1227a286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FacadeDict({'CDKO_EXPERIMENT_DESIGN': Table('CDKO_EXPERIMENT_DESIGN', MetaData(bind=Engine(sqlite:///SLKB_sqlite3)), Column('sgRNA_id', INTEGER(), table=<CDKO_EXPERIMENT_DESIGN>, primary_key=True), Column('sgRNA_guide_name', TEXT(), table=<CDKO_EXPERIMENT_DESIGN>, nullable=False), Column('sgRNA_guide_seq', TEXT(), table=<CDKO_EXPERIMENT_DESIGN>, nullable=False), Column('sgRNA_target_name', TEXT(), table=<CDKO_EXPERIMENT_DESIGN>, nullable=False), Column('study_origin', TEXT(), table=<CDKO_EXPERIMENT_DESIGN>, nullable=False), schema=None), 'CDKO_ORIGINAL_SL_RESULTS': Table('CDKO_ORIGINAL_SL_RESULTS', MetaData(bind=Engine(sqlite:///SLKB_sqlite3)), Column('id', INTEGER(), table=<CDKO_ORIGINAL_SL_RESULTS>, primary_key=True), Column('gene_pair_id', INTEGER(), table=<CDKO_ORIGINAL_SL_RESULTS>), Column('gene_pair', TEXT(), table=<CDKO_ORIGINAL_SL_RESULTS>, nullable=False), Column('study_origin', TEXT(), table=<CDKO_ORIGINAL_SL_RESULTS>, nullable=False), Column('cell_line_origin', TEXT(), table=<CDKO_ORIGINAL_SL_RESULTS>, nullable=False), Column('gene_1', TEXT(), table=<CDKO_ORIGINAL_SL_RESULTS>, nullable=False), Column('gene_2', TEXT(), table=<CDKO_ORIGINAL_SL_RESULTS>, nullable=False), Column('SL_or_not', TEXT(), table=<CDKO_ORIGINAL_SL_RESULTS>, nullable=False), Column('SL_score', REAL(), table=<CDKO_ORIGINAL_SL_RESULTS>), Column('statistical_score', REAL(), table=<CDKO_ORIGINAL_SL_RESULTS>), Column('SL_score_cutoff', REAL(), table=<CDKO_ORIGINAL_SL_RESULTS>), Column('statistical_score_cutoff', REAL(), table=<CDKO_ORIGINAL_SL_RESULTS>), schema=None), 'CDKO_SGRNA_COUNTS': Table('CDKO_SGRNA_COUNTS', MetaData(bind=Engine(sqlite:///SLKB_sqlite3)), Column('sgRNA_pair_id', INTEGER(), table=<CDKO_SGRNA_COUNTS>, primary_key=True), Column('guide_1_id', INTEGER(), ForeignKey('CDKO_EXPERIMENT_DESIGN.sgRNA_id'), table=<CDKO_SGRNA_COUNTS>), Column('guide_2_id', INTEGER(), ForeignKey('CDKO_EXPERIMENT_DESIGN.sgRNA_id'), table=<CDKO_SGRNA_COUNTS>), Column('gene_pair_id', INTEGER(), table=<CDKO_SGRNA_COUNTS>), Column('gene_pair_orientation', TEXT(), table=<CDKO_SGRNA_COUNTS>), Column('T0_counts', TEXT(), table=<CDKO_SGRNA_COUNTS>), Column('T0_replicate_names', TEXT(), table=<CDKO_SGRNA_COUNTS>), Column('TEnd_counts', TEXT(), table=<CDKO_SGRNA_COUNTS>), Column('TEnd_replicate_names', TEXT(), table=<CDKO_SGRNA_COUNTS>), Column('target_type', TEXT(), table=<CDKO_SGRNA_COUNTS>), Column('study_origin', TEXT(), table=<CDKO_SGRNA_COUNTS>, nullable=False), Column('cell_line_origin', TEXT(), table=<CDKO_SGRNA_COUNTS>, nullable=False), schema=None), 'GEMINI_SCORE': Table('GEMINI_SCORE', MetaData(bind=Engine(sqlite:///SLKB_sqlite3)), Column('id', INTEGER(), table=<GEMINI_SCORE>, primary_key=True), Column('gene_pair_id', INTEGER(), table=<GEMINI_SCORE>), Column('SL_score', REAL(), table=<GEMINI_SCORE>), schema=None), 'HORLBECK_SCORE': Table('HORLBECK_SCORE', MetaData(bind=Engine(sqlite:///SLKB_sqlite3)), Column('id', INTEGER(), table=<HORLBECK_SCORE>, primary_key=True), Column('gene_pair_id', INTEGER(), table=<HORLBECK_SCORE>), Column('SL_score', REAL(), table=<HORLBECK_SCORE>), Column('standard_error', REAL(), table=<HORLBECK_SCORE>), schema=None), 'MAGECK_SCORE': Table('MAGECK_SCORE', MetaData(bind=Engine(sqlite:///SLKB_sqlite3)), Column('id', INTEGER(), table=<MAGECK_SCORE>, primary_key=True), Column('gene_pair_id', INTEGER(), table=<MAGECK_SCORE>), Column('SL_score', REAL(), table=<MAGECK_SCORE>), Column('standard_error', REAL(), table=<MAGECK_SCORE>), Column('Z_SL_score', REAL(), table=<MAGECK_SCORE>), schema=None), 'MEDIAN_B_SCORE': Table('MEDIAN_B_SCORE', MetaData(bind=Engine(sqlite:///SLKB_sqlite3)), Column('id', INTEGER(), table=<MEDIAN_B_SCORE>, primary_key=True), Column('gene_pair_id', INTEGER(), table=<MEDIAN_B_SCORE>), Column('SL_score', REAL(), table=<MEDIAN_B_SCORE>), Column('standard_error', REAL(), table=<MEDIAN_B_SCORE>), Column('Z_SL_score', REAL(), table=<MEDIAN_B_SCORE>), schema=None), 'MEDIAN_NB_SCORE': Table('MEDIAN_NB_SCORE', MetaData(bind=Engine(sqlite:///SLKB_sqlite3)), Column('id', INTEGER(), table=<MEDIAN_NB_SCORE>, primary_key=True), Column('gene_pair_id', INTEGER(), table=<MEDIAN_NB_SCORE>), Column('SL_score', REAL(), table=<MEDIAN_NB_SCORE>), Column('standard_error', REAL(), table=<MEDIAN_NB_SCORE>), Column('Z_SL_score', REAL(), table=<MEDIAN_NB_SCORE>), schema=None), 'SGRA_DERIVED_B_SCORE': Table('SGRA_DERIVED_B_SCORE', MetaData(bind=Engine(sqlite:///SLKB_sqlite3)), Column('id', INTEGER(), table=<SGRA_DERIVED_B_SCORE>, primary_key=True), Column('gene_pair_id', INTEGER(), table=<SGRA_DERIVED_B_SCORE>), Column('SL_score', REAL(), table=<SGRA_DERIVED_B_SCORE>), schema=None), 'SGRA_DERIVED_NB_SCORE': Table('SGRA_DERIVED_NB_SCORE', MetaData(bind=Engine(sqlite:///SLKB_sqlite3)), Column('id', INTEGER(), table=<SGRA_DERIVED_NB_SCORE>, primary_key=True), Column('gene_pair_id', INTEGER(), table=<SGRA_DERIVED_NB_SCORE>), Column('SL_score', REAL(), table=<SGRA_DERIVED_NB_SCORE>), schema=None)})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_metadata.tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef7249ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_metadata = sqlalchemy.MetaData(bind=SLKB_engine)\n",
    "# db_metadata.reflect(SLKB_engine)\n",
    "\n",
    "# all_results_tables = ['HORLBECK_SCORE', \n",
    "#                       'MAGECK_SCORE', \n",
    "#                       'MEDIAN_NB_SCORE', \n",
    "#                       'MEDIAN_NB_SCORE_FULL_NORM', \n",
    "#                       'MEDIAN_B_SCORE', \n",
    "#                       'MEDIAN_B_SCORE_FULL_NORM',\n",
    "#                       'SGRA_DERIVED_NB_SCORE', \n",
    "#                       'SGRA_DERIVED_NB_SCORE_FULL_NORM', \n",
    "#                       'SGRA_DERIVED_B_SCORE', \n",
    "#                       'SGRA_DERIVED_B_SCORE_FULL_NORM', \n",
    "#                       'GEMINI_SCORE']\n",
    "\n",
    "# for table_name in all_results_tables:\n",
    "#     curr_table = db_metadata.tables[table_name]\n",
    "#     curr_table.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cb8e75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## store pubmed IDs\n",
    "study_name_to_pubmed_id = {}\n",
    "\n",
    "study_name_to_pubmed_id['diehl_data'] = '33956155'\n",
    "\n",
    "study_name_to_pubmed_id['han_data'] = '28319085'\n",
    "\n",
    "study_name_to_pubmed_id['horlbeck_data'] = '30033366'\n",
    "\n",
    "study_name_to_pubmed_id['ito_data'] = '34857952'\n",
    "\n",
    "study_name_to_pubmed_id['parrish_data'] = '34469736'\n",
    "\n",
    "study_name_to_pubmed_id['shen_data'] = '28319113'\n",
    "\n",
    "study_name_to_pubmed_id['thompson_data'] = '33637726'\n",
    "\n",
    "study_name_to_pubmed_id['wong_data'] = '26864203'\n",
    "\n",
    "study_name_to_pubmed_id['zhao_data'] = '29452643'\n",
    "\n",
    "study_name_to_pubmed_id['shantang_data'] = '36060092'\n",
    "\n",
    "study_name_to_pubmed_id['najm_data'] = '29251726'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05ac401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_study_name_to_pubmed_id = {}\n",
    "for item in study_name_to_pubmed_id:\n",
    "    rev_study_name_to_pubmed_id[study_name_to_pubmed_id[item]] = item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8764103",
   "metadata": {},
   "outputs": [],
   "source": [
    "## controls\n",
    "controls = {}\n",
    "\n",
    "# diehl et al\n",
    "controls['diehl_data'] = [\"wildtype-I-CeuI\", \"wildtype-I-SceI\", \"nan\"] + [\"Non-Human-Target-114\", \"Non-Human-Target-122\",\n",
    "                                    \"Non-Human-Target-144\", \"Non-Human-Target-148\", \"Non-Human-Target-161\", \"Non-Human-Target-178\", \"Non-Human-Target-185\", \"Non-Human-Target-222\", \"Non-Human-Target-223\",\n",
    "                                    \"Non-Human-Target-224\", \"Non-Human-Target-23\", \"Non-Human-Target-243\", \"Non-Human-Target-245\", \"Non-Human-Target-249\", \"Non-Human-Target-292\", \"Non-Human-Target-298\",\n",
    "                                    \"Non-Human-Target-31\", \"Non-Human-Target-311\", \"Non-Human-Target-313\", \"Non-Human-Target-327\", \"Non-Human-Target-333\", \"Non-Human-Target-335\", \"Non-Human-Target-339\",\n",
    "                                    \"Non-Human-Target-341\", \"Non-Human-Target-343\", \"Non-Human-Target-389\", \"Non-Human-Target-39\", \"Non-Human-Target-397\", \"Non-Human-Target-398\", \"Non-Human-Target-40\", \n",
    "                                    \"Non-Human-Target-402\", \"Non-Human-Target-42\", \"Non-Human-Target-432\", \"Non-Human-Target-444\", \"Non-Human-Target-466\", \"Non-Human-Target-479\", \"Non-Human-Target-495\",\n",
    "                                    \"Non-Human-Target-512\", \"Non-Human-Target-515\", \"Non-Human-Target-526\", \"Non-Human-Target-532\", \"Non-Human-Target-542\", \"Non-Human-Target-547\", \"Non-Human-Target-55\", \n",
    "                                    \"Non-Human-Target-551\", \"Non-Human-Target-560\", \"Non-Human-Target-565\", \"Non-Human-Target-584\", \"Non-Human-Target-588\", \"Non-Human-Target-595\", \"Non-Human-Target-602\",\n",
    "                                    \"Non-Human-Target-622\", \"Non-Human-Target-636\", \"Non-Human-Target-637\", \"Non-Human-Target-654\", \"Non-Human-Target-659\", \"Non-Human-Target-668\", \"Non-Human-Target-676\",\n",
    "                                    \"Non-Human-Target-678\", \"Non-Human-Target-681\", \"Non-Human-Target-692\", \"Non-Human-Target-719\", \"Non-Human-Target-732\", \"Non-Human-Target-736\", \"Non-Human-Target-748\",\n",
    "                                    \"Non-Human-Target-752\", \"Non-Human-Target-766\", \"Non-Human-Target-782\", \"Non-Human-Target-789\", \"Non-Human-Target-798\", \"Non-Human-Target-799\", \"Non-Human-Target-801\",\n",
    "                                    \"Non-Human-Target-805\", \"Non-Human-Target-807\", \"Non-Human-Target-808\", \"Non-Human-Target-814\", \"Non-Human-Target-816\", \"Non-Human-Target-822\", \"Non-Human-Target-824\",\n",
    "                                    \"Non-Human-Target-827\", \"Non-Human-Target-828\", \"Non-Human-Target-835\", \"Non-Human-Target-85\", \"Non-Human-Target-857\", \"Non-Human-Target-863\", \"Non-Human-Target-864\",\n",
    "                                    \"Non-Human-Target-877\", \"Non-Human-Target-88\", \"Non-Human-Target-884\", \"Non-Human-Target-900\", \"Non-Human-Target-902\", \"Non-Human-Target-905\", \"Non-Human-Target-941\",\n",
    "                                    \"Non-Human-Target-942\", \"Non-Human-Target-953\", \"Non-Human-Target-954\", \"Non-Human-Target-958\", \"Non-Human-Target-959\", \"Non-Human-Target-965\", \"Non-Human-Target-969\",\n",
    "                                    \"Non-Human-Target-970\", \"Non-Human-Target-99\", \"Non-Human-Target-995\", \"Non-Human-Target-997\"]\n",
    "\n",
    "# horlbeck et al\n",
    "controls['horlbeck_data'] = [\"negative\"]\n",
    "\n",
    "# parrish et al\n",
    "controls['parrish_data'] = [\"nt\" + str(i+1) for i in range(975)] + [\"FAKE_GENE_\" + str(i+1) for i in range(50)]\n",
    "controls['parrish_data_original'] = [\"nt\" + str(i+1) for i in range(975)] + [\"FAKE_GENE_\" + str(i+1) for i in range(50)]\n",
    "\n",
    "# wong et al\n",
    "controls['wong_data'] = [\"DUMMYGUIDE\"]\n",
    "\n",
    "# zhao et al\n",
    "controls['zhao_data'] = [\"0\", 'CONTROL']\n",
    "\n",
    "# tang et al\n",
    "controls['shantang_data'] = ['0SAFE-SAFE-GE',\n",
    "                             '0SAFE-SAFE-SP',\n",
    "                             '0SAFE-SAFE-MP',\n",
    "                             '0SAFE-SAFE-U2',\n",
    "                             '0SAFE-SAFE-DTKP',\n",
    "                             '0SAFE-SAFE-ACOC',\n",
    "                             '0SAFE-SAFE-TMM',\n",
    "                             '0SAFE-SAFE-U1',\n",
    "                             '0SAFE-SAFE-U3']\n",
    "\n",
    "controls['najm_data'] = [\"HPRT INTRON\",\n",
    "                         \"6T\",\n",
    "                         \"EEF2\",\n",
    "                         \"CD81\"]\n",
    "\n",
    "for study in controls:\n",
    "    controls[study] = [i.upper() for i in controls[study]]# + [i for i in controls[study]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc022583",
   "metadata": {},
   "outputs": [],
   "source": [
    "## conditions\n",
    "study_conditions = {}\n",
    "\n",
    "# diehl et al\n",
    "study_conditions['diehl_data'] = [['ctrl_1',\n",
    "                                    'ctrl_2'],\n",
    "                                   ['rep_1',\n",
    "                                    'rep_2',\n",
    "                                    'rep_3']]\n",
    "\n",
    "# ctrl_1;ctrl_2;rep_1;rep_2;rep_3\n",
    "# [\"wildtype-I-CeuI\", \"wildtype-I-SceI\", \"nan\"]\n",
    "\n",
    "# horlbeck et al\n",
    "study_conditions['horlbeck_data'] = {}\n",
    "# study_conditions['horlbeck_data']['JURKAT'] = [['JURKAT_barcode,T0,rep1',\n",
    "#                                                 'JURKAT_barcode,T0,rep2'],\n",
    "#                                                ['JURKAT_barcode,cyc,rep1',\n",
    "#                                                 'JURKAT_barcode,cyc,rep2',]]\n",
    "study_conditions['horlbeck_data']['JURKAT'] = [['JURKAT_tripleseq,T0,rep1',\n",
    "                                                'JURKAT_tripleseq,T0,rep2'],\n",
    "                                               ['JURKAT_tripleseq,cyc,rep1',\n",
    "                                                'JURKAT_tripleseq,cyc,rep2',]]\n",
    "\n",
    "# study_conditions['horlbeck_data']['K562'] = [['K562_barcode,T0,rep1',\n",
    "#                                         'K562_barcode,T0,rep2'],\n",
    "#                                        ['K562_barcode,cyc,rep1',\n",
    "#                                         'K562_barcode,cyc,rep2',]]\n",
    "study_conditions['horlbeck_data']['K562'] = [['K562_barcode,T0,rep1',\n",
    "                                        'K562_barcode,T0,rep2'],\n",
    "                                       ['K562_tripleseq,cyc,rep1',\n",
    "                                        'K562_tripleseq,cyc,rep2',]]\n",
    "\n",
    "# parrish et al\n",
    "study_conditions['parrish_data'] = [[\"plasmid_1\", \n",
    "                                     \"plasmid_2\",\n",
    "                                     \"plasmid_3\"],\n",
    "                                    [\"LTP_1\",\n",
    "                                     \"LTP_2\",\n",
    "                                     \"LTP_3\"]]\n",
    "study_conditions['parrish_data_original'] = [[\"plasmid_1\", \n",
    "                                     \"plasmid_2\",\n",
    "                                     \"plasmid_3\"],\n",
    "                                    [\"LTP_1\",\n",
    "                                     \"LTP_2\",\n",
    "                                     \"LTP_3\"]]\n",
    "\n",
    "# wong et al\n",
    "study_conditions['wong_data'] = [[\"day5 (Replicate 1)\", \n",
    "                                  \"day5 (Replicate 2)\"],\n",
    "                                 [\"day20 (Replicate 1)\",\n",
    "                                  \"day20 (Replicate 2)\"]]\n",
    "\n",
    "# zhao et al\n",
    "study_conditions['zhao_data'] = {}\n",
    "study_conditions['zhao_data'][\"HELA\"] = [[\"Hela_MV4_d3_1_S1_trimmed53_len_filtered_counts\",\n",
    "                                          \"Hela_MV4_d3_2_S2_trimmed53_len_filtered_counts\"],\n",
    "                                         [\"Hela_MV4_d28_1_S5_trimmed53_len_filtered_counts\",\n",
    "                                          \"Hela_MV4_d28_2_S6_trimmed53_len_filtered_counts\"]]\n",
    "\n",
    "study_conditions['zhao_data'][\"A549\"] = [[\"A549_MV4_d3_1_S1_trimmed53_len_filtered_counts\",\n",
    "                                          \"A549_MV4_d3_2_S2_trimmed53_len_filtered_counts\"],\n",
    "                                         [\"A549_MV4_d28_1_S7_trimmed53_len_filtered_counts\",\n",
    "                                          \"A549_MV4_d28_2_S8_trimmed53_len_filtered_counts\"]]\n",
    "\n",
    "study_conditions['shantang_data'] = [[\"T0_1\", \n",
    "                                     \"T0_2\"],\n",
    "                                    [\"T12_1\",\n",
    "                                     \"T12_2\"]]\n",
    "\n",
    "study_conditions['najm_data'] = [['pDNA_Reads'],\n",
    "                                 ['Rep_A_Reads',\n",
    "                                  'Rep_B_Reads',\n",
    "                                  'Rep_C_Reads']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "577f71e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "\n",
    "# experiment design\n",
    "experiment_design = pd.read_sql_table('CDKO_EXPERIMENT_DESIGN', SLKB_engine, index_col = 'sgRNA_id')#\n",
    "experiment_design.reset_index(drop = True, inplace = True)\n",
    "experiment_design.index.rename('sgRNA_id', inplace = True)\n",
    "\n",
    "# counts\n",
    "counts = pd.read_sql_table('CDKO_SGRNA_COUNTS', SLKB_engine, index_col = 'sgRNA_pair_id')\n",
    "counts.reset_index(drop = True, inplace = True)\n",
    "counts.index.rename('sgRNA_pair_id', inplace = True)\n",
    "\n",
    "# scores\n",
    "scores = pd.read_sql_table('CDKO_ORIGINAL_SL_RESULTS', SLKB_engine, index_col = 'id')\n",
    "scores.reset_index(drop = True, inplace = True)\n",
    "scores.index.rename('gene_pair_id', inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e207b62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the tables together\n",
    "#counts = counts.merge(scores, how = 'left', left_on = 'gene_pair_id_original', right_index = True)\n",
    "counts = counts.merge(experiment_design, how = 'left', left_on = 'guide_1_id', right_index = True, suffixes = ('', '_g1'))\n",
    "counts = counts.merge(experiment_design, how = 'left', left_on = 'guide_2_id', right_index = True, suffixes = ('', '_g2'))\n",
    "# rename\n",
    "counts = counts.rename({'sgRNA_guide_name': 'sgRNA_guide_name_g1',\n",
    "                        'sgRNA_guide_seq': 'sgRNA_guide_seq_g1',\n",
    "                        'sgRNA_target_name': 'sgRNA_target_name_g1',\n",
    "                        'study_origin_x': 'study_origin',\n",
    "                        'cell_line_origin_x': 'cell_line_origin'}, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a3b1903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset is sufficient\n",
    "#counts = counts.loc[:,['guide_1_id', 'guide_2_id', 'sgRNA_guide_name_g1', 'sgRNA_guide_name_g2', 'sgRNA_target_name_g1', 'sgRNA_target_name_g2', 'T0_counts', 'T0_replicate_names', 'TEnd_counts', 'TEnd_replicate_names', 'target_type', 'study_origin', 'cell_line_origin']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c569a19c",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e340c483",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_counts(curr_counts):\n",
    "    \n",
    "    print('Getting raw counts...')\n",
    "    # get counts\n",
    "    T0_counts = curr_counts['T0_counts'].apply(    \n",
    "        lambda x: np.array(x.split(\";\"), dtype = np.float64)\n",
    "    )\n",
    "\n",
    "    T0_counts = pd.DataFrame(data = T0_counts.tolist(),\n",
    "                   index = T0_counts.index, columns = curr_counts['T0_replicate_names'].iloc[0].split(';'))\n",
    "\n",
    "    TEnd_counts = curr_counts['TEnd_counts'].apply(    \n",
    "        lambda x: np.array(x.split(\";\"), dtype = np.float64)\n",
    "    )\n",
    "\n",
    "    TEnd_counts = pd.DataFrame(data = TEnd_counts.tolist(),\n",
    "                   index = TEnd_counts.index, columns = curr_counts['TEnd_replicate_names'].iloc[0].split(';'))\n",
    "    \n",
    "    # make sure no columns are filled with NAs completely\n",
    "    NA_replicate = T0_counts.isna().sum()\n",
    "    if (NA_replicate == T0_counts.shape[0]).sum() > 0:\n",
    "        print('Removing NA replicate from T0...')\n",
    "        T0_counts.drop(NA_replicate.index[NA_replicate == T0_counts.shape[0]], axis = 1, inplace = True)\n",
    "    \n",
    "    NA_replicate = TEnd_counts.isna().sum()\n",
    "    if (NA_replicate == T0_counts.shape[0]).sum() > 0:\n",
    "        print('Removing NA replicate from TEnd...')\n",
    "        TEnd_counts.drop(NA_replicate.index[NA_replicate == TEnd_counts.shape[0]], axis = 1, inplace = True)\n",
    "\n",
    "    T0_counts = T0_counts.fillna(0)\n",
    "    TEnd_counts = TEnd_counts.fillna(0)\n",
    "    \n",
    "    return((T0_counts, TEnd_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02f355cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_counts(curr_counts, filtering_counts = 100):\n",
    "    \n",
    "    print(' '.join([\"Filtering enabled... Condition:\", str(filtering_counts), \"counts\"]))\n",
    "    \n",
    "    curr_counts[curr_counts < filtering_counts] = np.nan\n",
    "    \n",
    "    # drop the entire sgRNAs\n",
    "    curr_counts = curr_counts.dropna()    \n",
    "    \n",
    "    return(curr_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a409d5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_counts(curr_counts, set_normalization = 1e6):\n",
    "    \n",
    "    print(\"Normalization enabled...\")\n",
    "    \n",
    "    if set_normalization is not None:\n",
    "        print(\"Current counts:\")\n",
    "        print(curr_counts.sum(axis = 0))\n",
    "        \n",
    "        norm_value = set_normalization\n",
    "        print(' '.join([\"Normalize based on a specific value...\", str(set_normalization), \"counts\"]))\n",
    "    else:\n",
    "        print(\"Normalize based on sample counts... Current counts:\")\n",
    "        print(curr_counts.sum(axis = 0))\n",
    "        \n",
    "        norm_value = np.median(curr_counts.sum(axis = 0))\n",
    "        print(' '.join([\"Normalize value...\", str(norm_value), \"counts\"]))    \n",
    "    \n",
    "    filt_locations = curr_counts.isna()\n",
    "    #print(curr_counts.isna().sum())\n",
    "    \n",
    "    curr_counts = (curr_counts * norm_value) / curr_counts.sum(axis = 0)\n",
    "    curr_counts[filt_locations] = np.nan\n",
    "    \n",
    "    return(curr_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90bf3015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_pairs_and_guides(curr_counts):\n",
    "    # sort the genes and guides based on gene ordering\n",
    "    print('Sorting gene pairs and guides based on ordering gene ordering...')\n",
    "    gene_pairs = []\n",
    "    gene_pair_guides = []\n",
    "    for i in range(curr_counts.shape[0]):\n",
    "\n",
    "        guide_1 = curr_counts['sgRNA_guide_name_g1'].iloc[i]\n",
    "        guide_2 = curr_counts['sgRNA_guide_name_g2'].iloc[i]\n",
    "\n",
    "        gene_1 = curr_counts['sgRNA_target_name_g1'].iloc[i]\n",
    "        gene_2 = curr_counts['sgRNA_target_name_g2'].iloc[i]\n",
    "\n",
    "        t_gene_1, t_gene_2 = sorted([gene_1, gene_2])\n",
    "\n",
    "\n",
    "        if (t_gene_1 == gene_1) and (t_gene_2 == gene_2):\n",
    "            gene_1 = t_gene_1\n",
    "            gene_2 = t_gene_2\n",
    "        else:\n",
    "            gene_1 = t_gene_1\n",
    "            gene_2 = t_gene_2\n",
    "\n",
    "            # swap the guides accordingly\n",
    "            temp = guide_1\n",
    "            guide_1 = guide_2\n",
    "            guide_2 = temp\n",
    "\n",
    "        gene_pairs.append('|'.join([gene_1, gene_2]))\n",
    "        gene_pair_guides.append('|'.join([guide_1, guide_2]))\n",
    "\n",
    "    return(gene_pairs, gene_pair_guides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e472561d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from Horlbeck et al., https://github.com/mhorlbeck/GImap_tools/blob/601cd22126432edadb30202e952859195c73a841/GImap_analysis.py\n",
    "def quadFitForceIntercept(xdata, ydata, bdata):\n",
    "    m1 = optimize.fmin(lambda m, x, y: ((m[0]*(x**2) + m[1]*x + bdata - y)**2).sum(), x0=[0.1,0.1], args=(xdata, ydata), disp=0)\n",
    "    \n",
    "    return lambda x1: m1[0]*(np.array(x1)**2) + m1[1]*np.array(x1) + bdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64697dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_horlbeck_preprocessing(curr_counts, filterThreshold = 35, pseudocount = 10):\n",
    "        \n",
    "    T0_counts, TEnd_counts = get_raw_counts(curr_counts.copy())\n",
    "    \n",
    "    # horlbeck uses single x single as double, proceed to move them to dual instead\n",
    "    replace_idx = (curr_counts['target_type'] == 'Single') & (curr_counts['sgRNA_target_name_g1'] == curr_counts['sgRNA_target_name_g2'])\n",
    "    curr_counts.loc[replace_idx, 'target_type'] = 'Dual'\n",
    "\n",
    "    if T0_counts.shape[1] != TEnd_counts.shape[1]:\n",
    "        print(\"Mismatch times, averaging...\")\n",
    "\n",
    "        T0_counts = pd.DataFrame(data = T0_counts.apply(lambda x: np.mean(x), axis = 1).values,\n",
    "                             index = T0_counts.index)\n",
    "\n",
    "        TEnd_counts = pd.DataFrame(data = TEnd_counts.apply(lambda x: np.mean(x), axis = 1).values,\n",
    "                 index = TEnd_counts.index)\n",
    "\n",
    "    T0_counts = pd.concat([T0_counts, curr_counts['sgRNA_guide_name_g1'], curr_counts['sgRNA_guide_name_g2']], axis = 1)\n",
    "    TEnd_counts = pd.concat([TEnd_counts, curr_counts['sgRNA_guide_name_g1'], curr_counts['sgRNA_guide_name_g2']], axis = 1)\n",
    "    all_sgRNAs = set(TEnd_counts['sgRNA_guide_name_g1']).union(set(TEnd_counts['sgRNA_guide_name_g2']))\n",
    "\n",
    "    # add sorted targets\n",
    "    sorted_gene_pairs, sorted_gene_guides = sort_pairs_and_guides(curr_counts.copy())\n",
    "    curr_counts['sgRNA_pair'] = sorted_gene_guides\n",
    "    curr_counts['gene_pair'] = sorted_gene_pairs\n",
    "    \n",
    "    replicate_list = []\n",
    "    for replicate_i in range(len(T0_counts.columns)-2):\n",
    "        print(\"For replicate \" + str(replicate_i + 1))\n",
    "        meanCounts = pd.concat((TEnd_counts.iloc[:,replicate_i].groupby(TEnd_counts['sgRNA_guide_name_g1']).agg(np.median),TEnd_counts.iloc[:,replicate_i].groupby(TEnd_counts['sgRNA_guide_name_g2']).agg(np.median)),axis=1, keys=['sgRNA_guide_name_g1', 'sgRNA_guide_name_g2'])\n",
    "        sgsToFilter = set(meanCounts.loc[meanCounts.loc[:,'sgRNA_guide_name_g1'] < filterThreshold].index).union(set(meanCounts.loc[meanCounts.loc[:,'sgRNA_guide_name_g2'] < filterThreshold].index))\n",
    "        print(\" \".join([\"Total of\", str(len(sgsToFilter)), 'sgRNAs were filtered out of', str(len(all_sgRNAs))]))\n",
    "\n",
    "        chosen_idx = np.array([True if i not in sgsToFilter else False for i in TEnd_counts['sgRNA_guide_name_g1']]) & np.array([True if i not in sgsToFilter else False for i in TEnd_counts['sgRNA_guide_name_g2']])\n",
    "        TEnd_counts_curr = TEnd_counts.iloc[chosen_idx, replicate_i]\n",
    "        T0_counts_curr = T0_counts.iloc[chosen_idx, replicate_i]\n",
    "\n",
    "        counts_ratio = ((T0_counts_curr + pseudocount).sum()*1.0)/(TEnd_counts_curr + pseudocount).sum()\n",
    "\n",
    "        # calculate FC like in horlbeck\n",
    "        replicate_FC = np.log2((TEnd_counts_curr + pseudocount)/(T0_counts_curr + pseudocount)/counts_ratio)\n",
    "        replicate_FC.columns = ['Replicate_' + str(replicate_i+1) + \"_FC\"]\n",
    "        replicate_FC.name = 'Replicate_' + str(replicate_i+1) + \"_FC\"\n",
    "\n",
    "        # get control\n",
    "        control_effect = 0\n",
    "        if 'Control' in set(curr_counts['target_type']):\n",
    "            control_index = curr_counts['target_type'] == 'Control'\n",
    "            if control_index.sum() != 0:\n",
    "                control_effect = replicate_FC.loc[control_index].median()\n",
    "\n",
    "        replicate_FC -= control_effect\n",
    "\n",
    "        # doubling differences, taken from original code\n",
    "        replicate_FC /= 6.3\n",
    "\n",
    "        curr_counts = curr_counts.join(replicate_FC)\n",
    "\n",
    "        replicate_list.append(replicate_FC)\n",
    "\n",
    "    # save the results to original data\n",
    "    replicate_list = pd.concat(replicate_list, axis = 1)\n",
    "    replicate_list = replicate_list.dropna()\n",
    "\n",
    "    replicate_list = replicate_list.mean(axis = 1)\n",
    "\n",
    "    replicate_list.columns = ['FC_Averaged']\n",
    "    replicate_list.name = 'FC_Averaged'\n",
    "\n",
    "    curr_counts = curr_counts.join(replicate_list)\n",
    "\n",
    "    average_of_transpose = curr_counts.groupby('sgRNA_pair')['FC_Averaged'].apply(np.nanmean)\n",
    "    curr_counts = curr_counts.join(average_of_transpose,\n",
    "                             on = 'sgRNA_pair',\n",
    "                             rsuffix = \"_abbaAveraged\")\n",
    "    \n",
    "    return(curr_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e52ca2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_horlbeck_score(curr_counts, do_preprocessing = True):\n",
    "    \n",
    "    print('Running horlbeck score...')\n",
    "    \n",
    "    ######### preprocessing\n",
    "    \n",
    "    print('Running preprocessing...')\n",
    "\n",
    "    if do_preprocessing:\n",
    "        curr_counts = run_horlbeck_preprocessing(curr_counts)\n",
    "\n",
    "\n",
    "    #########/ preprocessing\n",
    "    \n",
    "    ######### original horlbeck scoring\n",
    "    \n",
    "    print('Started scoring')\n",
    "\n",
    "    # first, drop the rows with nan replicateFCname\n",
    "    curr_counts.dropna(subset = ['FC_Averaged_abbaAveraged'], inplace = True)\n",
    "\n",
    "    # get ab/ba\n",
    "    a_average, b_average = curr_counts.loc[curr_counts['target_type'] != 'Dual'].copy(), curr_counts.loc[curr_counts['target_type'] != 'Dual'].copy()\n",
    "    #curr_counts.loc[curr_counts['target_type'] == 'Single'].copy(), curr_counts.loc[curr_counts['target_type'] == 'Single'].copy()\n",
    "    #\n",
    "    a_average = a_average[a_average['sgRNA_target_name_g2'] == \"CONTROL\"]\n",
    "    b_average = b_average[b_average['sgRNA_target_name_g1'] == \"CONTROL\"]\n",
    "\n",
    "    a_average = a_average.groupby('sgRNA_guide_name_g1')['FC_Averaged_abbaAveraged'].apply(np.mean)\n",
    "    b_average = b_average.groupby('sgRNA_guide_name_g2')['FC_Averaged_abbaAveraged'].apply(np.mean)\n",
    "\n",
    "    # single, control, and dual phenotypes are used in calculation\n",
    "    all_pairs = set(curr_counts['sgRNA_guide_name_g1']).union(set(curr_counts['sgRNA_guide_name_g2']))\n",
    "    curr_counts['GI_Averaged'] = 0\n",
    "\n",
    "    # for missing pairs, update a_average, b_average\n",
    "    a_average_0s = list(all_pairs.difference(set(a_average.index)))\n",
    "    a_average = pd.concat([a_average, pd.Series(data = np.zeros(len(a_average_0s)), index = a_average_0s)])\n",
    "\n",
    "    b_average_0s = list(all_pairs.difference(set(b_average.index)))\n",
    "    b_average = pd.concat([b_average, pd.Series(data = np.zeros(len(b_average_0s)), index = b_average_0s)])\n",
    "\n",
    "    # store in a matrix\n",
    "    GI_Score_1 = pd.DataFrame(0, index = sorted(list(all_pairs)), columns = sorted(list(all_pairs)))\n",
    "    GI_Score_2 = pd.DataFrame(0, index = sorted(list(all_pairs)), columns = sorted(list(all_pairs)))\n",
    "\n",
    "    ## A orientation ()\n",
    "\n",
    "    ## go through all query sgRNAs\n",
    "    for query_sgRNA in all_pairs:\n",
    "\n",
    "        ## get all the pairs with the given query\n",
    "        idx_loc = (curr_counts['sgRNA_guide_name_g2'] == query_sgRNA)\n",
    "\n",
    "        if len(idx_loc) == 0:\n",
    "            continue\n",
    "\n",
    "        ## all pairs \n",
    "        curr_filtered_pairs = curr_counts.loc[idx_loc, :]\n",
    "\n",
    "        ## get sgRNAs assayed together with the query sgRNA\n",
    "        selected_sgRNAs = curr_filtered_pairs['sgRNA_guide_name_g1'].values\n",
    "\n",
    "        if 'Control' in set(curr_counts['target_type']):\n",
    "            control_sgRNAs = np.where(curr_filtered_pairs['sgRNA_target_name_g1'] == \"CONTROL\")[0]\n",
    "\n",
    "        # Fit to a quadratic formula, where the x is the single phenotypes and y is the pair phenotypes\n",
    "\n",
    "        xs = a_average.loc[selected_sgRNAs].values # a -> b\n",
    "        ys = curr_filtered_pairs['FC_Averaged_abbaAveraged'].values\n",
    "        bs = b_average.loc[query_sgRNA] # b -> a\n",
    "\n",
    "        res_fn = quadFitForceIntercept(xs, ys, bs)\n",
    "\n",
    "        # get expected\n",
    "        expected_phenotype = res_fn(xs)\n",
    "\n",
    "        # the difference is the GI score\n",
    "        GI_Score = ys - expected_phenotype\n",
    "\n",
    "        if ('Control' in set(curr_counts['target_type'])) and len(control_sgRNAs) > 0:\n",
    "            if GI_Score[control_sgRNAs].std() != 0:\n",
    "                GI_Score /= GI_Score[control_sgRNAs].std()\n",
    "\n",
    "        GI_Score_1.loc[query_sgRNA, selected_sgRNAs] = GI_Score\n",
    "\n",
    "    ## B orientation ()\n",
    "    ## go through all query sgRNAs\n",
    "    for query_sgRNA in all_pairs:\n",
    "\n",
    "        ## get all the pairs with the given query\n",
    "        idx_loc = (curr_counts['sgRNA_guide_name_g1'] == query_sgRNA)\n",
    "\n",
    "        if len(idx_loc) == 0:\n",
    "            continue\n",
    "\n",
    "        ## all pairs \n",
    "        curr_filtered_pairs = curr_counts.loc[idx_loc, :]\n",
    "\n",
    "        ## get sgRNAs assayed together with the query sgRNA\n",
    "        selected_sgRNAs = curr_filtered_pairs['sgRNA_guide_name_g2'].values\n",
    "\n",
    "        if 'Control' in set(curr_counts['target_type']):\n",
    "            control_sgRNAs = np.where(curr_filtered_pairs['sgRNA_target_name_g2'] == \"CONTROL\")[0]\n",
    "\n",
    "        # Fit to a quadratic formula, where the x is the single phenotypes and y is the pair phenotypes\n",
    "\n",
    "        xs = b_average.loc[selected_sgRNAs].values # b -> a\n",
    "        ys = curr_filtered_pairs['FC_Averaged_abbaAveraged'].values\n",
    "        bs = a_average.loc[query_sgRNA] # a -> b\n",
    "\n",
    "        res_fn = quadFitForceIntercept(xs, ys, bs)\n",
    "\n",
    "        # get expected\n",
    "        expected_phenotype = res_fn(xs)\n",
    "\n",
    "        # the difference is the GI score\n",
    "        GI_Score = ys - expected_phenotype\n",
    "\n",
    "        if ('Control' in set(curr_counts['target_type'])) and len(control_sgRNAs) > 0:\n",
    "            if GI_Score[control_sgRNAs].std() != 0:\n",
    "                GI_Score /= GI_Score[control_sgRNAs].std()\n",
    "\n",
    "        # set the \n",
    "        #curr_res['sgRNA_level']['dual'].loc[idx_loc, replicate_GI_name] += GI_Score\n",
    "        GI_Score_2.loc[query_sgRNA, selected_sgRNAs] = GI_Score\n",
    "\n",
    "\n",
    "    # average between A and B orientations\n",
    "    #curr_res['sgRNA_level']['dual'][replicate_GI_name] /= 2\n",
    "    GI_Score_avg = (GI_Score_1 + GI_Score_2)/2\n",
    "    GI_Score_avg = (GI_Score_avg + GI_Score_avg.T)/2\n",
    "\n",
    "    for i in range(len(curr_counts['GI_Averaged'])):\n",
    "        guide_1 = curr_counts['sgRNA_guide_name_g1'].iloc[i]\n",
    "        guide_2 = curr_counts['sgRNA_guide_name_g2'].iloc[i]\n",
    "\n",
    "        curr_counts['GI_Averaged'].iloc[i] = GI_Score_avg.loc[guide_1, guide_2]\n",
    "\n",
    "    \n",
    "    ######### /original horlbeck scoring\n",
    "    \n",
    "    \n",
    "    # store results\n",
    "    SL_score = curr_counts.groupby('gene_pair')['GI_Averaged'].apply(lambda x: np.mean(x))\n",
    "    SE = curr_counts.groupby('gene_pair')['GI_Averaged'].apply(lambda x: sem(x, ddof=1))\n",
    "\n",
    "    genes_1 = [i.split('|')[0] for i in SL_score.index]\n",
    "    genes_2 = [i.split('|')[1] for i in SL_score.index]\n",
    "\n",
    "    horlbeck_results = pd.DataFrame(data = {'SL_score' : SL_score.values,\n",
    "                                             'standard_error' : SE.values,\n",
    "                                             'Gene 1' : genes_1,\n",
    "                                             'Gene 2' : genes_2}, index = SL_score.index)\n",
    "    \n",
    "    \n",
    "    # remove possible controls\n",
    "    control_idx = np.array([True if 'CONTROL' in i else False for i in horlbeck_results.index])\n",
    "    horlbeck_results = horlbeck_results.loc[~control_idx]\n",
    "    \n",
    "    results = {}\n",
    "    results['HORLBECK_SCORE'] = horlbeck_results\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d08bc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_median_scores(curr_counts, full_normalization = False):\n",
    "\n",
    "    # for standard error\n",
    "    median_SE_constant = 1.25\n",
    "    \n",
    "    print('Running median scores...')\n",
    "    \n",
    "    ######### preprocessing\n",
    "    t_0_comb, t_end_comb = get_raw_counts(curr_counts)\n",
    "    \n",
    "    # filter counts, only at T0\n",
    "    t_0_comb = filter_counts(t_0_comb, filtering_counts = 35)\n",
    "    print(' '.join(['Filtered a total of', str(t_end_comb.shape[0] - t_0_comb.shape[0]), \"out of\", str(t_end_comb.shape[0]), \"sgRNAs.\"]))\n",
    "    print(\"\\n---\\n\")\n",
    "        \n",
    "    # add pseudocount of 10 after filtering\n",
    "    t_0_comb = t_0_comb + 10\n",
    "    t_end_comb = t_end_comb + 10\n",
    "    \n",
    "    # some sgRNAs were filtered out\n",
    "    overlapping_sgRNAs = sorted(list(set(t_0_comb.index).intersection(set(t_end_comb.index))))\n",
    "    \n",
    "    t_0_comb = t_0_comb.loc[overlapping_sgRNAs,:]\n",
    "    t_end_comb = t_end_comb.loc[overlapping_sgRNAs,:]\n",
    "    curr_counts = curr_counts.loc[overlapping_sgRNAs,:]\n",
    "        \n",
    "    # normalize to the median of the all time points\n",
    "    if full_normalization:\n",
    "        print('Full normalization...')\n",
    "        normalization_value = np.median(pd.concat([t_0_comb, t_end_comb], axis = 1).sum(axis = 0))\n",
    "\n",
    "        t_0_comb = normalize_counts(t_0_comb, set_normalization = normalization_value)\n",
    "        t_end_comb = normalize_counts(t_end_comb, set_normalization = normalization_value)\n",
    "        \n",
    "    else:\n",
    "        print('Not full normalization...')\n",
    "        for subset in set(curr_counts['target_type']):\n",
    "            idx = curr_counts.loc[curr_counts['target_type'] == subset,:].index\n",
    "\n",
    "            # normalize to the median of the all time points\n",
    "            normalization_value = np.median(pd.concat([t_0_comb.loc[idx,:], t_end_comb.loc[idx,:]], axis = 1).sum(axis = 0))\n",
    "\n",
    "            t_0_comb.loc[idx,:] = normalize_counts(t_0_comb.loc[idx,:], set_normalization = normalization_value)\n",
    "            t_end_comb.loc[idx,:] = normalize_counts(t_end_comb.loc[idx,:], set_normalization = normalization_value)\n",
    "\n",
    "\n",
    "    \n",
    "    # get median of counts \n",
    "    t_0_comb = t_0_comb.apply(lambda x: np.median(x), axis = 1)\n",
    "    t_end_comb = t_end_comb.apply(lambda x: np.median(x), axis = 1)\n",
    "\n",
    "    # get LFC\n",
    "    FC = np.log2(t_end_comb) - np.log2(t_0_comb)\n",
    "    \n",
    "    # set FC\n",
    "    curr_counts['FC'] = FC\n",
    "    \n",
    "    # add sorted targets\n",
    "    sorted_gene_pairs, sorted_gene_guides = sort_pairs_and_guides(curr_counts.copy())\n",
    "    curr_counts['sgRNA_pair'] = sorted_gene_guides\n",
    "    curr_counts['gene_pair'] = sorted_gene_pairs\n",
    "    \n",
    "    ######### /preprocessing\n",
    "    \n",
    "    # store results\n",
    "    results = {}\n",
    "    results['MEDIAN_B_SCORE'] = None\n",
    "    results['MEDIAN_NB_SCORE'] = None\n",
    "    \n",
    "    ######### scoring\n",
    "    \n",
    "    # get the three target categories\n",
    "    single = curr_counts.loc[curr_counts['target_type'] == 'Single']\n",
    "    dual = curr_counts.loc[curr_counts['target_type'] == 'Dual']\n",
    "    control = curr_counts.loc[curr_counts['target_type'] == 'Control']\n",
    "    \n",
    "    print('Available singles: ' + str(single.shape[0]))\n",
    "    print('Available duals: ' + str(dual.shape[0]))\n",
    "    print('Available control: ' + str(control.shape[0]))\n",
    "    \n",
    "    temp_repeat = single.copy()\n",
    "    temp_repeat['sgRNA_guide_name_g1'] = single[\"sgRNA_guide_name_g2\"]\n",
    "    temp_repeat['sgRNA_target_name_g1'] = single[\"sgRNA_target_name_g2\"]\n",
    "    temp_repeat['sgRNA_guide_name_g2'] = single[\"sgRNA_guide_name_g1\"]\n",
    "    temp_repeat['sgRNA_target_name_g1'] = single[\"sgRNA_target_name_g2\"]\n",
    "    \n",
    "    single_repeat = pd.concat([single, temp_repeat])\n",
    "\n",
    "    # get single sgRNA impact\n",
    "    EC_single = single_repeat.groupby(\"sgRNA_guide_name_g1\")['FC'].apply(\n",
    "            lambda x: np.median(x))\n",
    "    \n",
    "    # get control sgRNA impact\n",
    "    EC_control = None\n",
    "    if control.shape[0] != 0:\n",
    "\n",
    "        temp_repeat = control.copy()\n",
    "        temp_repeat['sgRNA_guide_name_g1'] = control[\"sgRNA_guide_name_g2\"]\n",
    "        temp_repeat['sgRNA_guide_name_g2'] = control[\"sgRNA_guide_name_g1\"]\n",
    "\n",
    "        EC_control = pd.concat([control, temp_repeat]).groupby(\"sgRNA_guide_name_g1\")['FC'].apply(\n",
    "            lambda x: np.median(x)\n",
    "        )\n",
    "\n",
    "        EC_single = EC_single.drop(set(EC_control.index).intersection(set(EC_single.index)))\n",
    "    \n",
    "    # all available dual sgRNAs\n",
    "    all_pairs = set(dual['sgRNA_guide_name_g1']).union(set(dual['sgRNA_guide_name_g2']))\n",
    "    \n",
    "    # fill for empty\n",
    "    missing_pairs = np.array(list(all_pairs.difference(set(EC_single.index))))\n",
    "\n",
    "    print(' '.join([\"Filtered single sgRNA count:\", str(len(set(missing_pairs)))]))\n",
    "    \n",
    "    # add them as 0s\n",
    "    EC_single = pd.concat([EC_single, pd.Series(index = missing_pairs, data = np.zeros(len(missing_pairs)))])\n",
    "    \n",
    "    # get EC for each\n",
    "    EC_1 = EC_single[dual['sgRNA_guide_name_g1']]\n",
    "    EC_2 = EC_single[dual['sgRNA_guide_name_g2']]\n",
    "    \n",
    "    # calculate Impact Scores (sgRNA level)\n",
    "\n",
    "    dual['Median-NB-dual-IS'] = dual['FC'].values\n",
    "    dual['Median-NB-single-IS-Guide-1'] = EC_1.values\n",
    "    dual['Median-NB-single-IS-Guide-2'] = EC_2.values\n",
    "    dual['Median-NB-dual-SL-sgRNA'] = dual['FC'].values - EC_1.values - EC_2.values\n",
    "    \n",
    "    ## calculate SL scores (sgRNA)\n",
    "    gene_pair_SL = dual.groupby('gene_pair')['Median-NB-dual-IS'].apply(lambda x: np.median(x))\n",
    "    gene_pair_SE = dual.groupby('gene_pair')['Median-NB-dual-IS'].apply(lambda x: np.var(x) / np.size(x))\n",
    "    \n",
    "    ## calculate SL scores (gene)\n",
    "    gene_SL = single_repeat.groupby(\"sgRNA_target_name_g1\")['FC'].apply(\n",
    "    lambda x: np.median(x))\n",
    "    gene_SE = single_repeat.groupby(\"sgRNA_target_name_g1\")['FC'].apply(\n",
    "        lambda x: np.var(x) / np.size(x))\n",
    "\n",
    "    genes_1 = np.array([i.split('|')[0] for i in gene_pair_SL.index])\n",
    "    genes_2 = np.array([i.split('|')[1] for i in gene_pair_SL.index])\n",
    "\n",
    "    all_genes = set(genes_1).union(set(genes_2))\n",
    "    missing_genes = all_genes.difference(set(gene_SL.index))\n",
    "    print(' '.join([\"Filtered gene count:\", str(len(set(missing_genes)))]))\n",
    "\n",
    "    # add them as 0s\n",
    "    gene_SL = pd.concat([gene_SL, pd.Series(index = missing_genes, data = np.zeros(len(missing_genes)))])\n",
    "    gene_SE = pd.concat([gene_SE, pd.Series(index = missing_genes, data = np.zeros(len(missing_genes)))])\n",
    "\n",
    "    median_nb_SL = gene_pair_SL.values - gene_SL[genes_1].values - gene_SL[genes_2].values\n",
    "    median_nb_SE = np.sqrt(gene_pair_SE.values + gene_SE[genes_1].values + gene_SE[genes_2].values) * median_SE_constant\n",
    "    median_nb_Z = median_nb_SL/median_nb_SE\n",
    "\n",
    "    median_nb_results = pd.DataFrame(data = {'SL_score' : median_nb_SL,\n",
    "                                             'standard_error' : median_nb_SE,\n",
    "                                             'Z_SL_score' : median_nb_Z,\n",
    "                                             'Gene 1' : genes_1,\n",
    "                                             'Gene 2' : genes_2}, index = gene_pair_SL.index)\n",
    "    \n",
    "    results['MEDIAN_NB_SCORE'] = median_nb_results\n",
    "    \n",
    "    if EC_control is not None:\n",
    "        control_median = np.median(EC_control)\n",
    "\n",
    "        dual['Median-B-dual-IS'] = dual['FC'].values - control_median\n",
    "        dual['Median-B-single-IS-Guide-1'] = EC_1.values - control_median\n",
    "        dual['Median-B-single-IS-Guide-2'] = EC_2.values - control_median\n",
    "        dual['Median-B-dual-SL-sgRNA'] = (dual['FC'].values - control_median) - (EC_1.values - control_median) - (EC_2.values - control_median)\n",
    "\n",
    "        ## calculate SL scores (sgRNA)\n",
    "        gene_pair_SL = dual.groupby('gene_pair')['Median-B-dual-IS'].apply(lambda x: np.median(x))\n",
    "        gene_pair_SE = dual.groupby('gene_pair')['Median-B-dual-IS'].apply(lambda x: np.var(x) / np.size(x))\n",
    "\n",
    "        # remove controls first\n",
    "        single_repeat['FC'] = single_repeat['FC'] - control_median\n",
    "        ## calculate SL scores (gene)\n",
    "        gene_SL = single_repeat.groupby(\"sgRNA_target_name_g1\")['FC'].apply(\n",
    "        lambda x: np.median(x))\n",
    "        gene_SE = single_repeat.groupby(\"sgRNA_target_name_g1\")['FC'].apply(\n",
    "            lambda x: np.var(x) / np.size(x))\n",
    "\n",
    "        genes_1 = np.array([i.split('|')[0] for i in gene_pair_SL.index])\n",
    "        genes_2 = np.array([i.split('|')[1] for i in gene_pair_SL.index])\n",
    "\n",
    "        all_genes = set(genes_1).union(set(genes_2))\n",
    "        missing_genes = all_genes.difference(set(gene_SL.index))\n",
    "        print(' '.join([\"Filtered gene count:\", str(len(set(missing_genes)))]))\n",
    "\n",
    "        # add them as 0s\n",
    "        gene_SL = pd.concat([gene_SL, pd.Series(index = missing_genes, data = np.zeros(len(missing_genes)))])\n",
    "        gene_SE = pd.concat([gene_SE, pd.Series(index = missing_genes, data = np.zeros(len(missing_genes)))])\n",
    "\n",
    "        median_b_SL = gene_pair_SL.values - gene_SL[genes_1].values - gene_SL[genes_2].values\n",
    "        median_b_SE = np.sqrt(gene_pair_SE.values + gene_SE[genes_1].values + gene_SE[genes_2].values) * median_SE_constant\n",
    "        median_b_Z = median_b_SL/median_b_SE\n",
    "\n",
    "        median_b_results = pd.DataFrame(data = {'SL_score' : median_b_SL,\n",
    "                                                 'standard_error' : median_b_SE,\n",
    "                                                 'Z_SL_score' : median_b_Z,\n",
    "                                                 'Gene 1' : genes_1,\n",
    "                                                 'Gene 2' : genes_2}, index = gene_pair_SL.index)\n",
    "        \n",
    "        results['MEDIAN_B_SCORE'] = median_b_results\n",
    "    \n",
    "    ######### /scoring\n",
    "    \n",
    "    \n",
    "    # return computed scores\n",
    "    return(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ffcf6d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sgrna_scores(curr_counts, full_normalization = False):\n",
    "        \n",
    "    # for standard error\n",
    "    median_SE_constant = 1.25\n",
    "\n",
    "    print('Running sgrna derived score...')\n",
    "\n",
    "    ######### preprocessing\n",
    "    t_0_comb, t_end_comb = get_raw_counts(curr_counts)\n",
    "    \n",
    "    # filter counts, only at T0\n",
    "    t_0_comb = filter_counts(t_0_comb, filtering_counts = 35)\n",
    "    print(' '.join(['Filtered a total of', str(t_end_comb.shape[0] - t_0_comb.shape[0]), \"out of\", str(t_end_comb.shape[0]), \"sgRNAs.\"]))\n",
    "    print(\"\\n---\\n\")\n",
    "        \n",
    "    # add pseudocount of 10 after filtering\n",
    "    t_0_comb = t_0_comb + 10\n",
    "    t_end_comb = t_end_comb + 10\n",
    "    \n",
    "    # some sgRNAs were filtered out\n",
    "    overlapping_sgRNAs = sorted(list(set(t_0_comb.index).intersection(set(t_end_comb.index))))\n",
    "    \n",
    "    t_0_comb = t_0_comb.loc[overlapping_sgRNAs,:]\n",
    "    t_end_comb = t_end_comb.loc[overlapping_sgRNAs,:]\n",
    "    curr_counts = curr_counts.loc[overlapping_sgRNAs,:]\n",
    "    \n",
    "    if full_normalization:\n",
    "        print('Full normalization...')\n",
    "        \n",
    "        # normalize to the median of the all time points\n",
    "        normalization_value = np.median(pd.concat([t_0_comb, t_end_comb], axis = 1).sum(axis = 0))\n",
    "\n",
    "        t_0_comb = normalize_counts(t_0_comb, set_normalization = normalization_value)\n",
    "        t_end_comb = normalize_counts(t_end_comb, set_normalization = normalization_value)\n",
    "        \n",
    "    else:\n",
    "        print('Not full normalization...')\n",
    "    \n",
    "        for subset in set(curr_counts['target_type']):\n",
    "            idx = curr_counts.loc[curr_counts['target_type'] == subset,:].index\n",
    "\n",
    "            # normalize to the median of the all time points\n",
    "            normalization_value = np.median(pd.concat([t_0_comb.loc[idx,:], t_end_comb.loc[idx,:]], axis = 1).sum(axis = 0))\n",
    "\n",
    "            t_0_comb.loc[idx,:] = normalize_counts(t_0_comb.loc[idx,:], set_normalization = normalization_value)\n",
    "            t_end_comb.loc[idx,:] = normalize_counts(t_end_comb.loc[idx,:], set_normalization = normalization_value)\n",
    "    \n",
    "    # if mismatch, average\n",
    "    if t_0_comb.shape[1] != t_end_comb.shape[1]:\n",
    "        print(\"Mismatch times, averaging...\")\n",
    "        t_0_comb = pd.DataFrame(data = t_0_comb.apply(lambda x: np.mean(x), axis = 1).values,\n",
    "                     index = t_0_comb.index)\n",
    "        t_end_comb = pd.DataFrame(data = t_end_comb.apply(lambda x: np.mean(x), axis = 1).values,\n",
    "             index = t_end_comb.index)\n",
    "    \n",
    "    # set FC\n",
    "    curr_counts['FC'] = 0\n",
    "    \n",
    "    # add NOT sorted targets\n",
    "#     curr_counts['sgRNA_pair'] = ['|'.join(sorted([curr_counts['sgRNA_guide_name_g1'].iloc[i], curr_counts['sgRNA_guide_name_g2'].iloc[i]])) for i in range(curr_counts.shape[0])]\n",
    "#     curr_counts['gene_pair'] = ['|'.join(sorted([curr_counts['sgRNA_target_name_g1'].iloc[i], curr_counts['sgRNA_target_name_g2'].iloc[i]])) for i in range(curr_counts.shape[0])]\n",
    "    \n",
    "    # add sorted targets\n",
    "    sorted_gene_pairs, sorted_gene_guides = sort_pairs_and_guides(curr_counts.copy())\n",
    "    curr_counts['sgRNA_pair'] = sorted_gene_guides\n",
    "    curr_counts['gene_pair'] = sorted_gene_pairs\n",
    "    \n",
    "    # get count annotations\n",
    "    count_annotations = curr_counts.loc[:,['sgRNA_guide_name_g1', 'sgRNA_guide_name_g2', 'sgRNA_target_name_g1', 'sgRNA_target_name_g2', 'target_type', 'sgRNA_pair', 'gene_pair']].copy()\n",
    "\n",
    "    \n",
    "    ######### /preprocessing\n",
    "    \n",
    "    print('Starting scoring..')\n",
    "    \n",
    "    replicate_results = []\n",
    "    for i in range(t_0_comb.shape[1]):\n",
    "        print('calculating for replicate ' + str(i))\n",
    "\n",
    "        replicate_fc = pd.DataFrame(data = np.log2(t_end_comb.iloc[:, i]/t_0_comb.iloc[:, i]).values,\n",
    "                                    index = t_end_comb.index,\n",
    "                                    columns = ['FC'])\n",
    "\n",
    "        # merge\n",
    "        replicate_fc = replicate_fc.merge(count_annotations, left_index = True, right_index = True)\n",
    "\n",
    "        # get the three target categories\n",
    "        single = replicate_fc.loc[curr_counts['target_type'] == 'Single']\n",
    "        dual = replicate_fc.loc[curr_counts['target_type'] == 'Dual']\n",
    "        control = replicate_fc.loc[curr_counts['target_type'] == 'Control']\n",
    "\n",
    "        ## proceed with GI calculation\n",
    "        temp_repeat = single.copy()\n",
    "        temp_repeat['sgRNA_guide_name_g1'] = single[\"sgRNA_guide_name_g2\"]\n",
    "        temp_repeat['sgRNA_target_name_g1'] = single[\"sgRNA_target_name_g2\"]\n",
    "        temp_repeat['sgRNA_guide_name_g2'] = single[\"sgRNA_guide_name_g1\"]\n",
    "        temp_repeat['sgRNA_target_name_g1'] = single[\"sgRNA_target_name_g2\"]\n",
    "\n",
    "        single_repeat = pd.concat([single, temp_repeat])\n",
    "\n",
    "        # get single sgRNA impact\n",
    "        EC_single = single_repeat.groupby(\"sgRNA_guide_name_g1\")['FC'].apply(\n",
    "                lambda x: np.median(x))\n",
    "        sgRNA_SE = single_repeat.groupby(\"sgRNA_guide_name_g1\")['FC'].apply(\n",
    "            lambda x: median_SE_constant * np.sqrt(np.var(x) / np.size(x)))\n",
    "\n",
    "\n",
    "        EC_control = None\n",
    "        if control.shape[0] != 0:# and (study != 'parrish_data')\n",
    "\n",
    "            temp_repeat = control.copy()\n",
    "            temp_repeat['sgRNA_guide_name_g1'] = control[\"sgRNA_guide_name_g2\"]\n",
    "            temp_repeat['sgRNA_guide_name_g2'] = control[\"sgRNA_guide_name_g1\"]\n",
    "\n",
    "            EC_control = np.median(pd.concat([control, temp_repeat])['FC'])\n",
    "\n",
    "        ## get all pairs\n",
    "        all_pairs = set(dual['sgRNA_guide_name_g1']).union(set(dual['sgRNA_guide_name_g2']))\n",
    "\n",
    "        missing_pairs = np.array(list(all_pairs.difference(set(EC_single.index))))\n",
    "\n",
    "        print(' '.join([\"Filtered single sgRNA count:\", str(len(set(missing_pairs)))]))\n",
    "\n",
    "        # add them as 0s\n",
    "\n",
    "        EC_single = pd.concat([EC_single, pd.Series(index = missing_pairs, data = np.zeros(len(missing_pairs)))])\n",
    "        sgRNA_SE = pd.concat([sgRNA_SE, pd.Series(index = missing_pairs, data = np.zeros(len(missing_pairs)))])\n",
    "\n",
    "        sgRNA_level_scores = dual.groupby(['gene_pair', 'sgRNA_pair'], as_index = False)['FC'].apply(lambda x: np.mean(x))\n",
    "        sgRNA_level_SE = dual.groupby(['gene_pair', 'sgRNA_pair'], as_index = False)['FC'].apply(lambda x: np.sqrt(np.var(x) / np.size(x)))\n",
    "\n",
    "        guide_1 = np.array([i.split('|')[0] for i in sgRNA_level_scores['sgRNA_pair']])\n",
    "        guide_2 = np.array([i.split('|')[1] for i in sgRNA_level_scores['sgRNA_pair']])\n",
    "        EC_1 = EC_single[guide_1]\n",
    "        EC_2 = EC_single[guide_2]\n",
    "\n",
    "        SE_1 = sgRNA_SE[guide_1]\n",
    "        SE_2 = sgRNA_SE[guide_2]\n",
    "\n",
    "        sgRNA_level_scores['SL'] = sgRNA_level_scores['FC'].values - EC_1.values - EC_2.values\n",
    "        sgRNA_level_scores['SE'] = np.sqrt(np.square(sgRNA_level_SE['FC'].values) + np.square(SE_1.values) + np.square(SE_2.values))\n",
    "        sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'].isna()] = 1\n",
    "        sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'] == 0] = 1\n",
    "        sgRNA_level_scores['Z-Score'] = sgRNA_level_scores['SL'].values/sgRNA_level_scores['SE'].values\n",
    "\n",
    "        gene_SL_scores_nobackground = sgRNA_level_scores.groupby('gene_pair')['Z-Score'].apply(lambda x: np.median(x))\n",
    "        gene_SL_scores_SE = sgRNA_level_scores.groupby('gene_pair')['Z-Score'].apply(lambda x:  median_SE_constant * np.sqrt(np.var(x) / np.size(x)))\n",
    "        gene_SL_scores_SE.loc[gene_SL_scores_SE.isna()] = 1\n",
    "        gene_SL_scores_SE.loc[gene_SL_scores_SE == 0] = 1\n",
    "        gene_SL_scores_nobackground_Z = gene_SL_scores_nobackground/gene_SL_scores_SE\n",
    "\n",
    "        results_nb = pd.concat([gene_SL_scores_nobackground, gene_SL_scores_SE, gene_SL_scores_nobackground_Z], axis = 1)\n",
    "        results_nb.columns = ['sgRNA-Score-NB_' + str(i), 'sgRNA-Score-NB SE_' + str(i), 'sgRNA-Score-NB SL_' + str(i)]\n",
    "\n",
    "        replicate_results.append(results_nb)\n",
    "\n",
    "        if EC_control is not None:\n",
    "\n",
    "            single['FC'] = single['FC'] - EC_control\n",
    "            dual['FC'] = dual['FC'] - EC_control\n",
    "\n",
    "            ## proceed with GI calculation\n",
    "            temp_repeat = single.copy()\n",
    "            temp_repeat['sgRNA_guide_name_g1'] = single[\"sgRNA_guide_name_g2\"]\n",
    "            temp_repeat['sgRNA_target_name_g1'] = single[\"sgRNA_target_name_g2\"]\n",
    "            temp_repeat['sgRNA_guide_name_g2'] = single[\"sgRNA_guide_name_g1\"]\n",
    "            temp_repeat['sgRNA_target_name_g1'] = single[\"sgRNA_target_name_g2\"]\n",
    "\n",
    "            single_repeat = pd.concat([single, temp_repeat])\n",
    "\n",
    "            # get single sgRNA impact\n",
    "            EC_single = single_repeat.groupby(\"sgRNA_guide_name_g1\")['FC'].apply(\n",
    "                    lambda x: np.median(x))\n",
    "            sgRNA_SE = single_repeat.groupby(\"sgRNA_guide_name_g1\")['FC'].apply(\n",
    "                lambda x: median_SE_constant * np.sqrt(np.var(x) / np.size(x)))\n",
    "\n",
    "\n",
    "            EC_control = None\n",
    "            if control.shape[0] != 0:# and (study != 'parrish_data')\n",
    "\n",
    "                temp_repeat = control.copy()\n",
    "                temp_repeat['sgRNA_guide_name_g1'] = control[\"sgRNA_guide_name_g2\"]\n",
    "                temp_repeat['sgRNA_guide_name_g2'] = control[\"sgRNA_guide_name_g1\"]\n",
    "\n",
    "                EC_control = np.median(pd.concat([control, temp_repeat])['FC'])\n",
    "\n",
    "            ## get all pairs\n",
    "            all_pairs = set(dual['sgRNA_guide_name_g1']).union(set(dual['sgRNA_guide_name_g2']))\n",
    "\n",
    "            missing_pairs = np.array(list(all_pairs.difference(set(EC_single.index))))\n",
    "\n",
    "            print(' '.join([\"Filtered single sgRNA count:\", str(len(set(missing_pairs)))]))\n",
    "\n",
    "            # add them as 0s\n",
    "\n",
    "            EC_single = pd.concat([EC_single, pd.Series(index = missing_pairs, data = np.zeros(len(missing_pairs)))])\n",
    "            sgRNA_SE = pd.concat([sgRNA_SE, pd.Series(index = missing_pairs, data = np.zeros(len(missing_pairs)))])\n",
    "\n",
    "            sgRNA_level_scores = dual.groupby(['gene_pair', 'sgRNA_pair'], as_index = False)['FC'].apply(lambda x: np.mean(x))\n",
    "            sgRNA_level_SE = dual.groupby(['gene_pair', 'sgRNA_pair'], as_index = False)['FC'].apply(lambda x: np.sqrt(np.var(x) / np.size(x)))\n",
    "\n",
    "            guide_1 = np.array([i.split('|')[0] for i in sgRNA_level_scores['sgRNA_pair']])\n",
    "            guide_2 = np.array([i.split('|')[1] for i in sgRNA_level_scores['sgRNA_pair']])\n",
    "            EC_1 = EC_single[guide_1]\n",
    "            EC_2 = EC_single[guide_2]\n",
    "\n",
    "            SE_1 = sgRNA_SE[guide_1]\n",
    "            SE_2 = sgRNA_SE[guide_2]\n",
    "\n",
    "            sgRNA_level_scores['SL'] = sgRNA_level_scores['FC'].values - EC_1.values - EC_2.values\n",
    "            sgRNA_level_scores['SE'] = np.sqrt(np.square(sgRNA_level_SE['FC'].values) + np.square(SE_1.values) + np.square(SE_2.values))\n",
    "            sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'].isna()] = 1\n",
    "            sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'] == 0] = 1\n",
    "            sgRNA_level_scores['Z-Score'] = sgRNA_level_scores['SL'].values/sgRNA_level_scores['SE'].values\n",
    "\n",
    "            gene_SL_scores_w_background = sgRNA_level_scores.groupby('gene_pair')['Z-Score'].apply(lambda x: np.median(x))\n",
    "            gene_SL_scores_SE = sgRNA_level_scores.groupby('gene_pair')['Z-Score'].apply(lambda x:  median_SE_constant * np.sqrt(np.var(x) / np.size(x)))\n",
    "            gene_SL_scores_SE.loc[gene_SL_scores_SE.isna()] = 1\n",
    "            gene_SL_scores_SE.loc[gene_SL_scores_SE == 0] = 1\n",
    "            gene_SL_scores_w_background_Z = gene_SL_scores_w_background/gene_SL_scores_SE\n",
    "\n",
    "\n",
    "            results_b = pd.concat([gene_SL_scores_w_background, gene_SL_scores_SE, gene_SL_scores_w_background_Z], axis = 1)\n",
    "            results_b.columns = ['sgRNA-Score-B_' + str(i), 'sgRNA-Score-B SE_' + str(i), 'sgRNA-Score-B SL_' + str(i)]\n",
    "\n",
    "            replicate_results.append(results_b)\n",
    "\n",
    "    # save results\n",
    "    results = {}\n",
    "    results['SGRA_DERIVED_NB_SCORE'] = None\n",
    "    results['SGRA_DERIVED_B_SCORE'] = None\n",
    "\n",
    "    merged = pd.concat(replicate_results, axis = 1)\n",
    "    \n",
    "    # sort the names\n",
    "    merged.index = ['|'.join(sorted(i.split('|'))) for i in merged .index]\n",
    "\n",
    "    merged['sgRNA-Score_Average_NB'] = merged.loc[:,['sgRNA-Score-NB SL_' + str(i) for i in range(t_end_comb.shape[1])]].mean(axis = 1)\n",
    "    results['SGRA_DERIVED_NB_SCORE'] = pd.DataFrame(merged['sgRNA-Score_Average_NB'])\n",
    "    results['SGRA_DERIVED_NB_SCORE'].columns = ['SL_score']\n",
    "    results['SGRA_DERIVED_NB_SCORE']['Gene 1'] = [i.split('|')[0] for i in results['SGRA_DERIVED_NB_SCORE'].index]\n",
    "    results['SGRA_DERIVED_NB_SCORE']['Gene 2'] = [i.split('|')[1] for i in results['SGRA_DERIVED_NB_SCORE'].index]\n",
    "\n",
    "    if 'sgRNA-Score-B_0' in merged.columns:\n",
    "        merged['sgRNA-Score_Average_B'] = merged.loc[:,['sgRNA-Score-B SL_' + str(i) for i in range(t_end_comb.shape[1])]].mean(axis = 1)\n",
    "        results['SGRA_DERIVED_B_SCORE'] = pd.DataFrame(merged['sgRNA-Score_Average_B'])\n",
    "        results['SGRA_DERIVED_B_SCORE'].columns = ['SL_score']\n",
    "        results['SGRA_DERIVED_B_SCORE']['Gene 1'] = [i.split('|')[0] for i in results['SGRA_DERIVED_B_SCORE'].index]\n",
    "        results['SGRA_DERIVED_B_SCORE']['Gene 2'] = [i.split('|')[1] for i in results['SGRA_DERIVED_B_SCORE'].index]\n",
    "\n",
    "    return(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb58f2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_fp_and_list(command, cmd_list, fp):\n",
    "    # write, and add to list\n",
    "    fp.write(command + '\\n')\n",
    "    cmd_list.append(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ecbf5dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mageck_score(curr_counts, curr_study, curr_cl, save_dir = 'MAGECK_Files'):\n",
    "\n",
    "    print('Running mageck score...')\n",
    "\n",
    "    # !no preprocessing!\n",
    "    T0_counts, TEnd_counts = get_raw_counts(curr_counts)\n",
    "\n",
    "    # due to mageck, don't have any comma on columns\n",
    "    T0_counts.columns = ['T0_' + str(i) for i in range(T0_counts.shape[1])]\n",
    "    TEnd_counts.columns = ['TEnd_' + str(i) for i in range(TEnd_counts.shape[1])]\n",
    "\n",
    "    # get the annotations\n",
    "    curr_counts['sgRNA_pair'] = ['|'.join([curr_counts['sgRNA_guide_name_g1'].iloc[i], curr_counts['sgRNA_guide_name_g2'].iloc[i]]) for i in range(curr_counts.shape[0])]\n",
    "    curr_counts['gene_pair'] = ['|'.join([curr_counts['sgRNA_target_name_g1'].iloc[i], curr_counts['sgRNA_target_name_g2'].iloc[i]]) for i in range(curr_counts.shape[0])]\n",
    "\n",
    "    curr_counts['sgRNA_pair_mageck_id'] = curr_counts['sgRNA_pair'].values + \"|\" + np.array(range(curr_counts.shape[0]), dtype = str)\n",
    "\n",
    "    # combine them\n",
    "    comb = pd.concat([curr_counts.loc[:, ['sgRNA_pair_mageck_id', 'gene_pair']], T0_counts, TEnd_counts], axis = 1)\n",
    "    comb = comb.fillna(0)\n",
    "\n",
    "    ######### save\n",
    "\n",
    "    # get save location \n",
    "    save_loc = os.path.join(os.getcwd(), save_dir, curr_study, curr_cl)\n",
    "    os.makedirs(save_loc, exist_ok = True)\n",
    "\n",
    "    # save the counts\n",
    "    comb.to_csv(os.path.join(save_loc, \"counts.csv\"), sep = ',', index = False)\n",
    "\n",
    "    ######### /save\n",
    "\n",
    "    ######### create script and run\n",
    "\n",
    "    file_loc = os.path.join(save_loc, 'MAGECK_commands.sh')\n",
    "    control_loc = '../../../controls.txt'\n",
    "\n",
    "    fp = open(file_loc, '+w')\n",
    "\n",
    "    cmd_list = []\n",
    "\n",
    "    add_to_fp_and_list(\"#!/bin/sh\", cmd_list, fp)\n",
    "    add_to_fp_and_list(\"module load python/3.9-2022.05\", cmd_list, fp)\n",
    "    add_to_fp_and_list(\"source activate cnn_training\", cmd_list, fp)\n",
    "\n",
    "    # get index of last time point columns\n",
    "\n",
    "    t_end_col_locs = []\n",
    "    for i in range(comb.shape[1]):\n",
    "        if comb.columns[i] in TEnd_counts.columns:\n",
    "            t_end_col_locs.append(str(i-2))\n",
    "\n",
    "    add_to_fp_and_list(\"cd \\\"\" + os.path.join(os.getcwd(), save_loc) + \"\\\"\", cmd_list, fp)\n",
    "\n",
    "    command = \"mageck test -k counts.csv -t \\\"\" + ','.join(t_end_col_locs) + \"\\\" --normcounts-to-file -n out --pdf-report\"\n",
    "    if 'Control' in set(curr_counts['target_type']):\n",
    "        command = \"mageck test -k counts.csv -t \\\"\" + ','.join(t_end_col_locs) + \"\\\" --norm-method control --control-gene \" + control_loc + \" --normcounts-to-file -n out --pdf-report\"\n",
    "\n",
    "    add_to_fp_and_list(command, cmd_list, fp)\n",
    "    fp.close()\n",
    "\n",
    "    # set chmod\n",
    "    os.chmod(file_loc, 0o0777)\n",
    "    \n",
    "    # scores have already been computed\n",
    "    if os.path.exists(os.path.join(save_loc, \"out.sgrna_summary.txt\")):\n",
    "        print('Scores exist!')\n",
    "    else:\n",
    "        print(\"Running mageck...\")\n",
    "        process = subprocess.run([file_loc], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        if process.returncode == 1:\n",
    "            print(\"Error in mageck!!!\")\n",
    "            return(process.stdout.splitlines())\n",
    "        else:\n",
    "            print(\"Finished running mageck!\")\n",
    "\n",
    "\n",
    "    ######### load results\n",
    "\n",
    "    print('Loading computed results...')\n",
    "\n",
    "    res = pd.read_csv(os.path.join(save_loc, \"out.sgrna_summary.txt\"), index_col = 0, sep = \"\\t\")\n",
    "    res.index = ['|'.join(i.split('|')[:len(i.split('|'))-1]) for i in res.index]\n",
    "\n",
    "    gene1 = np.array([genes.split('|')[0] for genes in res['Gene']])\n",
    "    gene2 = np.array([genes.split('|')[1] for genes in res['Gene']])\n",
    "\n",
    "    res_df = pd.DataFrame(data = {'Gene Pair': res['Gene'],\n",
    "                                  'Gene 1' : gene1,\n",
    "                                  'Gene 2' : gene2,\n",
    "                                  'MAGECK-FC': res['LFC']})\n",
    "\n",
    "    # add a column for gene pairs, but sorted\n",
    "    sorted_pairs = []\n",
    "    sorted_gene_1 = []\n",
    "    sorted_gene_2 = []\n",
    "    for i in range(res_df.shape[0]):\n",
    "\n",
    "        gene_1 = str(res_df[\"Gene 1\"].iloc[i])\n",
    "        gene_2 = str(res_df[\"Gene 2\"].iloc[i])\n",
    "\n",
    "        t_gene_1, t_gene_2 = sorted([gene_1, gene_2])\n",
    "\n",
    "\n",
    "        if (t_gene_1 == gene_1) and (t_gene_2 == gene_2):\n",
    "            gene_1 = t_gene_1\n",
    "            gene_2 = t_gene_2\n",
    "        else:\n",
    "            gene_1 = t_gene_1\n",
    "            gene_2 = t_gene_2\n",
    "\n",
    "        pair = '|'.join([gene_1, gene_2])\n",
    "\n",
    "        sorted_gene_1.append(gene_1)\n",
    "        sorted_gene_2.append(gene_2)\n",
    "\n",
    "        sorted_pairs.append(pair)\n",
    "    res_df['Gene Pair'] = sorted_pairs\n",
    "    res_df['Gene 1'] = sorted_gene_1\n",
    "    res_df['Gene 2'] = sorted_gene_2\n",
    "\n",
    "    # get dual controls and remove them\n",
    "    dual_controls_idx = np.array([True if i == 'CONTROL|CONTROL' else False for i in res_df['Gene Pair']])\n",
    "    dual_controls = res_df.loc[dual_controls_idx]\n",
    "    res_df = res_df.loc[~dual_controls_idx]\n",
    "\n",
    "    # get single targets and remove them\n",
    "    singles_idx = np.array([True if i == 'CONTROL' else False for i in res_df['Gene 1']]) | np.array([True if i == 'CONTROL' else False for i in res_df['Gene 2']]) | (res_df['Gene 1'] == res_df['Gene 2'])\n",
    "    singles = res_df.loc[singles_idx]\n",
    "    res_df = res_df.loc[~singles_idx]\n",
    "\n",
    "    temp_repeat = singles.copy()\n",
    "    temp_repeat['Gene 1'] = singles[\"Gene 2\"]\n",
    "    temp_repeat['Gene 2'] = singles[\"Gene 1\"]\n",
    "\n",
    "    single_repeat = pd.concat([singles, temp_repeat])\n",
    "\n",
    "    # now res_df contains strictly dual targets\n",
    "    ## calculate SL scores\n",
    "    gene_pair_SL = res_df.groupby('Gene Pair')['MAGECK-FC'].apply(lambda x: np.median(x))\n",
    "    gene_pair_SE = res_df.groupby('Gene Pair')['MAGECK-FC'].apply(lambda x: np.var(x) / np.size(x))\n",
    "\n",
    "    gene_SL = single_repeat.groupby(\"Gene 1\")['MAGECK-FC'].apply(\n",
    "        lambda x: np.median(x))\n",
    "    gene_SE = single_repeat.groupby(\"Gene 1\")['MAGECK-FC'].apply(\n",
    "        lambda x: np.var(x) / np.size(x))\n",
    "\n",
    "    genes_1 = np.array([i.split('|')[0] for i in gene_pair_SL.index])\n",
    "    genes_2 = np.array([i.split('|')[1] for i in gene_pair_SL.index])\n",
    "\n",
    "    all_genes = set(genes_1).union(set(genes_2))\n",
    "    missing_genes = all_genes.difference(set(gene_SL.index))\n",
    "    print(' '.join([\"Filtered gene count:\", str(len(set(missing_genes)))]))\n",
    "\n",
    "    # add them as 0s\n",
    "    gene_SL = pd.concat([gene_SL, pd.Series(index = missing_genes, data = np.zeros(len(missing_genes)))])\n",
    "    gene_SE = pd.concat([gene_SE, pd.Series(index = missing_genes, data = np.zeros(len(missing_genes)))])\n",
    "\n",
    "    mageck_SL = gene_pair_SL.values - gene_SL[genes_1].values - gene_SL[genes_2].values\n",
    "    mageck_SE = np.sqrt(gene_pair_SE.values + gene_SE[genes_1].values + gene_SE[genes_2].values) * math.sqrt(2)\n",
    "    mageck_Z = mageck_SL/mageck_SE\n",
    "\n",
    "    mageck_results = pd.DataFrame(data = {'SL_score' : mageck_SL,\n",
    "                                             'standard_error' : mageck_SE,\n",
    "                                             'Z_SL_score' : mageck_Z,\n",
    "                                             'Gene 1' : genes_1,\n",
    "                                             'Gene 2' : genes_2}, index = ['|'.join(sorted(i.split('|'))) for i in gene_pair_SL.index])\n",
    "\n",
    "    ######### /load results\n",
    "\n",
    "    results = {}\n",
    "    results['MAGECK_SCORE'] = mageck_results\n",
    "\n",
    "    return(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2da3ac5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gemini_score(curr_counts, curr_study, curr_cl, save_dir = 'GEMINI_Files'):\n",
    "\n",
    "    print('Running gemini score...')\n",
    "    \n",
    "    # !no preprocessing!\n",
    "    T0_counts, TEnd_counts = get_raw_counts(curr_counts)\n",
    "\n",
    "    T0_counts.columns = ['T0_' + str(i) for i in range(T0_counts.shape[1])]\n",
    "    TEnd_counts.columns = ['TEnd_' + str(i) for i in range(TEnd_counts.shape[1])]\n",
    "    \n",
    "    # get save location \n",
    "    save_loc = os.path.join(os.getcwd(), save_dir, curr_study, curr_cl)\n",
    "    os.makedirs(save_loc, exist_ok = True)\n",
    "    \n",
    "    # save the sequences\n",
    "    study_sequences = pd.DataFrame({'Guide_ID' : curr_counts['sgRNA_guide_name_g1'].tolist() + curr_counts['sgRNA_guide_name_g2'].tolist(),\n",
    "                                    'Sequence' : curr_counts['sgRNA_guide_seq_g1'].tolist() + curr_counts['sgRNA_guide_seq_g2'].tolist()})\n",
    "\n",
    "    study_sequences.drop_duplicates(subset = 'Sequence', inplace = True)\n",
    "    study_sequences.index = study_sequences['Guide_ID']\n",
    "    study_sequences.to_csv(os.path.join(save_loc, \"sequences.csv\"), sep = ',', index = False)\n",
    "\n",
    "    # save guidexgene annotation\n",
    "    guide_gene_annotation = pd.DataFrame({'Sequences Comb': curr_counts[['sgRNA_guide_seq_g1', 'sgRNA_guide_seq_g2']].agg(';'.join, axis = 1),\n",
    "                                          'Gene 1': curr_counts['sgRNA_target_name_g1'],\n",
    "                                          'Gene 2': curr_counts['sgRNA_target_name_g2']})\n",
    "\n",
    "    gemini_counts = pd.DataFrame(guide_gene_annotation['Sequences Comb'].copy())\n",
    "    gemini_counts = gemini_counts.merge(T0_counts, how = 'left', right_index = True, left_index = True)\n",
    "    gemini_counts = gemini_counts.merge(TEnd_counts, how = 'left', right_index = True, left_index = True)\n",
    "\n",
    "    guide_gene_annotation.reset_index(drop = True, inplace = True)\n",
    "    guide_gene_annotation.to_csv(os.path.join(save_loc, \"guide_gene_annotation.csv\"), sep = ',', index = False)\n",
    "\n",
    "    # save counts\n",
    "    gemini_counts.reset_index(drop = True, inplace = True)\n",
    "    gemini_counts.to_csv(os.path.join(save_loc, \"counts.csv\"), sep = ',', index = False)\n",
    "    \n",
    "    # write a gemini bash file\n",
    "    file_loc = os.path.join(save_loc, 'GEMINI_commands.sh')\n",
    "    fp = open(file_loc, '+w')\n",
    "    fp.write(\"#!/bin/sh\\n\")\n",
    "    fp.write('module load R/4.1.0-gnu9.1\\n')\n",
    "    fp.write('Rscript --vanilla GEMINI.R --args ' + os.path.join(save_dir, curr_study, curr_cl) + '\\n')\n",
    "    fp.close()\n",
    "\n",
    "    # set chmod\n",
    "    os.chmod(file_loc, 0o0777)\n",
    "\n",
    "    \n",
    "    #### scoring\n",
    "    \n",
    "    # scores have already been computed\n",
    "    if os.path.exists(os.path.join(save_loc, 'GEMINI_Scores.csv')):\n",
    "        print('Scores exist!')\n",
    "    else:\n",
    "        print(\"Running GEMINI...\")\n",
    "        process = subprocess.run([file_loc], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        if process.returncode == 1:\n",
    "            print(\"Error in GEMINI!!!\")\n",
    "            return(process.stdout.splitlines())\n",
    "        else:\n",
    "            print(\"Finished running GEMINI!\")\n",
    "\n",
    "        \n",
    "    ######### load results\n",
    "    \n",
    "    res = pd.read_csv(os.path.join(save_loc, 'GEMINI_Scores.csv'), index_col = 0)\n",
    "\n",
    "    res.index = ['|'.join(sorted(i.split(';'))) for i in res.index]\n",
    "    res.columns = ['GEMINI Score']\n",
    "\n",
    "    # # get only dual SL\n",
    "    only_dual_idx = [False if 'CONTROL' in i else True for i in res.index]\n",
    "    res = res.loc[only_dual_idx]\n",
    "\n",
    "    # set results\n",
    "    gemini_results = pd.DataFrame(data = {'SL_score' : res['GEMINI Score'].values,\n",
    "                                             'Gene 1' : [i.split('|')[0] for i in res.index],\n",
    "                                             'Gene 2' : [i.split('|')[1] for i in res.index]}, index = ['|'.join(sorted(i.split('|'))) for i in res.index])\n",
    "\n",
    "    \n",
    "    \n",
    "    ######### /load results\n",
    "\n",
    "    results = {}\n",
    "    results['GEMINI_SCORE'] = gemini_results\n",
    "    \n",
    "    return(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c11087c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_table_to_db(curr_counts, curr_results, table_name, engine_link):\n",
    "    \n",
    "    print('---------ADDING-TO-DB---------')\n",
    "    \n",
    "    # print table\n",
    "    print('Processing table for: ' + table_name)\n",
    "    \n",
    "    # add sorted targets\n",
    "    # add a sorted gene pair column\n",
    "    curr_counts['gene_pair'] = ['|'.join(sorted([curr_counts['sgRNA_target_name_g1'].iloc[i], curr_counts['sgRNA_target_name_g2'].iloc[i]])) for i in range(curr_counts.shape[0])]\n",
    "\n",
    "    # remove the same ones\n",
    "    curr_results = curr_results.loc[curr_results['Gene 1'] != curr_results['Gene 2'],:]\n",
    "\n",
    "    # keep only score columns\n",
    "    curr_results.drop(['Gene 1', 'Gene 2'], axis = 1, inplace = True, errors = 'ignore')\n",
    "\n",
    "    # make the index\n",
    "    # curr_counts['gene_pair'] = ['|'.join(sorted([curr_counts['sgRNA_target_name_g1'].iloc[i], curr_counts['sgRNA_target_name_g2'].iloc[i]])) for i in range(curr_counts.shape[0])]\n",
    "\n",
    "    # merge and get final table\n",
    "    curr_results = curr_results.merge(curr_counts.drop_duplicates(subset = 'gene_pair'), how = 'left', left_index = True, right_on ='gene_pair').loc[:, ['gene_pair_id'] + list(curr_results.columns)]\n",
    "\n",
    "    # first, get the metadata\n",
    "    db_metadata = sqlalchemy.MetaData(bind=engine_link)\n",
    "    db_metadata.reflect(engine_link)\n",
    "\n",
    "    # access the tables\n",
    "    curr_table = db_metadata.tables[table_name]\n",
    "\n",
    "    # then, start the session\n",
    "    engine_session = sessionmaker(bind=engine_link)\n",
    "    curr_session = engine_session()\n",
    "\n",
    "    # get number of records in each table\n",
    "    curr_records_num = curr_session.query(curr_table).count()\n",
    "\n",
    "    curr_results.reset_index(drop = True, inplace = True)\n",
    "    curr_results.index += curr_records_num\n",
    "    # set index\n",
    "    curr_results['id'] = curr_results.index\n",
    "    \n",
    "    if curr_results['gene_pair_id'].isna().sum() > 0:\n",
    "        print('NA found')\n",
    "        return()\n",
    "        \n",
    "    with engine_link.begin() as transaction:\n",
    "        # insert sequence\n",
    "        print('Beginning transaction...')\n",
    "\n",
    "        # insert scores\n",
    "        curr_results.to_sql(name = table_name, con = transaction, if_exists = 'append', index = False, index_label = 'id')\n",
    "\n",
    "        print('Successfully inserted!')\n",
    "\n",
    "        print('Added Record stats...')\n",
    "        print(' '.join(['Score insert:', str(curr_results.shape[0])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bb1edea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_added_to_table(curr_counts, table_name, engine_link):\n",
    "    print('Checking if score already computed: ' + table_name)\n",
    "    \n",
    "    # get available results\n",
    "    res = pd.read_sql_table(table_name, engine_link, index_col = 'id')\n",
    "    \n",
    "    if res.shape[0] == 0:\n",
    "        # none added, so proceed\n",
    "        return(False)\n",
    "    else:\n",
    "        # get all IDs\n",
    "        available_ids = set(res['gene_pair_id']).difference(set(curr_counts['gene_pair_id']))\n",
    "        \n",
    "        # already added\n",
    "        if len(available_ids) == 0:\n",
    "            print('Scores already in database!')\n",
    "            print('Inserted scores: ' + str(len(set(curr_counts['gene_pair_id']))))\n",
    "            print('---------NOT-TO-DB---------')\n",
    "            return(True)\n",
    "        elif len(available_ids) == len(set(res['gene_pair_id'])):\n",
    "            # none added, so proceed\n",
    "            return(False)\n",
    "        else:\n",
    "            print('Scores already in database?')\n",
    "            print('Inserted scores?: ' + str(res.shape[0]))\n",
    "            print('---------NOT-TO-DB---------')\n",
    "            return(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a5ac80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_result_table(curr_counts, table_name, curr_study, curr_cl, engine_link):\n",
    "    \n",
    "    print('Accessing table: ' + table_name)\n",
    "    \n",
    "    # get available results\n",
    "    res = pd.read_sql_table(table_name, engine_link, index_col = 'id')\n",
    "    \n",
    "    # possible gene pairs\n",
    "    curr_counts['gene_pair'] = ['|'.join(sorted([curr_counts['sgRNA_target_name_g1'].iloc[i], curr_counts['sgRNA_target_name_g2'].iloc[i]])) for i in range(curr_counts.shape[0])]\n",
    "\n",
    "    # get results\n",
    "    query_res = curr_counts.loc[curr_counts['target_type'] == 'Dual', ['gene_pair', 'gene_pair_id']].drop_duplicates(subset = ['gene_pair_id'])\n",
    "    query_res = query_res.merge(res, left_on = 'gene_pair_id', right_on = 'gene_pair_id').drop('gene_pair_id', axis = 1)\n",
    "    \n",
    "    # add column names to the front\n",
    "    names_dict = {i: table_name + '_' + i for i in query_res.columns[1:]}\n",
    "    query_res.rename(columns = names_dict, inplace = True)\n",
    "    #query_res.columns[1:] = table_name + '_' + query_res.columns[1:]\n",
    "    \n",
    "    print('Available gene pairs: ' + str(query_res.shape[0]))\n",
    "    \n",
    "    # add name of study\n",
    "    query_res['study_origin'] = curr_study\n",
    "    \n",
    "    # add name of cell line\n",
    "    query_res['cell_line_origin'] = curr_cl\n",
    "    \n",
    "    return(query_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7df7a26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_studies = set(counts['study_origin'])\n",
    "available_studies = sorted([rev_study_name_to_pubmed_id[i] for i in set(counts['study_origin'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d17498cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['diehl_data',\n",
       " 'horlbeck_data',\n",
       " 'najm_data',\n",
       " 'parrish_data',\n",
       " 'shantang_data',\n",
       " 'wong_data',\n",
       " 'zhao_data']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c9d23362",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# store_results = {}\n",
    "# horlbeck_processed = False\n",
    "# for curr_study in available_studies:\n",
    "#     store_results[curr_study] = {}\n",
    "#     print('Working on study: ' + curr_study)\n",
    "\n",
    "#     # get study counts and seq\n",
    "#     study_counts = counts.loc[counts['study_origin'] == study_name_to_pubmed_id[curr_study]].copy()\n",
    "\n",
    "#     curr_seq_ids = np.array(sorted(list(set(study_counts['guide_1_id'].tolist() + study_counts['guide_2_id'].tolist()))))\n",
    "#     study_sequences = experiment_design.loc[curr_seq_ids]\n",
    "\n",
    "#     # the analysis runs for each individual cell line\n",
    "#     available_cell_lines = set(study_counts['cell_line_origin'])\n",
    "\n",
    "#     for curr_cl in available_cell_lines:\n",
    "#         store_results[curr_study][curr_cl] = {}\n",
    "#         print('Working on cell line: ' + curr_cl)\n",
    "#         curr_counts = study_counts.loc[study_counts['cell_line_origin'] == curr_cl].copy()\n",
    "        \n",
    "#         # run horlbeck score\n",
    "# #         if curr_study == 'horlbeck_data' and (not horlbeck_processed):\n",
    "# #             # Horlbeck does additional filtering on JURKAT based on K562\n",
    "# #             JURKAT_counts = study_counts.loc[study_counts['cell_line_origin'] == 'JURKAT'].copy()\n",
    "# #             K562_counts = study_counts.loc[study_counts['cell_line_origin'] == 'K562'].copy()\n",
    "\n",
    "# #             #if (not check_if_added_to_table(JURKAT_counts.copy(), 'HORLBECK_SCORE', SLKB_engine)) and (not check_if_added_to_table(K562_counts.copy(), 'HORLBECK_SCORE', SLKB_engine)):\n",
    "\n",
    "# #             # do the preprocessing\n",
    "# #             JURKAT_counts = run_horlbeck_preprocessing(JURKAT_counts, filterThreshold = 35, pseudocount = 10)\n",
    "# #             K562_counts = run_horlbeck_preprocessing(K562_counts, filterThreshold = 35, pseudocount = 10)\n",
    "\n",
    "# #             # do the additional filtering\n",
    "# #             singles_K562 = JURKAT_counts.loc[JURKAT_counts['target_type'] == 'Single'].copy().dropna()\n",
    "# #             singles_JURKAT = K562_counts.loc[K562_counts['target_type'] == 'Single'].copy().dropna()\n",
    "\n",
    "# #             a_average_K562 = singles_K562[singles_K562['sgRNA_target_name_g2'] == \"CONTROL\"]\n",
    "# #             a_average_K562 = pd.DataFrame(a_average_K562.groupby('sgRNA_guide_name_g1')['FC_Averaged_abbaAveraged'].apply(np.mean))\n",
    "\n",
    "# #             a_average_JURKAT = singles_JURKAT[singles_JURKAT['sgRNA_target_name_g2'] == \"CONTROL\"]\n",
    "# #             a_average_JURKAT = pd.DataFrame(a_average_JURKAT.groupby('sgRNA_guide_name_g1')['FC_Averaged_abbaAveraged'].apply(np.mean))\n",
    "\n",
    "# #             a_average_JURKAT = a_average_JURKAT.join(a_average_K562, rsuffix = '_K562')\n",
    "\n",
    "# #             filter_criteria = a_average_JURKAT.loc[((a_average_JURKAT['FC_Averaged_abbaAveraged'] > -0.025) & (a_average_JURKAT['FC_Averaged_abbaAveraged_K562'] < -0.05))]\n",
    "\n",
    "# #             additionally_filtered = list(filter_criteria.index)\n",
    "\n",
    "# #             to_be_dropped = JURKAT_counts['sgRNA_guide_name_g1'].isin(additionally_filtered) | JURKAT_counts['sgRNA_guide_name_g2'].isin(additionally_filtered)\n",
    "\n",
    "# #             # drop them\n",
    "# #             JURKAT_counts = JURKAT_counts.loc[~to_be_dropped, :]\n",
    "\n",
    "# #             # now, proceed to run horlbeck score\n",
    "# #             JURKAT_res = run_horlbeck_score(JURKAT_counts.copy(), do_preprocessing = False)\n",
    "# #             K562_res = run_horlbeck_score(K562_counts.copy(), do_preprocessing = False)\n",
    "\n",
    "# #             store_results[curr_study]['JURKAT'].update(JURKAT_res)\n",
    "# #             store_results[curr_study]['K562'].update(K562_res)\n",
    "\n",
    "# #             add_table_to_db(JURKAT_counts.copy(), JURKAT_res['HORLBECK_SCORE'], 'HORLBECK_SCORE', SLKB_engine)\n",
    "# #             add_table_to_db(K562_counts.copy(), K562_res['HORLBECK_SCORE'], 'HORLBECK_SCORE', SLKB_engine)\n",
    "\n",
    "# #             horlbeck_processed = True\n",
    "# # #             else:\n",
    "# # #                 print('Skipping horlbeck score...horlbeck case')\n",
    "\n",
    "# #         elif curr_study == 'diehl_data':\n",
    "# # #             if not check_if_added_to_table(curr_counts.copy(), 'HORLBECK_SCORE', SLKB_engine):\n",
    "# #                 # very low counts, set the threshold to be 0\n",
    "# #             temp_counts = run_horlbeck_preprocessing(curr_counts.copy(), filterThreshold = 0, pseudocount = 10)\n",
    "# #             horlbeck_res = run_horlbeck_score(temp_counts.copy(), do_preprocessing = False)\n",
    "# #             store_results[curr_study][curr_cl].update(horlbeck_res)\n",
    "# #             add_table_to_db(curr_counts.copy(), horlbeck_res['HORLBECK_SCORE'], 'HORLBECK_SCORE', SLKB_engine)\n",
    "# # #             else:\n",
    "# # #                 print('Skipping horlbeck score...')\n",
    "# #         else:\n",
    "# #             if curr_study != 'horlbeck_data':\n",
    "# # #                 if not check_if_added_to_table(curr_counts.copy(), 'HORLBECK_SCORE', SLKB_engine):\n",
    "# #                 horlbeck_res = run_horlbeck_score(curr_counts.copy(), do_preprocessing = True)\n",
    "# #                 store_results[curr_study][curr_cl].update(horlbeck_res)\n",
    "# #                 add_table_to_db(curr_counts.copy(), horlbeck_res['HORLBECK_SCORE'], 'HORLBECK_SCORE', SLKB_engine)\n",
    "# # #                 else:\n",
    "# # #                     print('Skipping horlbeck score...')\n",
    "    \n",
    "\n",
    "#         # run MAGeCK\n",
    "# #         if not check_if_added_to_table(curr_counts.copy(), 'MAGECK_SCORE', SLKB_engine):\n",
    "#         mageck_res = run_mageck_score(curr_counts.copy(), curr_study, curr_cl, save_dir = 'MAGECK_Files')\n",
    "#         store_results[curr_study][curr_cl].update(mageck_res)\n",
    "#         add_table_to_db(curr_counts.copy(), mageck_res['MAGECK_SCORE'], 'MAGECK_SCORE', SLKB_engine)\n",
    "            \n",
    "# #         else:\n",
    "# #             print('Skipping MAGeCK score...')\n",
    "\n",
    "#         # run median scores\n",
    "# #         if not check_if_added_to_table(curr_counts.copy(), 'MEDIAN_NB_SCORE', SLKB_engine):\n",
    "#         median_res = run_median_scores(curr_counts.copy(), full_normalization = False)\n",
    "#         store_results[curr_study][curr_cl].update(median_res)\n",
    "#         add_table_to_db(curr_counts.copy(), median_res['MEDIAN_NB_SCORE'], 'MEDIAN_NB_SCORE', SLKB_engine)\n",
    "#         if median_res['MEDIAN_B_SCORE'] is not None:\n",
    "#             add_table_to_db(curr_counts.copy(), median_res['MEDIAN_B_SCORE'], 'MEDIAN_B_SCORE', SLKB_engine)\n",
    "# #         else:\n",
    "# #             print('Skipping median score...')\n",
    "\n",
    "#         # run median scores\n",
    "#         #if not check_if_added_to_table(curr_counts.copy(), 'MEDIAN_NB_SCORE_FULL_NORM', SLKB_engine):\n",
    "#         median_res2 = run_median_scores(curr_counts.copy(), full_normalization = True)\n",
    "#         store_results[curr_study][curr_cl].update(median_res2)\n",
    "#         add_table_to_db(curr_counts.copy(), median_res2['MEDIAN_NB_SCORE'], 'MEDIAN_NB_SCORE_FULL_NORM', SLKB_engine)\n",
    "#         if median_res2['MEDIAN_B_SCORE'] is not None:\n",
    "#             add_table_to_db(curr_counts.copy(), median_res2['MEDIAN_B_SCORE'], 'MEDIAN_B_SCORE_FULL_NORM', SLKB_engine)\n",
    "# #         else:\n",
    "# #             print('Skipping median score...')\n",
    "\n",
    "#         # run sgRNA scores\n",
    "# #         if not check_if_added_to_table(curr_counts.copy(), 'SGRA_DERIVED_NB_SCORE', SLKB_engine):\n",
    "#         sgRNA_res = run_sgrna_scores(curr_counts.copy(), full_normalization = False)\n",
    "#         store_results[curr_study][curr_cl].update(sgRNA_res)\n",
    "#         add_table_to_db(curr_counts.copy(), sgRNA_res['SGRA_DERIVED_NB_SCORE'], 'SGRA_DERIVED_NB_SCORE', SLKB_engine)\n",
    "#         if sgRNA_res['SGRA_DERIVED_B_SCORE'] is not None:\n",
    "#             add_table_to_db(curr_counts.copy(), sgRNA_res['SGRA_DERIVED_B_SCORE'], 'SGRA_DERIVED_B_SCORE', SLKB_engine)\n",
    "# #         else:\n",
    "# #             print('Skipping sgRNA score...')\n",
    "\n",
    "# #         if not check_if_added_to_table(curr_counts.copy(), 'SGRA_DERIVED_NB_SCORE_FULL_NORM', SLKB_engine):\n",
    "#         sgRNA_res2 = run_sgrna_scores(curr_counts.copy(), full_normalization = True)\n",
    "#         store_results[curr_study][curr_cl].update(sgRNA_res2)\n",
    "#         add_table_to_db(curr_counts.copy(), sgRNA_res2['SGRA_DERIVED_NB_SCORE'], 'SGRA_DERIVED_NB_SCORE_FULL_NORM', SLKB_engine)\n",
    "#         if sgRNA_res2['SGRA_DERIVED_B_SCORE'] is not None:\n",
    "#             add_table_to_db(curr_counts.copy(), sgRNA_res2['SGRA_DERIVED_B_SCORE'], 'SGRA_DERIVED_B_SCORE_FULL_NORM', SLKB_engine)\n",
    "# #         else:\n",
    "# #             print('Skipping sgRNA score...')\n",
    "\n",
    "#         # run GEMINI\n",
    "#         #if not check_if_added_to_table(curr_counts.copy(), 'GEMINI_SCORE', SLKB_engine):\n",
    "#         gemini_res = run_gemini_score(curr_counts.copy(), curr_study, curr_cl, save_dir = 'GEMINI_Files')\n",
    "#         store_results[curr_study][curr_cl].update(gemini_res)\n",
    "#         add_table_to_db(curr_counts.copy(), gemini_res['GEMINI_SCORE'], 'GEMINI_SCORE', SLKB_engine)\n",
    "# #         else:\n",
    "# #             print('Skipping GEMINI score...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ef177bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on study: diehl_data\n",
      "Working on cell line: RPE1\n",
      "Checking if score already computed: MEDIAN_NB_SCORE\n",
      "Running median scores...\n",
      "Getting raw counts...\n",
      "Filtering enabled... Condition: 35 counts\n",
      "Filtered a total of 9757 out of 248191 sgRNAs.\n",
      "\n",
      "---\n",
      "\n",
      "Not full normalization...\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "ctrl_1    3434902.0\n",
      "ctrl_2    2905388.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 59882.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "rep_1    43897.0\n",
      "rep_2    59882.0\n",
      "rep_3    23578.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 59882.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "ctrl_1    49753319.0\n",
      "ctrl_2    41904226.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 1621160.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "rep_1    1621160.0\n",
      "rep_2    1589753.0\n",
      "rep_3     550919.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 1621160.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "ctrl_1    171179130.0\n",
      "ctrl_2    143161060.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 8077727.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "rep_1    8077727.0\n",
      "rep_2    7604781.0\n",
      "rep_3    2737975.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 8077727.0 counts\n",
      "Sorting gene pairs and guides based on ordering gene ordering...\n",
      "Available singles: 41003\n",
      "Available duals: 195410\n",
      "Available control: 2021\n",
      "Filtered single sgRNA count: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:124: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-dual-IS'] = dual['FC'].values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-single-IS-Guide-1'] = EC_1.values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:126: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-single-IS-Guide-2'] = EC_2.values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-dual-SL-sgRNA'] = dual['FC'].values - EC_1.values - EC_2.values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered gene count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:165: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-dual-IS'] = dual['FC'].values - control_median\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:166: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-single-IS-Guide-1'] = EC_1.values - control_median\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-single-IS-Guide-2'] = EC_2.values - control_median\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:168: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-dual-SL-sgRNA'] = (dual['FC'].values - control_median) - (EC_1.values - control_median) - (EC_2.values - control_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered gene count: 0\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: MEDIAN_NB_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 10720\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: MEDIAN_B_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 10720\n",
      "---------------------\n",
      "Working on study: horlbeck_data\n",
      "Working on cell line: JURKAT\n",
      "Checking if score already computed: MEDIAN_NB_SCORE\n",
      "Running median scores...\n",
      "Getting raw counts...\n",
      "Filtering enabled... Condition: 35 counts\n",
      "Filtered a total of 128359 out of 1044484 sgRNAs.\n",
      "\n",
      "---\n",
      "\n",
      "Not full normalization...\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "JURKAT_tripleseq,T0,rep1    67829.0\n",
      "JURKAT_tripleseq,T0,rep2    52320.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 89585.5 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "JURKAT_tripleseq,cyc,rep1    111342.0\n",
      "JURKAT_tripleseq,cyc,rep2    130002.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 89585.5 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "JURKAT_tripleseq,T0,rep1    10110190.0\n",
      "JURKAT_tripleseq,T0,rep2     7967463.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 10178674.5 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "JURKAT_tripleseq,cyc,rep1    10247159.0\n",
      "JURKAT_tripleseq,cyc,rep2    11858053.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 10178674.5 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "JURKAT_tripleseq,T0,rep1    320133675.0\n",
      "JURKAT_tripleseq,T0,rep2    253657246.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 254499846.5 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "JURKAT_tripleseq,cyc,rep1    227568286.0\n",
      "JURKAT_tripleseq,cyc,rep2    255342447.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 254499846.5 counts\n",
      "Sorting gene pairs and guides based on ordering gene ordering...\n",
      "Available singles: 31978\n",
      "Available duals: 883891\n",
      "Available control: 256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:124: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-dual-IS'] = dual['FC'].values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-single-IS-Guide-1'] = EC_1.values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:126: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-single-IS-Guide-2'] = EC_2.values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-dual-SL-sgRNA'] = dual['FC'].values - EC_1.values - EC_2.values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered single sgRNA count: 4\n",
      "Filtered gene count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:165: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-dual-IS'] = dual['FC'].values - control_median\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:166: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-single-IS-Guide-1'] = EC_1.values - control_median\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-single-IS-Guide-2'] = EC_2.values - control_median\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:168: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-dual-SL-sgRNA'] = (dual['FC'].values - control_median) - (EC_1.values - control_median) - (EC_2.values - control_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered gene count: 0\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: MEDIAN_NB_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 110614\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: MEDIAN_B_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 110614\n",
      "---------------------\n",
      "Working on cell line: K562\n",
      "Checking if score already computed: MEDIAN_NB_SCORE\n",
      "Running median scores...\n",
      "Getting raw counts...\n",
      "Filtering enabled... Condition: 35 counts\n",
      "Filtered a total of 92141 out of 1044484 sgRNAs.\n",
      "\n",
      "---\n",
      "\n",
      "Not full normalization...\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "K562_barcode,T0,rep1     90567.0\n",
      "K562_barcode,T0,rep2    105269.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 339731.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "K562_tripleseq,cyc,rep1    627562.0\n",
      "K562_tripleseq,cyc,rep2    574193.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 339731.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "K562_barcode,T0,rep1    13775507.0\n",
      "K562_barcode,T0,rep2    15538057.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 17525698.5 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "K562_tripleseq,cyc,rep1    23202008.0\n",
      "K562_tripleseq,cyc,rep2    19513340.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 17525698.5 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "K562_barcode,T0,rep1    433279037.0\n",
      "K562_barcode,T0,rep2    482402577.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 376245319.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "K562_tripleseq,cyc,rep1    319211601.0\n",
      "K562_tripleseq,cyc,rep2    263341379.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 376245319.0 counts\n",
      "Sorting gene pairs and guides based on ordering gene ordering...\n",
      "Available singles: 32858\n",
      "Available duals: 919229\n",
      "Available control: 256\n",
      "Filtered single sgRNA count: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:124: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-dual-IS'] = dual['FC'].values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-single-IS-Guide-1'] = EC_1.values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:126: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-single-IS-Guide-2'] = EC_2.values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-dual-SL-sgRNA'] = dual['FC'].values - EC_1.values - EC_2.values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered gene count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:165: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-dual-IS'] = dual['FC'].values - control_median\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:166: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-single-IS-Guide-1'] = EC_1.values - control_median\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-single-IS-Guide-2'] = EC_2.values - control_median\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:168: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-dual-SL-sgRNA'] = (dual['FC'].values - control_median) - (EC_1.values - control_median) - (EC_2.values - control_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered gene count: 0\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: MEDIAN_NB_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 110684\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: MEDIAN_B_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 110684\n",
      "---------------------\n",
      "Working on study: najm_data\n",
      "Working on cell line: HT29\n",
      "Checking if score already computed: MEDIAN_NB_SCORE\n",
      "Running median scores...\n",
      "Getting raw counts...\n",
      "Removing NA replicate from TEnd...\n",
      "Filtering enabled... Condition: 35 counts\n",
      "Filtered a total of 1 out of 9216 sgRNAs.\n",
      "\n",
      "---\n",
      "\n",
      "Not full normalization...\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "pDNA_Reads    3609228.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 3609228.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "Rep_A_Reads    3009073.0\n",
      "Rep_B_Reads    4006083.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 3609228.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "pDNA_Reads    2407466.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 2438869.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "Rep_A_Reads    2438869.0\n",
      "Rep_B_Reads    3266357.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 2438869.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "pDNA_Reads    341184.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 440351.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "Rep_A_Reads    440351.0\n",
      "Rep_B_Reads    590592.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 440351.0 counts\n",
      "Sorting gene pairs and guides based on ordering gene ordering...\n",
      "Available singles: 3374\n",
      "Available duals: 5400\n",
      "Available control: 441\n",
      "Filtered single sgRNA count: 0\n",
      "Filtered gene count: 0\n",
      "Filtered gene count: 0\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: MEDIAN_NB_SCORE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:124: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-dual-IS'] = dual['FC'].values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-single-IS-Guide-1'] = EC_1.values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:126: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-single-IS-Guide-2'] = EC_2.values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-dual-SL-sgRNA'] = dual['FC'].values - EC_1.values - EC_2.values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:165: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-dual-IS'] = dual['FC'].values - control_median\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:166: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-single-IS-Guide-1'] = EC_1.values - control_median\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-single-IS-Guide-2'] = EC_2.values - control_median\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:168: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-dual-SL-sgRNA'] = (dual['FC'].values - control_median) - (EC_1.values - control_median) - (EC_2.values - control_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 300\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: MEDIAN_B_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 300\n",
      "---------------------\n",
      "Working on cell line: A549\n",
      "Checking if score already computed: MEDIAN_NB_SCORE\n",
      "Running median scores...\n",
      "Getting raw counts...\n",
      "Removing NA replicate from TEnd...\n",
      "Filtering enabled... Condition: 35 counts\n",
      "Filtered a total of 1 out of 9216 sgRNAs.\n",
      "\n",
      "---\n",
      "\n",
      "Not full normalization...\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "pDNA_Reads    3609228.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 3933111.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "Rep_A_Reads    3933111.0\n",
      "Rep_B_Reads    4567319.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 3933111.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "pDNA_Reads    2407466.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 3650146.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "Rep_A_Reads    3650146.0\n",
      "Rep_B_Reads    4233101.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 3650146.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "pDNA_Reads    341184.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 768155.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "Rep_A_Reads    768155.0\n",
      "Rep_B_Reads    889178.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 768155.0 counts\n",
      "Sorting gene pairs and guides based on ordering gene ordering...\n",
      "Available singles: 3374\n",
      "Available duals: 5400\n",
      "Available control: 441\n",
      "Filtered single sgRNA count: 0\n",
      "Filtered gene count: 0\n",
      "Filtered gene count: 0\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: MEDIAN_NB_SCORE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:124: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-dual-IS'] = dual['FC'].values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-single-IS-Guide-1'] = EC_1.values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:126: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-single-IS-Guide-2'] = EC_2.values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-dual-SL-sgRNA'] = dual['FC'].values - EC_1.values - EC_2.values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:165: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-dual-IS'] = dual['FC'].values - control_median\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:166: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-single-IS-Guide-1'] = EC_1.values - control_median\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-single-IS-Guide-2'] = EC_2.values - control_median\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:168: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-dual-SL-sgRNA'] = (dual['FC'].values - control_median) - (EC_1.values - control_median) - (EC_2.values - control_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 300\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: MEDIAN_B_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 300\n",
      "---------------------\n",
      "Working on cell line: OVCAR8\n",
      "Checking if score already computed: MEDIAN_NB_SCORE\n",
      "Running median scores...\n",
      "Getting raw counts...\n",
      "Filtering enabled... Condition: 35 counts\n",
      "Filtered a total of 1 out of 9216 sgRNAs.\n",
      "\n",
      "---\n",
      "\n",
      "Not full normalization...\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "pDNA_Reads    3609228.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 2499117.5 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "Rep_A_Reads    1540891.0\n",
      "Rep_B_Reads    1515861.0\n",
      "Rep_C_Reads    3457344.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 2499117.5 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "pDNA_Reads    2407466.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 1809065.5 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "Rep_A_Reads    1210665.0\n",
      "Rep_B_Reads    1194598.0\n",
      "Rep_C_Reads    2737491.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 1809065.5 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "pDNA_Reads    341184.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 275056.5 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "Rep_A_Reads    208929.0\n",
      "Rep_B_Reads    208275.0\n",
      "Rep_C_Reads    474433.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 275056.5 counts\n",
      "Sorting gene pairs and guides based on ordering gene ordering...\n",
      "Available singles: 3374\n",
      "Available duals: 5400\n",
      "Available control: 441\n",
      "Filtered single sgRNA count: 0\n",
      "Filtered gene count: 0\n",
      "Filtered gene count: 0\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: MEDIAN_NB_SCORE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:124: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-dual-IS'] = dual['FC'].values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-single-IS-Guide-1'] = EC_1.values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:126: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-single-IS-Guide-2'] = EC_2.values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-dual-SL-sgRNA'] = dual['FC'].values - EC_1.values - EC_2.values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:165: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-dual-IS'] = dual['FC'].values - control_median\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:166: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-single-IS-Guide-1'] = EC_1.values - control_median\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-single-IS-Guide-2'] = EC_2.values - control_median\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:168: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-dual-SL-sgRNA'] = (dual['FC'].values - control_median) - (EC_1.values - control_median) - (EC_2.values - control_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 300\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: MEDIAN_B_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 300\n",
      "---------------------\n",
      "Working on cell line: A375\n",
      "Checking if score already computed: MEDIAN_NB_SCORE\n",
      "Running median scores...\n",
      "Getting raw counts...\n",
      "Filtering enabled... Condition: 35 counts\n",
      "Filtered a total of 1 out of 9216 sgRNAs.\n",
      "\n",
      "---\n",
      "\n",
      "Not full normalization...\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "pDNA_Reads    3609228.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 3141784.5 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "Rep_A_Reads    3399698.0\n",
      "Rep_B_Reads    2883871.0\n",
      "Rep_C_Reads    2112357.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 3141784.5 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "pDNA_Reads    2407466.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 2540828.5 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "Rep_A_Reads    3174784.0\n",
      "Rep_B_Reads    2674191.0\n",
      "Rep_C_Reads    1956303.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 2540828.5 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "pDNA_Reads    341184.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 479825.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "Rep_A_Reads    662297.0\n",
      "Rep_B_Reads    554649.0\n",
      "Rep_C_Reads    405001.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 479825.0 counts\n",
      "Sorting gene pairs and guides based on ordering gene ordering...\n",
      "Available singles: 3374\n",
      "Available duals: 5400\n",
      "Available control: 441\n",
      "Filtered single sgRNA count: 0\n",
      "Filtered gene count: 0\n",
      "Filtered gene count: 0\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: MEDIAN_NB_SCORE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:124: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-dual-IS'] = dual['FC'].values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-single-IS-Guide-1'] = EC_1.values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:126: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-single-IS-Guide-2'] = EC_2.values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-dual-SL-sgRNA'] = dual['FC'].values - EC_1.values - EC_2.values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:165: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-dual-IS'] = dual['FC'].values - control_median\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:166: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-single-IS-Guide-1'] = EC_1.values - control_median\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-single-IS-Guide-2'] = EC_2.values - control_median\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:168: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-dual-SL-sgRNA'] = (dual['FC'].values - control_median) - (EC_1.values - control_median) - (EC_2.values - control_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 300\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: MEDIAN_B_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 300\n",
      "---------------------\n",
      "Working on cell line: 786O\n",
      "Checking if score already computed: MEDIAN_NB_SCORE\n",
      "Running median scores...\n",
      "Getting raw counts...\n",
      "Filtering enabled... Condition: 35 counts\n",
      "Filtered a total of 1 out of 9216 sgRNAs.\n",
      "\n",
      "---\n",
      "\n",
      "Not full normalization...\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "pDNA_Reads    3609228.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 4237644.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "Rep_A_Reads    6257808.0\n",
      "Rep_B_Reads    4094431.0\n",
      "Rep_C_Reads    4380857.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 4237644.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "pDNA_Reads    2407466.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 3228455.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "Rep_A_Reads    4770033.0\n",
      "Rep_B_Reads    3114367.0\n",
      "Rep_C_Reads    3342543.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 3228455.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "pDNA_Reads    341184.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 543765.5 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "Rep_A_Reads    803810.0\n",
      "Rep_B_Reads    523893.0\n",
      "Rep_C_Reads    563638.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 543765.5 counts\n",
      "Sorting gene pairs and guides based on ordering gene ordering...\n",
      "Available singles: 3374\n",
      "Available duals: 5400\n",
      "Available control: 441\n",
      "Filtered single sgRNA count: 0\n",
      "Filtered gene count: 0\n",
      "Filtered gene count: 0\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: MEDIAN_NB_SCORE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:124: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-dual-IS'] = dual['FC'].values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-single-IS-Guide-1'] = EC_1.values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:126: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-single-IS-Guide-2'] = EC_2.values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-dual-SL-sgRNA'] = dual['FC'].values - EC_1.values - EC_2.values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:165: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-dual-IS'] = dual['FC'].values - control_median\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:166: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-single-IS-Guide-1'] = EC_1.values - control_median\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-single-IS-Guide-2'] = EC_2.values - control_median\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:168: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-dual-SL-sgRNA'] = (dual['FC'].values - control_median) - (EC_1.values - control_median) - (EC_2.values - control_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 300\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: MEDIAN_B_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 300\n",
      "---------------------\n",
      "Working on cell line: MELJUSO\n",
      "Checking if score already computed: MEDIAN_NB_SCORE\n",
      "Running median scores...\n",
      "Getting raw counts...\n",
      "Removing NA replicate from TEnd...\n",
      "Filtering enabled... Condition: 35 counts\n",
      "Filtered a total of 1 out of 9216 sgRNAs.\n",
      "\n",
      "---\n",
      "\n",
      "Not full normalization...\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "pDNA_Reads    3609228.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 3643736.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "Rep_A_Reads    3643736.0\n",
      "Rep_B_Reads    4225805.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 3643736.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "pDNA_Reads    2407466.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 3020501.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "Rep_A_Reads    3020501.0\n",
      "Rep_B_Reads    3512932.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 3020501.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "pDNA_Reads    341184.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 544008.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "Rep_A_Reads    544008.0\n",
      "Rep_B_Reads    635373.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 544008.0 counts\n",
      "Sorting gene pairs and guides based on ordering gene ordering...\n",
      "Available singles: 3374\n",
      "Available duals: 5400\n",
      "Available control: 441\n",
      "Filtered single sgRNA count: 0\n",
      "Filtered gene count: 0\n",
      "Filtered gene count: 0\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: MEDIAN_NB_SCORE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:124: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-dual-IS'] = dual['FC'].values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-single-IS-Guide-1'] = EC_1.values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:126: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-single-IS-Guide-2'] = EC_2.values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-dual-SL-sgRNA'] = dual['FC'].values - EC_1.values - EC_2.values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:165: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-dual-IS'] = dual['FC'].values - control_median\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:166: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-single-IS-Guide-1'] = EC_1.values - control_median\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-single-IS-Guide-2'] = EC_2.values - control_median\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:168: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-dual-SL-sgRNA'] = (dual['FC'].values - control_median) - (EC_1.values - control_median) - (EC_2.values - control_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 300\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: MEDIAN_B_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 300\n",
      "---------------------\n",
      "Working on study: parrish_data\n",
      "Working on cell line: HELA\n",
      "Checking if score already computed: MEDIAN_NB_SCORE\n",
      "Running median scores...\n",
      "Getting raw counts...\n",
      "Filtering enabled... Condition: 35 counts\n",
      "Filtered a total of 0 out of 31833 sgRNAs.\n",
      "\n",
      "---\n",
      "\n",
      "Not full normalization...\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "plasmid_1    468996.67\n",
      "plasmid_2    522803.80\n",
      "plasmid_3    524885.28\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 669420.108 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "LTP_1    813954.936\n",
      "LTP_2    930812.115\n",
      "LTP_3    936990.738\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 669420.108 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "plasmid_1    1.583331e+07\n",
      "plasmid_2    1.765058e+07\n",
      "plasmid_3    1.772088e+07\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 18741654.749250002 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "LTP_1    1.976243e+07\n",
      "LTP_2    2.219216e+07\n",
      "LTP_3    2.218181e+07\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 18741654.749250002 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "plasmid_1    1.614935e+07\n",
      "plasmid_2    1.800373e+07\n",
      "plasmid_3    1.807547e+07\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 15998347.7728 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "LTP_1    1.407944e+07\n",
      "LTP_2    1.584735e+07\n",
      "LTP_3    1.550406e+07\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 15998347.7728 counts\n",
      "Sorting gene pairs and guides based on ordering gene ordering...\n",
      "Available singles: 15878\n",
      "Available duals: 15465\n",
      "Available control: 490\n",
      "Filtered single sgRNA count: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:124: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-dual-IS'] = dual['FC'].values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-single-IS-Guide-1'] = EC_1.values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:126: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-single-IS-Guide-2'] = EC_2.values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-dual-SL-sgRNA'] = dual['FC'].values - EC_1.values - EC_2.values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered gene count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:165: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-dual-IS'] = dual['FC'].values - control_median\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:166: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-single-IS-Guide-1'] = EC_1.values - control_median\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-single-IS-Guide-2'] = EC_2.values - control_median\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:168: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-dual-SL-sgRNA'] = (dual['FC'].values - control_median) - (EC_1.values - control_median) - (EC_2.values - control_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered gene count: 0\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: MEDIAN_NB_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 1030\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: MEDIAN_B_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 1030\n",
      "---------------------\n",
      "Working on cell line: PC9\n",
      "Checking if score already computed: MEDIAN_NB_SCORE\n",
      "Running median scores...\n",
      "Getting raw counts...\n",
      "Filtering enabled... Condition: 35 counts\n",
      "Filtered a total of 0 out of 32740 sgRNAs.\n",
      "\n",
      "---\n",
      "\n",
      "Not full normalization...\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "plasmid_1    422252.993\n",
      "plasmid_2    410554.421\n",
      "plasmid_3    378813.398\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 445240.2355 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "LTP_1    502102.581\n",
      "LTP_2    515471.323\n",
      "LTP_3    468227.478\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 445240.2355 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "plasmid_1    1.456573e+07\n",
      "plasmid_2    1.416191e+07\n",
      "plasmid_3    1.306632e+07\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 14499502.423999999 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "LTP_1    1.610231e+07\n",
      "LTP_2    1.563642e+07\n",
      "LTP_3    1.443328e+07\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 14499502.423999999 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "plasmid_1    1.515278e+07\n",
      "plasmid_2    1.473253e+07\n",
      "plasmid_3    1.359235e+07\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 14228697.41955 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "LTP_1    1.442529e+07\n",
      "LTP_2    1.403210e+07\n",
      "LTP_3    1.298875e+07\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 14228697.41955 counts\n",
      "Sorting gene pairs and guides based on ordering gene ordering...\n",
      "Available singles: 16082\n",
      "Available duals: 16165\n",
      "Available control: 493\n",
      "Filtered single sgRNA count: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:124: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-dual-IS'] = dual['FC'].values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-single-IS-Guide-1'] = EC_1.values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:126: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-single-IS-Guide-2'] = EC_2.values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-dual-SL-sgRNA'] = dual['FC'].values - EC_1.values - EC_2.values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered gene count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:165: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-dual-IS'] = dual['FC'].values - control_median\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:166: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-single-IS-Guide-1'] = EC_1.values - control_median\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-single-IS-Guide-2'] = EC_2.values - control_median\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:168: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-dual-SL-sgRNA'] = (dual['FC'].values - control_median) - (EC_1.values - control_median) - (EC_2.values - control_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered gene count: 0\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: MEDIAN_NB_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 1030\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: MEDIAN_B_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 1030\n",
      "---------------------\n",
      "Working on study: shantang_data\n",
      "Working on cell line: 22RV1\n",
      "Checking if score already computed: MEDIAN_NB_SCORE\n",
      "Running median scores...\n",
      "Getting raw counts...\n",
      "Filtering enabled... Condition: 35 counts\n",
      "Filtered a total of 8134 out of 48931 sgRNAs.\n",
      "\n",
      "---\n",
      "\n",
      "Not full normalization...\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "T0_1    4174896.0\n",
      "T0_2    4200469.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 4771163.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "T12_1    5341857.0\n",
      "T12_2    6456429.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 4771163.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "T0_1    877394.0\n",
      "T0_2    878730.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 1064517.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "T12_1    1250304.0\n",
      "T12_2    1491109.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 1064517.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "T0_1    34419.0\n",
      "T0_2    34661.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 44888.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "T12_1    55115.0\n",
      "T12_2    65234.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 44888.0 counts\n",
      "Sorting gene pairs and guides based on ordering gene ordering...\n",
      "Available singles: 7673\n",
      "Available duals: 32780\n",
      "Available control: 344\n",
      "Filtered single sgRNA count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:124: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-dual-IS'] = dual['FC'].values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-single-IS-Guide-1'] = EC_1.values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:126: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-single-IS-Guide-2'] = EC_2.values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-dual-SL-sgRNA'] = dual['FC'].values - EC_1.values - EC_2.values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:165: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-dual-IS'] = dual['FC'].values - control_median\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:166: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-single-IS-Guide-1'] = EC_1.values - control_median\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-single-IS-Guide-2'] = EC_2.values - control_median\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:168: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-dual-SL-sgRNA'] = (dual['FC'].values - control_median) - (EC_1.values - control_median) - (EC_2.values - control_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered gene count: 0\n",
      "Filtered gene count: 0\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: MEDIAN_NB_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 1225\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: MEDIAN_B_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 1225\n",
      "---------------------\n",
      "Working on study: wong_data\n",
      "Working on cell line: OVCAR8\n",
      "Checking if score already computed: MEDIAN_NB_SCORE\n",
      "Running median scores...\n",
      "Getting raw counts...\n",
      "Filtering enabled... Condition: 35 counts\n",
      "Filtered a total of 812 out of 23409 sgRNAs.\n",
      "\n",
      "---\n",
      "\n",
      "Not full normalization...\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "day5 (Replicate 1)    28372036.0\n",
      "day5 (Replicate 2)    27787859.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 28079947.5 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "day20 (Replicate 1)    32287131.0\n",
      "day20 (Replicate 2)    23231108.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 28079947.5 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "day5 (Replicate 1)    1800385.0\n",
      "day5 (Replicate 2)    1684723.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 1742554.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "day20 (Replicate 1)    2006287.0\n",
      "day20 (Replicate 2)    1467833.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 1742554.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "day5 (Replicate 1)    11397.0\n",
      "day5 (Replicate 2)     9032.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 10214.5 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "day20 (Replicate 1)    11730.0\n",
      "day20 (Replicate 2)     8930.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 10214.5 counts\n",
      "Sorting gene pairs and guides based on ordering gene ordering...\n",
      "Available singles: 1317\n",
      "Available duals: 21271\n",
      "Available control: 9\n",
      "Filtered single sgRNA count: 0\n",
      "Filtered gene count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:124: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-dual-IS'] = dual['FC'].values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-single-IS-Guide-1'] = EC_1.values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:126: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-single-IS-Guide-2'] = EC_2.values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-dual-SL-sgRNA'] = dual['FC'].values - EC_1.values - EC_2.values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:165: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-dual-IS'] = dual['FC'].values - control_median\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:166: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-single-IS-Guide-1'] = EC_1.values - control_median\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-single-IS-Guide-2'] = EC_2.values - control_median\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:168: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-B-dual-SL-sgRNA'] = (dual['FC'].values - control_median) - (EC_1.values - control_median) - (EC_2.values - control_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered gene count: 0\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: MEDIAN_NB_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 1225\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: MEDIAN_B_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 1225\n",
      "---------------------\n",
      "Working on study: zhao_data\n",
      "Working on cell line: HELA\n",
      "Checking if score already computed: MEDIAN_NB_SCORE\n",
      "Running median scores...\n",
      "Getting raw counts...\n",
      "Filtering enabled... Condition: 35 counts\n",
      "Filtered a total of 662 out of 11934 sgRNAs.\n",
      "\n",
      "---\n",
      "\n",
      "Not full normalization...\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "Hela_MV4_d3_1_S1_trimmed53_len_filtered_counts    263437.0\n",
      "Hela_MV4_d3_2_S2_trimmed53_len_filtered_counts    240792.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 279991.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "Hela_MV4_d28_1_S5_trimmed53_len_filtered_counts    311450.0\n",
      "Hela_MV4_d28_2_S6_trimmed53_len_filtered_counts    296545.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 279991.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "Hela_MV4_d3_1_S1_trimmed53_len_filtered_counts    4960359.0\n",
      "Hela_MV4_d3_2_S2_trimmed53_len_filtered_counts    4576331.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 4310349.5 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "Hela_MV4_d28_1_S5_trimmed53_len_filtered_counts    4044368.0\n",
      "Hela_MV4_d28_2_S6_trimmed53_len_filtered_counts    3815833.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 4310349.5 counts\n",
      "Sorting gene pairs and guides based on ordering gene ordering...\n",
      "Available singles: 443\n",
      "Available duals: 10829\n",
      "Available control: 0\n",
      "Filtered single sgRNA count: 1\n",
      "Filtered gene count: 0\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: MEDIAN_NB_SCORE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:124: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-dual-IS'] = dual['FC'].values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-single-IS-Guide-1'] = EC_1.values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:126: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-single-IS-Guide-2'] = EC_2.values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-dual-SL-sgRNA'] = dual['FC'].values - EC_1.values - EC_2.values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 1275\n",
      "---------------------\n",
      "Working on cell line: A549\n",
      "Checking if score already computed: MEDIAN_NB_SCORE\n",
      "Running median scores...\n",
      "Getting raw counts...\n",
      "Filtering enabled... Condition: 35 counts\n",
      "Filtered a total of 445 out of 11934 sgRNAs.\n",
      "\n",
      "---\n",
      "\n",
      "Not full normalization...\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "A549_MV4_d3_1_S1_trimmed53_len_filtered_counts    318714.0\n",
      "A549_MV4_d3_2_S2_trimmed53_len_filtered_counts    366817.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 386171.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "A549_MV4_d28_1_S7_trimmed53_len_filtered_counts    405525.0\n",
      "A549_MV4_d28_2_S8_trimmed53_len_filtered_counts    416768.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 386171.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "A549_MV4_d3_1_S1_trimmed53_len_filtered_counts    6193814.0\n",
      "A549_MV4_d3_2_S2_trimmed53_len_filtered_counts    6832663.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 6314277.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "A549_MV4_d28_1_S7_trimmed53_len_filtered_counts    6007062.0\n",
      "A549_MV4_d28_2_S8_trimmed53_len_filtered_counts    6434740.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 6314277.0 counts\n",
      "Sorting gene pairs and guides based on ordering gene ordering...\n",
      "Available singles: 449\n",
      "Available duals: 11040\n",
      "Available control: 0\n",
      "Filtered single sgRNA count: 1\n",
      "Filtered gene count: 0\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: MEDIAN_NB_SCORE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:124: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-dual-IS'] = dual['FC'].values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-single-IS-Guide-1'] = EC_1.values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:126: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-single-IS-Guide-2'] = EC_2.values\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/2692512166.py:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['Median-NB-dual-SL-sgRNA'] = dual['FC'].values - EC_1.values - EC_2.values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 1275\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "for curr_study in available_studies:\n",
    "    print('Working on study: ' + curr_study)\n",
    "\n",
    "    # get study counts and seq\n",
    "    study_counts = counts.loc[counts['study_origin'] == study_name_to_pubmed_id[curr_study]].copy()\n",
    "\n",
    "    curr_seq_ids = np.array(sorted(list(set(study_counts['guide_1_id'].tolist() + study_counts['guide_2_id'].tolist()))))\n",
    "    study_sequences = experiment_design.loc[curr_seq_ids]\n",
    "\n",
    "    # the analysis runs for each individual cell line\n",
    "    available_cell_lines = set(study_counts['cell_line_origin'])\n",
    "\n",
    "    for curr_cl in available_cell_lines:\n",
    "        print('Working on cell line: ' + curr_cl)\n",
    "        curr_counts = study_counts.loc[study_counts['cell_line_origin'] == curr_cl].copy()\n",
    "\n",
    "        # run median scores\n",
    "        if not check_if_added_to_table(curr_counts.copy(), 'MEDIAN_NB_SCORE', SLKB_engine):\n",
    "            median_res = run_median_scores(curr_counts.copy(), full_normalization = False)\n",
    "            add_table_to_db(curr_counts.copy(), median_res['MEDIAN_NB_SCORE'], 'MEDIAN_NB_SCORE', SLKB_engine)\n",
    "            if median_res['MEDIAN_B_SCORE'] is not None:\n",
    "                add_table_to_db(curr_counts.copy(), median_res['MEDIAN_B_SCORE'], 'MEDIAN_B_SCORE', SLKB_engine)\n",
    "        else:\n",
    "            print('Skipping median score...')\n",
    "            \n",
    "        print('---------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "622cc617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on study: diehl_data\n",
      "Working on cell line: RPE1\n",
      "Checking if score already computed: SGRA_DERIVED_NB_SCORE\n",
      "Running sgrna derived score...\n",
      "Getting raw counts...\n",
      "Filtering enabled... Condition: 35 counts\n",
      "Filtered a total of 9757 out of 248191 sgRNAs.\n",
      "\n",
      "---\n",
      "\n",
      "Not full normalization...\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "ctrl_1    3434902.0\n",
      "ctrl_2    2905388.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 59882.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "rep_1    43897.0\n",
      "rep_2    59882.0\n",
      "rep_3    23578.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 59882.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "ctrl_1    49753319.0\n",
      "ctrl_2    41904226.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 1621160.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "rep_1    1621160.0\n",
      "rep_2    1589753.0\n",
      "rep_3     550919.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 1621160.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "ctrl_1    171179130.0\n",
      "ctrl_2    143161060.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 8077727.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "rep_1    8077727.0\n",
      "rep_2    7604781.0\n",
      "rep_3    2737975.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 8077727.0 counts\n",
      "Mismatch times, averaging...\n",
      "Sorting gene pairs and guides based on ordering gene ordering...\n",
      "Starting scoring..\n",
      "calculating for replicate 0\n",
      "Filtered single sgRNA count: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:142: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'].isna()] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:143: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'] == 0] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single['FC'] = single['FC'] - EC_control\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['FC'] = dual['FC'] - EC_control\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered single sgRNA count: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:212: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'].isna()] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:213: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'] == 0] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------ADDING-TO-DB---------\n",
      "Processing table for: SGRA_DERIVED_NB_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 10720\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: SGRA_DERIVED_B_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 10720\n",
      "---------------------\n",
      "Working on study: horlbeck_data\n",
      "Working on cell line: JURKAT\n",
      "Checking if score already computed: SGRA_DERIVED_NB_SCORE\n",
      "Running sgrna derived score...\n",
      "Getting raw counts...\n",
      "Filtering enabled... Condition: 35 counts\n",
      "Filtered a total of 128359 out of 1044484 sgRNAs.\n",
      "\n",
      "---\n",
      "\n",
      "Not full normalization...\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "JURKAT_tripleseq,T0,rep1    67829.0\n",
      "JURKAT_tripleseq,T0,rep2    52320.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 89585.5 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "JURKAT_tripleseq,cyc,rep1    111342.0\n",
      "JURKAT_tripleseq,cyc,rep2    130002.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 89585.5 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "JURKAT_tripleseq,T0,rep1    10110190.0\n",
      "JURKAT_tripleseq,T0,rep2     7967463.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 10178674.5 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "JURKAT_tripleseq,cyc,rep1    10247159.0\n",
      "JURKAT_tripleseq,cyc,rep2    11858053.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 10178674.5 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "JURKAT_tripleseq,T0,rep1    320133675.0\n",
      "JURKAT_tripleseq,T0,rep2    253657246.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 254499846.5 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "JURKAT_tripleseq,cyc,rep1    227568286.0\n",
      "JURKAT_tripleseq,cyc,rep2    255342447.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 254499846.5 counts\n",
      "Sorting gene pairs and guides based on ordering gene ordering...\n",
      "Starting scoring..\n",
      "calculating for replicate 0\n",
      "Filtered single sgRNA count: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:142: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'].isna()] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:143: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'] == 0] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single['FC'] = single['FC'] - EC_control\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['FC'] = dual['FC'] - EC_control\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered single sgRNA count: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:212: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'].isna()] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:213: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'] == 0] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating for replicate 1\n",
      "Filtered single sgRNA count: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:142: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'].isna()] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:143: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'] == 0] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single['FC'] = single['FC'] - EC_control\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['FC'] = dual['FC'] - EC_control\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered single sgRNA count: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:212: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'].isna()] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:213: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'] == 0] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------ADDING-TO-DB---------\n",
      "Processing table for: SGRA_DERIVED_NB_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 110614\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: SGRA_DERIVED_B_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 110614\n",
      "---------------------\n",
      "Working on cell line: K562\n",
      "Checking if score already computed: SGRA_DERIVED_NB_SCORE\n",
      "Running sgrna derived score...\n",
      "Getting raw counts...\n",
      "Filtering enabled... Condition: 35 counts\n",
      "Filtered a total of 92141 out of 1044484 sgRNAs.\n",
      "\n",
      "---\n",
      "\n",
      "Not full normalization...\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "K562_barcode,T0,rep1     90567.0\n",
      "K562_barcode,T0,rep2    105269.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 339731.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "K562_tripleseq,cyc,rep1    627562.0\n",
      "K562_tripleseq,cyc,rep2    574193.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 339731.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "K562_barcode,T0,rep1    13775507.0\n",
      "K562_barcode,T0,rep2    15538057.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 17525698.5 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "K562_tripleseq,cyc,rep1    23202008.0\n",
      "K562_tripleseq,cyc,rep2    19513340.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 17525698.5 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "K562_barcode,T0,rep1    433279037.0\n",
      "K562_barcode,T0,rep2    482402577.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 376245319.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "K562_tripleseq,cyc,rep1    319211601.0\n",
      "K562_tripleseq,cyc,rep2    263341379.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 376245319.0 counts\n",
      "Sorting gene pairs and guides based on ordering gene ordering...\n",
      "Starting scoring..\n",
      "calculating for replicate 0\n",
      "Filtered single sgRNA count: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:142: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'].isna()] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:143: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'] == 0] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single['FC'] = single['FC'] - EC_control\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['FC'] = dual['FC'] - EC_control\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered single sgRNA count: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:212: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'].isna()] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:213: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'] == 0] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating for replicate 1\n",
      "Filtered single sgRNA count: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:142: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'].isna()] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:143: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'] == 0] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single['FC'] = single['FC'] - EC_control\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['FC'] = dual['FC'] - EC_control\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered single sgRNA count: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:212: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'].isna()] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:213: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'] == 0] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------ADDING-TO-DB---------\n",
      "Processing table for: SGRA_DERIVED_NB_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 110684\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: SGRA_DERIVED_B_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 110684\n",
      "---------------------\n",
      "Working on study: najm_data\n",
      "Working on cell line: HT29\n",
      "Checking if score already computed: SGRA_DERIVED_NB_SCORE\n",
      "Running sgrna derived score...\n",
      "Getting raw counts...\n",
      "Removing NA replicate from TEnd...\n",
      "Filtering enabled... Condition: 35 counts\n",
      "Filtered a total of 1 out of 9216 sgRNAs.\n",
      "\n",
      "---\n",
      "\n",
      "Not full normalization...\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "pDNA_Reads    3609228.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 3609228.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "Rep_A_Reads    3009073.0\n",
      "Rep_B_Reads    4006083.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 3609228.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "pDNA_Reads    2407466.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 2438869.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "Rep_A_Reads    2438869.0\n",
      "Rep_B_Reads    3266357.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 2438869.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "pDNA_Reads    341184.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 440351.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "Rep_A_Reads    440351.0\n",
      "Rep_B_Reads    590592.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 440351.0 counts\n",
      "Mismatch times, averaging...\n",
      "Sorting gene pairs and guides based on ordering gene ordering...\n",
      "Starting scoring..\n",
      "calculating for replicate 0\n",
      "Filtered single sgRNA count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:142: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'].isna()] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:143: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'] == 0] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single['FC'] = single['FC'] - EC_control\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['FC'] = dual['FC'] - EC_control\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered single sgRNA count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:212: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'].isna()] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:213: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'] == 0] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------ADDING-TO-DB---------\n",
      "Processing table for: SGRA_DERIVED_NB_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 300\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: SGRA_DERIVED_B_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 300\n",
      "---------------------\n",
      "Working on cell line: A549\n",
      "Checking if score already computed: SGRA_DERIVED_NB_SCORE\n",
      "Running sgrna derived score...\n",
      "Getting raw counts...\n",
      "Removing NA replicate from TEnd...\n",
      "Filtering enabled... Condition: 35 counts\n",
      "Filtered a total of 1 out of 9216 sgRNAs.\n",
      "\n",
      "---\n",
      "\n",
      "Not full normalization...\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "pDNA_Reads    3609228.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 3933111.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "Rep_A_Reads    3933111.0\n",
      "Rep_B_Reads    4567319.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 3933111.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "pDNA_Reads    2407466.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 3650146.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "Rep_A_Reads    3650146.0\n",
      "Rep_B_Reads    4233101.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 3650146.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "pDNA_Reads    341184.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 768155.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "Rep_A_Reads    768155.0\n",
      "Rep_B_Reads    889178.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 768155.0 counts\n",
      "Mismatch times, averaging...\n",
      "Sorting gene pairs and guides based on ordering gene ordering...\n",
      "Starting scoring..\n",
      "calculating for replicate 0\n",
      "Filtered single sgRNA count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:142: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'].isna()] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:143: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'] == 0] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single['FC'] = single['FC'] - EC_control\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['FC'] = dual['FC'] - EC_control\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered single sgRNA count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:212: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'].isna()] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:213: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'] == 0] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------ADDING-TO-DB---------\n",
      "Processing table for: SGRA_DERIVED_NB_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 300\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: SGRA_DERIVED_B_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 300\n",
      "---------------------\n",
      "Working on cell line: OVCAR8\n",
      "Checking if score already computed: SGRA_DERIVED_NB_SCORE\n",
      "Running sgrna derived score...\n",
      "Getting raw counts...\n",
      "Filtering enabled... Condition: 35 counts\n",
      "Filtered a total of 1 out of 9216 sgRNAs.\n",
      "\n",
      "---\n",
      "\n",
      "Not full normalization...\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "pDNA_Reads    3609228.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 2499117.5 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "Rep_A_Reads    1540891.0\n",
      "Rep_B_Reads    1515861.0\n",
      "Rep_C_Reads    3457344.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 2499117.5 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "pDNA_Reads    2407466.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 1809065.5 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "Rep_A_Reads    1210665.0\n",
      "Rep_B_Reads    1194598.0\n",
      "Rep_C_Reads    2737491.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 1809065.5 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "pDNA_Reads    341184.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 275056.5 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "Rep_A_Reads    208929.0\n",
      "Rep_B_Reads    208275.0\n",
      "Rep_C_Reads    474433.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 275056.5 counts\n",
      "Mismatch times, averaging...\n",
      "Sorting gene pairs and guides based on ordering gene ordering...\n",
      "Starting scoring..\n",
      "calculating for replicate 0\n",
      "Filtered single sgRNA count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:142: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'].isna()] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:143: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'] == 0] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single['FC'] = single['FC'] - EC_control\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['FC'] = dual['FC'] - EC_control\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered single sgRNA count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:212: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'].isna()] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:213: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'] == 0] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------ADDING-TO-DB---------\n",
      "Processing table for: SGRA_DERIVED_NB_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 300\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: SGRA_DERIVED_B_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 300\n",
      "---------------------\n",
      "Working on cell line: A375\n",
      "Checking if score already computed: SGRA_DERIVED_NB_SCORE\n",
      "Running sgrna derived score...\n",
      "Getting raw counts...\n",
      "Filtering enabled... Condition: 35 counts\n",
      "Filtered a total of 1 out of 9216 sgRNAs.\n",
      "\n",
      "---\n",
      "\n",
      "Not full normalization...\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "pDNA_Reads    3609228.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 3141784.5 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "Rep_A_Reads    3399698.0\n",
      "Rep_B_Reads    2883871.0\n",
      "Rep_C_Reads    2112357.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 3141784.5 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "pDNA_Reads    2407466.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 2540828.5 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "Rep_A_Reads    3174784.0\n",
      "Rep_B_Reads    2674191.0\n",
      "Rep_C_Reads    1956303.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 2540828.5 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "pDNA_Reads    341184.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 479825.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "Rep_A_Reads    662297.0\n",
      "Rep_B_Reads    554649.0\n",
      "Rep_C_Reads    405001.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 479825.0 counts\n",
      "Mismatch times, averaging...\n",
      "Sorting gene pairs and guides based on ordering gene ordering...\n",
      "Starting scoring..\n",
      "calculating for replicate 0\n",
      "Filtered single sgRNA count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:142: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'].isna()] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:143: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'] == 0] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single['FC'] = single['FC'] - EC_control\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['FC'] = dual['FC'] - EC_control\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered single sgRNA count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:212: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'].isna()] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:213: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'] == 0] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------ADDING-TO-DB---------\n",
      "Processing table for: SGRA_DERIVED_NB_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 300\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: SGRA_DERIVED_B_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 300\n",
      "---------------------\n",
      "Working on cell line: 786O\n",
      "Checking if score already computed: SGRA_DERIVED_NB_SCORE\n",
      "Running sgrna derived score...\n",
      "Getting raw counts...\n",
      "Filtering enabled... Condition: 35 counts\n",
      "Filtered a total of 1 out of 9216 sgRNAs.\n",
      "\n",
      "---\n",
      "\n",
      "Not full normalization...\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "pDNA_Reads    3609228.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 4237644.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "Rep_A_Reads    6257808.0\n",
      "Rep_B_Reads    4094431.0\n",
      "Rep_C_Reads    4380857.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 4237644.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "pDNA_Reads    2407466.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 3228455.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "Rep_A_Reads    4770033.0\n",
      "Rep_B_Reads    3114367.0\n",
      "Rep_C_Reads    3342543.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 3228455.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "pDNA_Reads    341184.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 543765.5 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "Rep_A_Reads    803810.0\n",
      "Rep_B_Reads    523893.0\n",
      "Rep_C_Reads    563638.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 543765.5 counts\n",
      "Mismatch times, averaging...\n",
      "Sorting gene pairs and guides based on ordering gene ordering...\n",
      "Starting scoring..\n",
      "calculating for replicate 0\n",
      "Filtered single sgRNA count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:142: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'].isna()] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:143: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'] == 0] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single['FC'] = single['FC'] - EC_control\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['FC'] = dual['FC'] - EC_control\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered single sgRNA count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:212: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'].isna()] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:213: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'] == 0] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------ADDING-TO-DB---------\n",
      "Processing table for: SGRA_DERIVED_NB_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 300\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: SGRA_DERIVED_B_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 300\n",
      "---------------------\n",
      "Working on cell line: MELJUSO\n",
      "Checking if score already computed: SGRA_DERIVED_NB_SCORE\n",
      "Running sgrna derived score...\n",
      "Getting raw counts...\n",
      "Removing NA replicate from TEnd...\n",
      "Filtering enabled... Condition: 35 counts\n",
      "Filtered a total of 1 out of 9216 sgRNAs.\n",
      "\n",
      "---\n",
      "\n",
      "Not full normalization...\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "pDNA_Reads    3609228.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 3643736.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "Rep_A_Reads    3643736.0\n",
      "Rep_B_Reads    4225805.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 3643736.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "pDNA_Reads    2407466.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 3020501.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "Rep_A_Reads    3020501.0\n",
      "Rep_B_Reads    3512932.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 3020501.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "pDNA_Reads    341184.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 544008.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "Rep_A_Reads    544008.0\n",
      "Rep_B_Reads    635373.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 544008.0 counts\n",
      "Mismatch times, averaging...\n",
      "Sorting gene pairs and guides based on ordering gene ordering...\n",
      "Starting scoring..\n",
      "calculating for replicate 0\n",
      "Filtered single sgRNA count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:142: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'].isna()] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:143: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'] == 0] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single['FC'] = single['FC'] - EC_control\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['FC'] = dual['FC'] - EC_control\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered single sgRNA count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:212: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'].isna()] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:213: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'] == 0] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------ADDING-TO-DB---------\n",
      "Processing table for: SGRA_DERIVED_NB_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 300\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: SGRA_DERIVED_B_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 300\n",
      "---------------------\n",
      "Working on study: parrish_data\n",
      "Working on cell line: HELA\n",
      "Checking if score already computed: SGRA_DERIVED_NB_SCORE\n",
      "Running sgrna derived score...\n",
      "Getting raw counts...\n",
      "Filtering enabled... Condition: 35 counts\n",
      "Filtered a total of 0 out of 31833 sgRNAs.\n",
      "\n",
      "---\n",
      "\n",
      "Not full normalization...\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "plasmid_1    468996.67\n",
      "plasmid_2    522803.80\n",
      "plasmid_3    524885.28\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 669420.108 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "LTP_1    813954.936\n",
      "LTP_2    930812.115\n",
      "LTP_3    936990.738\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 669420.108 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "plasmid_1    1.583331e+07\n",
      "plasmid_2    1.765058e+07\n",
      "plasmid_3    1.772088e+07\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 18741654.749250002 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "LTP_1    1.976243e+07\n",
      "LTP_2    2.219216e+07\n",
      "LTP_3    2.218181e+07\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 18741654.749250002 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "plasmid_1    1.614935e+07\n",
      "plasmid_2    1.800373e+07\n",
      "plasmid_3    1.807547e+07\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 15998347.7728 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "LTP_1    1.407944e+07\n",
      "LTP_2    1.584735e+07\n",
      "LTP_3    1.550406e+07\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 15998347.7728 counts\n",
      "Sorting gene pairs and guides based on ordering gene ordering...\n",
      "Starting scoring..\n",
      "calculating for replicate 0\n",
      "Filtered single sgRNA count: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:142: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'].isna()] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:143: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'] == 0] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single['FC'] = single['FC'] - EC_control\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['FC'] = dual['FC'] - EC_control\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered single sgRNA count: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:212: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'].isna()] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:213: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'] == 0] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating for replicate 1\n",
      "Filtered single sgRNA count: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:142: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'].isna()] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:143: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'] == 0] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single['FC'] = single['FC'] - EC_control\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['FC'] = dual['FC'] - EC_control\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered single sgRNA count: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:212: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'].isna()] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:213: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'] == 0] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating for replicate 2\n",
      "Filtered single sgRNA count: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:142: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'].isna()] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:143: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'] == 0] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single['FC'] = single['FC'] - EC_control\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['FC'] = dual['FC'] - EC_control\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered single sgRNA count: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:212: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'].isna()] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:213: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'] == 0] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------ADDING-TO-DB---------\n",
      "Processing table for: SGRA_DERIVED_NB_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 1030\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: SGRA_DERIVED_B_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 1030\n",
      "---------------------\n",
      "Working on cell line: PC9\n",
      "Checking if score already computed: SGRA_DERIVED_NB_SCORE\n",
      "Running sgrna derived score...\n",
      "Getting raw counts...\n",
      "Filtering enabled... Condition: 35 counts\n",
      "Filtered a total of 0 out of 32740 sgRNAs.\n",
      "\n",
      "---\n",
      "\n",
      "Not full normalization...\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "plasmid_1    422252.993\n",
      "plasmid_2    410554.421\n",
      "plasmid_3    378813.398\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 445240.2355 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "LTP_1    502102.581\n",
      "LTP_2    515471.323\n",
      "LTP_3    468227.478\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 445240.2355 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "plasmid_1    1.456573e+07\n",
      "plasmid_2    1.416191e+07\n",
      "plasmid_3    1.306632e+07\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 14499502.423999999 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "LTP_1    1.610231e+07\n",
      "LTP_2    1.563642e+07\n",
      "LTP_3    1.443328e+07\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 14499502.423999999 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "plasmid_1    1.515278e+07\n",
      "plasmid_2    1.473253e+07\n",
      "plasmid_3    1.359235e+07\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 14228697.41955 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "LTP_1    1.442529e+07\n",
      "LTP_2    1.403210e+07\n",
      "LTP_3    1.298875e+07\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 14228697.41955 counts\n",
      "Sorting gene pairs and guides based on ordering gene ordering...\n",
      "Starting scoring..\n",
      "calculating for replicate 0\n",
      "Filtered single sgRNA count: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:142: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'].isna()] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:143: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'] == 0] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single['FC'] = single['FC'] - EC_control\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['FC'] = dual['FC'] - EC_control\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered single sgRNA count: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:212: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'].isna()] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:213: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'] == 0] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating for replicate 1\n",
      "Filtered single sgRNA count: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:142: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'].isna()] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:143: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'] == 0] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single['FC'] = single['FC'] - EC_control\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['FC'] = dual['FC'] - EC_control\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered single sgRNA count: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:212: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'].isna()] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:213: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'] == 0] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating for replicate 2\n",
      "Filtered single sgRNA count: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:142: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'].isna()] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:143: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'] == 0] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single['FC'] = single['FC'] - EC_control\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['FC'] = dual['FC'] - EC_control\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered single sgRNA count: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:212: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'].isna()] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:213: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'] == 0] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------ADDING-TO-DB---------\n",
      "Processing table for: SGRA_DERIVED_NB_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 1030\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: SGRA_DERIVED_B_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 1030\n",
      "---------------------\n",
      "Working on study: shantang_data\n",
      "Working on cell line: 22RV1\n",
      "Checking if score already computed: SGRA_DERIVED_NB_SCORE\n",
      "Running sgrna derived score...\n",
      "Getting raw counts...\n",
      "Filtering enabled... Condition: 35 counts\n",
      "Filtered a total of 8134 out of 48931 sgRNAs.\n",
      "\n",
      "---\n",
      "\n",
      "Not full normalization...\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "T0_1    4174896.0\n",
      "T0_2    4200469.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 4771163.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "T12_1    5341857.0\n",
      "T12_2    6456429.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 4771163.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "T0_1    877394.0\n",
      "T0_2    878730.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 1064517.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "T12_1    1250304.0\n",
      "T12_2    1491109.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 1064517.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "T0_1    34419.0\n",
      "T0_2    34661.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 44888.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "T12_1    55115.0\n",
      "T12_2    65234.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 44888.0 counts\n",
      "Sorting gene pairs and guides based on ordering gene ordering...\n",
      "Starting scoring..\n",
      "calculating for replicate 0\n",
      "Filtered single sgRNA count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:142: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'].isna()] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:143: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'] == 0] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single['FC'] = single['FC'] - EC_control\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['FC'] = dual['FC'] - EC_control\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered single sgRNA count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:212: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'].isna()] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:213: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'] == 0] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating for replicate 1\n",
      "Filtered single sgRNA count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:142: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'].isna()] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:143: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'] == 0] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single['FC'] = single['FC'] - EC_control\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['FC'] = dual['FC'] - EC_control\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered single sgRNA count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:212: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'].isna()] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:213: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'] == 0] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------ADDING-TO-DB---------\n",
      "Processing table for: SGRA_DERIVED_NB_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 1225\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: SGRA_DERIVED_B_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 1225\n",
      "---------------------\n",
      "Working on study: wong_data\n",
      "Working on cell line: OVCAR8\n",
      "Checking if score already computed: SGRA_DERIVED_NB_SCORE\n",
      "Running sgrna derived score...\n",
      "Getting raw counts...\n",
      "Filtering enabled... Condition: 35 counts\n",
      "Filtered a total of 812 out of 23409 sgRNAs.\n",
      "\n",
      "---\n",
      "\n",
      "Not full normalization...\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "day5 (Replicate 1)    28372036.0\n",
      "day5 (Replicate 2)    27787859.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 28079947.5 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "day20 (Replicate 1)    32287131.0\n",
      "day20 (Replicate 2)    23231108.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 28079947.5 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "day5 (Replicate 1)    1800385.0\n",
      "day5 (Replicate 2)    1684723.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 1742554.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "day20 (Replicate 1)    2006287.0\n",
      "day20 (Replicate 2)    1467833.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 1742554.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "day5 (Replicate 1)    11397.0\n",
      "day5 (Replicate 2)     9032.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 10214.5 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "day20 (Replicate 1)    11730.0\n",
      "day20 (Replicate 2)     8930.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 10214.5 counts\n",
      "Sorting gene pairs and guides based on ordering gene ordering...\n",
      "Starting scoring..\n",
      "calculating for replicate 0\n",
      "Filtered single sgRNA count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:142: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'].isna()] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:143: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'] == 0] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single['FC'] = single['FC'] - EC_control\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['FC'] = dual['FC'] - EC_control\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered single sgRNA count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:212: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'].isna()] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:213: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'] == 0] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating for replicate 1\n",
      "Filtered single sgRNA count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:142: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'].isna()] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:143: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'] == 0] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  single['FC'] = single['FC'] - EC_control\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dual['FC'] = dual['FC'] - EC_control\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered single sgRNA count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:212: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'].isna()] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:213: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'] == 0] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------ADDING-TO-DB---------\n",
      "Processing table for: SGRA_DERIVED_NB_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 1225\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: SGRA_DERIVED_B_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 1225\n",
      "---------------------\n",
      "Working on study: zhao_data\n",
      "Working on cell line: HELA\n",
      "Checking if score already computed: SGRA_DERIVED_NB_SCORE\n",
      "Running sgrna derived score...\n",
      "Getting raw counts...\n",
      "Filtering enabled... Condition: 35 counts\n",
      "Filtered a total of 662 out of 11934 sgRNAs.\n",
      "\n",
      "---\n",
      "\n",
      "Not full normalization...\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "Hela_MV4_d3_1_S1_trimmed53_len_filtered_counts    263437.0\n",
      "Hela_MV4_d3_2_S2_trimmed53_len_filtered_counts    240792.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 279991.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "Hela_MV4_d28_1_S5_trimmed53_len_filtered_counts    311450.0\n",
      "Hela_MV4_d28_2_S6_trimmed53_len_filtered_counts    296545.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 279991.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "Hela_MV4_d3_1_S1_trimmed53_len_filtered_counts    4960359.0\n",
      "Hela_MV4_d3_2_S2_trimmed53_len_filtered_counts    4576331.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 4310349.5 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "Hela_MV4_d28_1_S5_trimmed53_len_filtered_counts    4044368.0\n",
      "Hela_MV4_d28_2_S6_trimmed53_len_filtered_counts    3815833.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 4310349.5 counts\n",
      "Sorting gene pairs and guides based on ordering gene ordering...\n",
      "Starting scoring..\n",
      "calculating for replicate 0\n",
      "Filtered single sgRNA count: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:142: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'].isna()] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:143: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'] == 0] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating for replicate 1\n",
      "Filtered single sgRNA count: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:142: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'].isna()] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:143: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'] == 0] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------ADDING-TO-DB---------\n",
      "Processing table for: SGRA_DERIVED_NB_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 1275\n",
      "---------------------\n",
      "Working on cell line: A549\n",
      "Checking if score already computed: SGRA_DERIVED_NB_SCORE\n",
      "Running sgrna derived score...\n",
      "Getting raw counts...\n",
      "Filtering enabled... Condition: 35 counts\n",
      "Filtered a total of 445 out of 11934 sgRNAs.\n",
      "\n",
      "---\n",
      "\n",
      "Not full normalization...\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "A549_MV4_d3_1_S1_trimmed53_len_filtered_counts    318714.0\n",
      "A549_MV4_d3_2_S2_trimmed53_len_filtered_counts    366817.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 386171.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "A549_MV4_d28_1_S7_trimmed53_len_filtered_counts    405525.0\n",
      "A549_MV4_d28_2_S8_trimmed53_len_filtered_counts    416768.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 386171.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "A549_MV4_d3_1_S1_trimmed53_len_filtered_counts    6193814.0\n",
      "A549_MV4_d3_2_S2_trimmed53_len_filtered_counts    6832663.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 6314277.0 counts\n",
      "Normalization enabled...\n",
      "Current counts:\n",
      "A549_MV4_d28_1_S7_trimmed53_len_filtered_counts    6007062.0\n",
      "A549_MV4_d28_2_S8_trimmed53_len_filtered_counts    6434740.0\n",
      "dtype: float64\n",
      "Normalize based on a specific value... 6314277.0 counts\n",
      "Sorting gene pairs and guides based on ordering gene ordering...\n",
      "Starting scoring..\n",
      "calculating for replicate 0\n",
      "Filtered single sgRNA count: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:142: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'].isna()] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:143: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'] == 0] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating for replicate 1\n",
      "Filtered single sgRNA count: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:142: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'].isna()] = 1\n",
      "/tmp/slurmtmp.14811976/ipykernel_240588/351517165.py:143: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sgRNA_level_scores['SE'].loc[sgRNA_level_scores['SE'] == 0] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------ADDING-TO-DB---------\n",
      "Processing table for: SGRA_DERIVED_NB_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 1275\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "for curr_study in available_studies:\n",
    "    print('Working on study: ' + curr_study)\n",
    "\n",
    "    # get study counts and seq\n",
    "    study_counts = counts.loc[counts['study_origin'] == study_name_to_pubmed_id[curr_study]].copy()\n",
    "\n",
    "    curr_seq_ids = np.array(sorted(list(set(study_counts['guide_1_id'].tolist() + study_counts['guide_2_id'].tolist()))))\n",
    "    study_sequences = experiment_design.loc[curr_seq_ids]\n",
    "\n",
    "    # the analysis runs for each individual cell line\n",
    "    available_cell_lines = set(study_counts['cell_line_origin'])\n",
    "\n",
    "    for curr_cl in available_cell_lines:\n",
    "        print('Working on cell line: ' + curr_cl)\n",
    "        curr_counts = study_counts.loc[study_counts['cell_line_origin'] == curr_cl].copy()\n",
    "\n",
    "        # run sgRNA scores\n",
    "        if not check_if_added_to_table(curr_counts.copy(), 'SGRA_DERIVED_NB_SCORE', SLKB_engine):\n",
    "            sgRNA_res = run_sgrna_scores(curr_counts.copy(), full_normalization = False)\n",
    "            add_table_to_db(curr_counts.copy(), sgRNA_res['SGRA_DERIVED_NB_SCORE'], 'SGRA_DERIVED_NB_SCORE', SLKB_engine)\n",
    "            if sgRNA_res['SGRA_DERIVED_B_SCORE'] is not None:\n",
    "                add_table_to_db(curr_counts.copy(), sgRNA_res['SGRA_DERIVED_B_SCORE'], 'SGRA_DERIVED_B_SCORE', SLKB_engine)\n",
    "        else:\n",
    "            print('Skipping sgRNA score...')\n",
    "            \n",
    "        print('---------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "14d2df2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "horlbeck_processed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0c0014d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on study: diehl_data\n",
      "Working on cell line: RPE1\n",
      "Checking if score already computed: HORLBECK_SCORE\n",
      "Getting raw counts...\n",
      "Mismatch times, averaging...\n",
      "Sorting gene pairs and guides based on ordering gene ordering...\n",
      "For replicate 1\n",
      "Total of 0 sgRNAs were filtered out of 908\n",
      "Running horlbeck score...\n",
      "Running preprocessing...\n",
      "Started scoring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/1273021243.py:138: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  curr_counts['GI_Averaged'].iloc[i] = GI_Score_avg.loc[guide_1, guide_2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------ADDING-TO-DB---------\n",
      "Processing table for: HORLBECK_SCORE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/612781312.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  curr_results.drop(['Gene 1', 'Gene 2'], axis = 1, inplace = True, errors = 'ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 10720\n",
      "---------------------\n",
      "Working on study: horlbeck_data\n",
      "Working on cell line: JURKAT\n",
      "Checking if score already computed: HORLBECK_SCORE\n",
      "Checking if score already computed: HORLBECK_SCORE\n",
      "Getting raw counts...\n",
      "Sorting gene pairs and guides based on ordering gene ordering...\n",
      "For replicate 1\n",
      "Total of 188 sgRNAs were filtered out of 1022\n",
      "For replicate 2\n",
      "Total of 172 sgRNAs were filtered out of 1022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/python/3.9-2022.05/lib/python3.9/site-packages/pandas/core/groupby/ops.py:761: RuntimeWarning: Mean of empty slice\n",
      "  res = f(group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting raw counts...\n",
      "Sorting gene pairs and guides based on ordering gene ordering...\n",
      "For replicate 1\n",
      "Total of 149 sgRNAs were filtered out of 1022\n",
      "For replicate 2\n",
      "Total of 160 sgRNAs were filtered out of 1022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/python/3.9-2022.05/lib/python3.9/site-packages/pandas/core/groupby/ops.py:761: RuntimeWarning: Mean of empty slice\n",
      "  res = f(group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running horlbeck score...\n",
      "Running preprocessing...\n",
      "Started scoring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/1273021243.py:138: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  curr_counts['GI_Averaged'].iloc[i] = GI_Score_avg.loc[guide_1, guide_2]\n",
      "/users/PAS1376/bg12/.local/lib/python3.9/site-packages/numpy/core/_methods.py:261: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/users/PAS1376/bg12/.local/lib/python3.9/site-packages/numpy/core/_methods.py:253: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running horlbeck score...\n",
      "Running preprocessing...\n",
      "Started scoring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/1273021243.py:138: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  curr_counts['GI_Averaged'].iloc[i] = GI_Score_avg.loc[guide_1, guide_2]\n",
      "/users/PAS1376/bg12/.local/lib/python3.9/site-packages/numpy/core/_methods.py:261: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/users/PAS1376/bg12/.local/lib/python3.9/site-packages/numpy/core/_methods.py:253: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------ADDING-TO-DB---------\n",
      "Processing table for: HORLBECK_SCORE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/612781312.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  curr_results.drop(['Gene 1', 'Gene 2'], axis = 1, inplace = True, errors = 'ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 75078\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: HORLBECK_SCORE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/612781312.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  curr_results.drop(['Gene 1', 'Gene 2'], axis = 1, inplace = True, errors = 'ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 100128\n",
      "---------------------\n",
      "Working on cell line: K562\n",
      "---------------------\n",
      "Working on study: najm_data\n",
      "Working on cell line: HT29\n",
      "Checking if score already computed: HORLBECK_SCORE\n",
      "Running horlbeck score...\n",
      "Running preprocessing...\n",
      "Getting raw counts...\n",
      "Removing NA replicate from TEnd...\n",
      "Mismatch times, averaging...\n",
      "Sorting gene pairs and guides based on ordering gene ordering...\n",
      "For replicate 1\n",
      "Total of 6 sgRNAs were filtered out of 192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/python/3.9-2022.05/lib/python3.9/site-packages/pandas/core/groupby/ops.py:761: RuntimeWarning: Mean of empty slice\n",
      "  res = f(group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started scoring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/1273021243.py:138: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  curr_counts['GI_Averaged'].iloc[i] = GI_Score_avg.loc[guide_1, guide_2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------ADDING-TO-DB---------\n",
      "Processing table for: HORLBECK_SCORE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/612781312.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  curr_results.drop(['Gene 1', 'Gene 2'], axis = 1, inplace = True, errors = 'ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 300\n",
      "---------------------\n",
      "Working on cell line: A549\n",
      "Checking if score already computed: HORLBECK_SCORE\n",
      "Running horlbeck score...\n",
      "Running preprocessing...\n",
      "Getting raw counts...\n",
      "Removing NA replicate from TEnd...\n",
      "Mismatch times, averaging...\n",
      "Sorting gene pairs and guides based on ordering gene ordering...\n",
      "For replicate 1\n",
      "Total of 1 sgRNAs were filtered out of 192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/python/3.9-2022.05/lib/python3.9/site-packages/pandas/core/groupby/ops.py:761: RuntimeWarning: Mean of empty slice\n",
      "  res = f(group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started scoring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/1273021243.py:138: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  curr_counts['GI_Averaged'].iloc[i] = GI_Score_avg.loc[guide_1, guide_2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------ADDING-TO-DB---------\n",
      "Processing table for: HORLBECK_SCORE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/612781312.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  curr_results.drop(['Gene 1', 'Gene 2'], axis = 1, inplace = True, errors = 'ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 300\n",
      "---------------------\n",
      "Working on cell line: OVCAR8\n",
      "Checking if score already computed: HORLBECK_SCORE\n",
      "Running horlbeck score...\n",
      "Running preprocessing...\n",
      "Getting raw counts...\n",
      "Mismatch times, averaging...\n",
      "Sorting gene pairs and guides based on ordering gene ordering...\n",
      "For replicate 1\n",
      "Total of 2 sgRNAs were filtered out of 192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/python/3.9-2022.05/lib/python3.9/site-packages/pandas/core/groupby/ops.py:761: RuntimeWarning: Mean of empty slice\n",
      "  res = f(group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started scoring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/1273021243.py:138: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  curr_counts['GI_Averaged'].iloc[i] = GI_Score_avg.loc[guide_1, guide_2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------ADDING-TO-DB---------\n",
      "Processing table for: HORLBECK_SCORE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/612781312.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  curr_results.drop(['Gene 1', 'Gene 2'], axis = 1, inplace = True, errors = 'ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 300\n",
      "---------------------\n",
      "Working on cell line: A375\n",
      "Checking if score already computed: HORLBECK_SCORE\n",
      "Running horlbeck score...\n",
      "Running preprocessing...\n",
      "Getting raw counts...\n",
      "Mismatch times, averaging...\n",
      "Sorting gene pairs and guides based on ordering gene ordering...\n",
      "For replicate 1\n",
      "Total of 2 sgRNAs were filtered out of 192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/python/3.9-2022.05/lib/python3.9/site-packages/pandas/core/groupby/ops.py:761: RuntimeWarning: Mean of empty slice\n",
      "  res = f(group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started scoring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/1273021243.py:138: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  curr_counts['GI_Averaged'].iloc[i] = GI_Score_avg.loc[guide_1, guide_2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------ADDING-TO-DB---------\n",
      "Processing table for: HORLBECK_SCORE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/612781312.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  curr_results.drop(['Gene 1', 'Gene 2'], axis = 1, inplace = True, errors = 'ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 300\n",
      "---------------------\n",
      "Working on cell line: 786O\n",
      "Checking if score already computed: HORLBECK_SCORE\n",
      "Running horlbeck score...\n",
      "Running preprocessing...\n",
      "Getting raw counts...\n",
      "Mismatch times, averaging...\n",
      "Sorting gene pairs and guides based on ordering gene ordering...\n",
      "For replicate 1\n",
      "Total of 1 sgRNAs were filtered out of 192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/python/3.9-2022.05/lib/python3.9/site-packages/pandas/core/groupby/ops.py:761: RuntimeWarning: Mean of empty slice\n",
      "  res = f(group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started scoring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/1273021243.py:138: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  curr_counts['GI_Averaged'].iloc[i] = GI_Score_avg.loc[guide_1, guide_2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------ADDING-TO-DB---------\n",
      "Processing table for: HORLBECK_SCORE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/612781312.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  curr_results.drop(['Gene 1', 'Gene 2'], axis = 1, inplace = True, errors = 'ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 300\n",
      "---------------------\n",
      "Working on cell line: MELJUSO\n",
      "Checking if score already computed: HORLBECK_SCORE\n",
      "Running horlbeck score...\n",
      "Running preprocessing...\n",
      "Getting raw counts...\n",
      "Removing NA replicate from TEnd...\n",
      "Mismatch times, averaging...\n",
      "Sorting gene pairs and guides based on ordering gene ordering...\n",
      "For replicate 1\n",
      "Total of 1 sgRNAs were filtered out of 192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/python/3.9-2022.05/lib/python3.9/site-packages/pandas/core/groupby/ops.py:761: RuntimeWarning: Mean of empty slice\n",
      "  res = f(group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started scoring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/1273021243.py:138: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  curr_counts['GI_Averaged'].iloc[i] = GI_Score_avg.loc[guide_1, guide_2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------ADDING-TO-DB---------\n",
      "Processing table for: HORLBECK_SCORE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/612781312.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  curr_results.drop(['Gene 1', 'Gene 2'], axis = 1, inplace = True, errors = 'ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 300\n",
      "---------------------\n",
      "Working on study: parrish_data\n",
      "Working on cell line: HELA\n",
      "Checking if score already computed: HORLBECK_SCORE\n",
      "Running horlbeck score...\n",
      "Running preprocessing...\n",
      "Getting raw counts...\n",
      "Sorting gene pairs and guides based on ordering gene ordering...\n",
      "For replicate 1\n",
      "Total of 23 sgRNAs were filtered out of 9168\n",
      "For replicate 2\n",
      "Total of 29 sgRNAs were filtered out of 9168\n",
      "For replicate 3\n",
      "Total of 35 sgRNAs were filtered out of 9168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/python/3.9-2022.05/lib/python3.9/site-packages/pandas/core/groupby/ops.py:761: RuntimeWarning: Mean of empty slice\n",
      "  res = f(group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started scoring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/1273021243.py:138: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  curr_counts['GI_Averaged'].iloc[i] = GI_Score_avg.loc[guide_1, guide_2]\n",
      "/users/PAS1376/bg12/.local/lib/python3.9/site-packages/numpy/core/_methods.py:261: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/users/PAS1376/bg12/.local/lib/python3.9/site-packages/numpy/core/_methods.py:253: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------ADDING-TO-DB---------\n",
      "Processing table for: HORLBECK_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 1028\n",
      "---------------------\n",
      "Working on cell line: PC9\n",
      "Checking if score already computed: HORLBECK_SCORE\n",
      "Running horlbeck score...\n",
      "Running preprocessing...\n",
      "Getting raw counts...\n",
      "Sorting gene pairs and guides based on ordering gene ordering...\n",
      "For replicate 1\n",
      "Total of 1 sgRNAs were filtered out of 9190\n",
      "For replicate 2\n",
      "Total of 2 sgRNAs were filtered out of 9190\n",
      "For replicate 3\n",
      "Total of 6 sgRNAs were filtered out of 9190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/python/3.9-2022.05/lib/python3.9/site-packages/pandas/core/groupby/ops.py:761: RuntimeWarning: Mean of empty slice\n",
      "  res = f(group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started scoring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/1273021243.py:138: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  curr_counts['GI_Averaged'].iloc[i] = GI_Score_avg.loc[guide_1, guide_2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------ADDING-TO-DB---------\n",
      "Processing table for: HORLBECK_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 1030\n",
      "---------------------\n",
      "Working on study: shantang_data\n",
      "Working on cell line: 22RV1\n",
      "Checking if score already computed: HORLBECK_SCORE\n",
      "Running horlbeck score...\n",
      "Running preprocessing...\n",
      "Getting raw counts...\n",
      "Sorting gene pairs and guides based on ordering gene ordering...\n",
      "For replicate 1\n",
      "Total of 12 sgRNAs were filtered out of 222\n",
      "For replicate 2\n",
      "Total of 7 sgRNAs were filtered out of 222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/python/3.9-2022.05/lib/python3.9/site-packages/pandas/core/groupby/ops.py:761: RuntimeWarning: Mean of empty slice\n",
      "  res = f(group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started scoring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/1273021243.py:138: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  curr_counts['GI_Averaged'].iloc[i] = GI_Score_avg.loc[guide_1, guide_2]\n",
      "/users/PAS1376/bg12/.local/lib/python3.9/site-packages/numpy/core/_methods.py:261: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/users/PAS1376/bg12/.local/lib/python3.9/site-packages/numpy/core/_methods.py:253: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------ADDING-TO-DB---------\n",
      "Processing table for: HORLBECK_SCORE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/612781312.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  curr_results.drop(['Gene 1', 'Gene 2'], axis = 1, inplace = True, errors = 'ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 1225\n",
      "---------------------\n",
      "Working on study: wong_data\n",
      "Working on cell line: OVCAR8\n",
      "Checking if score already computed: HORLBECK_SCORE\n",
      "Running horlbeck score...\n",
      "Running preprocessing...\n",
      "Getting raw counts...\n",
      "Sorting gene pairs and guides based on ordering gene ordering...\n",
      "For replicate 1\n",
      "Total of 3 sgRNAs were filtered out of 153\n",
      "For replicate 2\n",
      "Total of 3 sgRNAs were filtered out of 153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/python/3.9-2022.05/lib/python3.9/site-packages/pandas/core/groupby/ops.py:761: RuntimeWarning: Mean of empty slice\n",
      "  res = f(group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started scoring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/1273021243.py:138: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  curr_counts['GI_Averaged'].iloc[i] = GI_Score_avg.loc[guide_1, guide_2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------ADDING-TO-DB---------\n",
      "Processing table for: HORLBECK_SCORE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/612781312.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  curr_results.drop(['Gene 1', 'Gene 2'], axis = 1, inplace = True, errors = 'ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 1225\n",
      "---------------------\n",
      "Working on study: zhao_data\n",
      "Working on cell line: HELA\n",
      "Checking if score already computed: HORLBECK_SCORE\n",
      "Running horlbeck score...\n",
      "Running preprocessing...\n",
      "Getting raw counts...\n",
      "Sorting gene pairs and guides based on ordering gene ordering...\n",
      "For replicate 1\n",
      "Total of 6 sgRNAs were filtered out of 156\n",
      "For replicate 2\n",
      "Total of 8 sgRNAs were filtered out of 156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/python/3.9-2022.05/lib/python3.9/site-packages/pandas/core/groupby/ops.py:761: RuntimeWarning: Mean of empty slice\n",
      "  res = f(group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started scoring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/1273021243.py:138: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  curr_counts['GI_Averaged'].iloc[i] = GI_Score_avg.loc[guide_1, guide_2]\n",
      "/users/PAS1376/bg12/.local/lib/python3.9/site-packages/numpy/core/_methods.py:261: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/users/PAS1376/bg12/.local/lib/python3.9/site-packages/numpy/core/_methods.py:253: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------ADDING-TO-DB---------\n",
      "Processing table for: HORLBECK_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 1275\n",
      "---------------------\n",
      "Working on cell line: A549\n",
      "Checking if score already computed: HORLBECK_SCORE\n",
      "Running horlbeck score...\n",
      "Running preprocessing...\n",
      "Getting raw counts...\n",
      "Sorting gene pairs and guides based on ordering gene ordering...\n",
      "For replicate 1\n",
      "Total of 3 sgRNAs were filtered out of 156\n",
      "For replicate 2\n",
      "Total of 2 sgRNAs were filtered out of 156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/python/3.9-2022.05/lib/python3.9/site-packages/pandas/core/groupby/ops.py:761: RuntimeWarning: Mean of empty slice\n",
      "  res = f(group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started scoring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.14811976/ipykernel_240588/1273021243.py:138: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  curr_counts['GI_Averaged'].iloc[i] = GI_Score_avg.loc[guide_1, guide_2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------ADDING-TO-DB---------\n",
      "Processing table for: HORLBECK_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 1275\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "for curr_study in available_studies:\n",
    "    print('Working on study: ' + curr_study)\n",
    "\n",
    "    # get study counts and seq\n",
    "    study_counts = counts.loc[counts['study_origin'] == study_name_to_pubmed_id[curr_study]].copy()\n",
    "\n",
    "    curr_seq_ids = np.array(sorted(list(set(study_counts['guide_1_id'].tolist() + study_counts['guide_2_id'].tolist()))))\n",
    "    study_sequences = experiment_design.loc[curr_seq_ids]\n",
    "\n",
    "    # the analysis runs for each individual cell line\n",
    "    available_cell_lines = set(study_counts['cell_line_origin'])\n",
    "\n",
    "    for curr_cl in available_cell_lines:\n",
    "        print('Working on cell line: ' + curr_cl)\n",
    "        curr_counts = study_counts.loc[study_counts['cell_line_origin'] == curr_cl].copy()\n",
    "        \n",
    "        # run horlbeck score\n",
    "        if curr_study == 'horlbeck_data' and (not horlbeck_processed):\n",
    "            # Horlbeck does additional filtering on JURKAT based on K562\n",
    "            JURKAT_counts = study_counts.loc[study_counts['cell_line_origin'] == 'JURKAT'].copy()\n",
    "            K562_counts = study_counts.loc[study_counts['cell_line_origin'] == 'K562'].copy()\n",
    "\n",
    "            if (not check_if_added_to_table(JURKAT_counts.copy(), 'HORLBECK_SCORE', SLKB_engine)) and (not check_if_added_to_table(K562_counts.copy(), 'HORLBECK_SCORE', SLKB_engine)):\n",
    "\n",
    "                # do the preprocessing\n",
    "                JURKAT_counts = run_horlbeck_preprocessing(JURKAT_counts, filterThreshold = 35, pseudocount = 10)\n",
    "                K562_counts = run_horlbeck_preprocessing(K562_counts, filterThreshold = 35, pseudocount = 10)\n",
    "\n",
    "                singles_JURKAT = JURKAT_counts.loc[JURKAT_counts['target_type'] == 'Single'].copy().dropna()\n",
    "                singles_K562 = K562_counts.loc[K562_counts['target_type'] == 'Single'].copy().dropna()\n",
    "\n",
    "                a_average_K562 = singles_K562[singles_K562['sgRNA_target_name_g2'] == \"CONTROL\"]\n",
    "                a_average_K562 = pd.DataFrame(a_average_K562.groupby('sgRNA_guide_name_g1')['FC_Averaged_abbaAveraged'].apply(np.mean))\n",
    "                a_average_K562.columns = [a_average_K562.columns[0] + '_K562']\n",
    "\n",
    "                a_average_JURKAT = singles_JURKAT[singles_JURKAT['sgRNA_target_name_g2'] == \"CONTROL\"]\n",
    "                a_average_JURKAT = pd.DataFrame(a_average_JURKAT.groupby('sgRNA_guide_name_g1')['FC_Averaged_abbaAveraged'].apply(np.mean))\n",
    "                a_average_JURKAT.columns = [a_average_JURKAT.columns[0] + '_JURKAT']\n",
    "\n",
    "                a_average_JURKAT = a_average_JURKAT.merge(a_average_K562, how = 'left', left_index = True, right_index = True)\n",
    "\n",
    "                filter_criteria = a_average_JURKAT.loc[((a_average_JURKAT['FC_Averaged_abbaAveraged_JURKAT'] > -0.025) & (a_average_JURKAT['FC_Averaged_abbaAveraged_K562'] < -0.05))]\n",
    "\n",
    "                additionally_filtered = list(filter_criteria.index)\n",
    "\n",
    "                to_be_dropped = JURKAT_counts['sgRNA_guide_name_g1'].isin(additionally_filtered) | JURKAT_counts['sgRNA_guide_name_g2'].isin(additionally_filtered)\n",
    "\n",
    "                # drop them\n",
    "                JURKAT_counts = JURKAT_counts.loc[~to_be_dropped, :]\n",
    "\n",
    "                # now, proceed to run horlbeck score\n",
    "                JURKAT_res = run_horlbeck_score(JURKAT_counts.copy(), do_preprocessing = False)\n",
    "                K562_res = run_horlbeck_score(K562_counts.copy(), do_preprocessing = False)\n",
    "\n",
    "                add_table_to_db(JURKAT_counts.copy(), JURKAT_res['HORLBECK_SCORE'], 'HORLBECK_SCORE', SLKB_engine)\n",
    "                add_table_to_db(K562_counts.copy(), K562_res['HORLBECK_SCORE'], 'HORLBECK_SCORE', SLKB_engine)\n",
    "\n",
    "                horlbeck_processed = True\n",
    "            else:\n",
    "                print('Skipping horlbeck score...horlbeck case')\n",
    "\n",
    "        elif curr_study == 'diehl_data':\n",
    "            if not check_if_added_to_table(curr_counts.copy(), 'HORLBECK_SCORE', SLKB_engine):\n",
    "                # very low counts, set the threshold to be 0\n",
    "                temp_counts = run_horlbeck_preprocessing(curr_counts.copy(), filterThreshold = 0, pseudocount = 10)\n",
    "                horlbeck_res = run_horlbeck_score(temp_counts.copy(), do_preprocessing = False)\n",
    "                add_table_to_db(curr_counts.copy(), horlbeck_res['HORLBECK_SCORE'], 'HORLBECK_SCORE', SLKB_engine)\n",
    "            else:\n",
    "                print('Skipping horlbeck score...')\n",
    "        else:\n",
    "            if curr_study != 'horlbeck_data':\n",
    "                if not check_if_added_to_table(curr_counts.copy(), 'HORLBECK_SCORE', SLKB_engine):\n",
    "                    horlbeck_res = run_horlbeck_score(curr_counts.copy(), do_preprocessing = True)\n",
    "                    add_table_to_db(curr_counts.copy(), horlbeck_res['HORLBECK_SCORE'], 'HORLBECK_SCORE', SLKB_engine)\n",
    "                else:\n",
    "                    print('Skipping horlbeck score...')\n",
    "                    \n",
    "        print('---------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "120d04a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on study: diehl_data\n",
      "Working on cell line: RPE1\n",
      "Checking if score already computed: MAGECK_SCORE\n",
      "Running mageck score...\n",
      "Getting raw counts...\n",
      "Scores exist!\n",
      "Loading computed results...\n",
      "Filtered gene count: 0\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: MAGECK_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 10720\n",
      "---------------------\n",
      "Working on study: horlbeck_data\n",
      "Working on cell line: JURKAT\n",
      "Checking if score already computed: MAGECK_SCORE\n",
      "Running mageck score...\n",
      "Getting raw counts...\n",
      "Scores exist!\n",
      "Loading computed results...\n",
      "Filtered gene count: 0\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: MAGECK_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 111156\n",
      "---------------------\n",
      "Working on cell line: K562\n",
      "Checking if score already computed: MAGECK_SCORE\n",
      "Running mageck score...\n",
      "Getting raw counts...\n",
      "Scores exist!\n",
      "Loading computed results...\n",
      "Filtered gene count: 0\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: MAGECK_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 111156\n",
      "---------------------\n",
      "Working on study: najm_data\n",
      "Working on cell line: HT29\n",
      "Checking if score already computed: MAGECK_SCORE\n",
      "Running mageck score...\n",
      "Getting raw counts...\n",
      "Removing NA replicate from TEnd...\n",
      "Scores exist!\n",
      "Loading computed results...\n",
      "Filtered gene count: 0\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: MAGECK_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 300\n",
      "---------------------\n",
      "Working on cell line: A549\n",
      "Checking if score already computed: MAGECK_SCORE\n",
      "Running mageck score...\n",
      "Getting raw counts...\n",
      "Removing NA replicate from TEnd...\n",
      "Scores exist!\n",
      "Loading computed results...\n",
      "Filtered gene count: 0\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: MAGECK_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 300\n",
      "---------------------\n",
      "Working on cell line: OVCAR8\n",
      "Checking if score already computed: MAGECK_SCORE\n",
      "Running mageck score...\n",
      "Getting raw counts...\n",
      "Scores exist!\n",
      "Loading computed results...\n",
      "Filtered gene count: 0\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: MAGECK_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 300\n",
      "---------------------\n",
      "Working on cell line: A375\n",
      "Checking if score already computed: MAGECK_SCORE\n",
      "Running mageck score...\n",
      "Getting raw counts...\n",
      "Scores exist!\n",
      "Loading computed results...\n",
      "Filtered gene count: 0\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: MAGECK_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 300\n",
      "---------------------\n",
      "Working on cell line: 786O\n",
      "Checking if score already computed: MAGECK_SCORE\n",
      "Running mageck score...\n",
      "Getting raw counts...\n",
      "Scores exist!\n",
      "Loading computed results...\n",
      "Filtered gene count: 0\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: MAGECK_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 300\n",
      "---------------------\n",
      "Working on cell line: MELJUSO\n",
      "Checking if score already computed: MAGECK_SCORE\n",
      "Running mageck score...\n",
      "Getting raw counts...\n",
      "Removing NA replicate from TEnd...\n",
      "Scores exist!\n",
      "Loading computed results...\n",
      "Filtered gene count: 0\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: MAGECK_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 300\n",
      "---------------------\n",
      "Working on study: parrish_data\n",
      "Working on cell line: HELA\n",
      "Checking if score already computed: MAGECK_SCORE\n",
      "Running mageck score...\n",
      "Getting raw counts...\n",
      "Scores exist!\n",
      "Loading computed results...\n",
      "Filtered gene count: 0\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: MAGECK_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 1030\n",
      "---------------------\n",
      "Working on cell line: PC9\n",
      "Checking if score already computed: MAGECK_SCORE\n",
      "Running mageck score...\n",
      "Getting raw counts...\n",
      "Scores exist!\n",
      "Loading computed results...\n",
      "Filtered gene count: 0\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: MAGECK_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 1030\n",
      "---------------------\n",
      "Working on study: shantang_data\n",
      "Working on cell line: 22RV1\n",
      "Checking if score already computed: MAGECK_SCORE\n",
      "Running mageck score...\n",
      "Getting raw counts...\n",
      "Scores exist!\n",
      "Loading computed results...\n",
      "Filtered gene count: 0\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: MAGECK_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 1225\n",
      "---------------------\n",
      "Working on study: wong_data\n",
      "Working on cell line: OVCAR8\n",
      "Checking if score already computed: MAGECK_SCORE\n",
      "Running mageck score...\n",
      "Getting raw counts...\n",
      "Scores exist!\n",
      "Loading computed results...\n",
      "Filtered gene count: 0\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: MAGECK_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 1225\n",
      "---------------------\n",
      "Working on study: zhao_data\n",
      "Working on cell line: HELA\n",
      "Checking if score already computed: MAGECK_SCORE\n",
      "Running mageck score...\n",
      "Getting raw counts...\n",
      "Scores exist!\n",
      "Loading computed results...\n",
      "Filtered gene count: 0\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: MAGECK_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 1275\n",
      "---------------------\n",
      "Working on cell line: A549\n",
      "Checking if score already computed: MAGECK_SCORE\n",
      "Running mageck score...\n",
      "Getting raw counts...\n",
      "Scores exist!\n",
      "Loading computed results...\n",
      "Filtered gene count: 0\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: MAGECK_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 1275\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "for curr_study in available_studies:\n",
    "    print('Working on study: ' + curr_study)\n",
    "\n",
    "    # get study counts and seq\n",
    "    study_counts = counts.loc[counts['study_origin'] == study_name_to_pubmed_id[curr_study]].copy()\n",
    "\n",
    "    curr_seq_ids = np.array(sorted(list(set(study_counts['guide_1_id'].tolist() + study_counts['guide_2_id'].tolist()))))\n",
    "    study_sequences = experiment_design.loc[curr_seq_ids]\n",
    "\n",
    "    # the analysis runs for each individual cell line\n",
    "    available_cell_lines = set(study_counts['cell_line_origin'])\n",
    "\n",
    "    for curr_cl in available_cell_lines:\n",
    "        print('Working on cell line: ' + curr_cl)\n",
    "        curr_counts = study_counts.loc[study_counts['cell_line_origin'] == curr_cl].copy()\n",
    "\n",
    "        # run MAGeCK\n",
    "        if not check_if_added_to_table(curr_counts.copy(), 'MAGECK_SCORE', SLKB_engine):\n",
    "            mageck_res = run_mageck_score(curr_counts.copy(), curr_study, curr_cl, save_dir = 'MAGECK_Files')\n",
    "            add_table_to_db(curr_counts.copy(), mageck_res['MAGECK_SCORE'], 'MAGECK_SCORE', SLKB_engine)\n",
    "        else:\n",
    "            print('Skipping MAGeCK score...')\n",
    "            \n",
    "        print('---------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "be795c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on study: diehl_data\n",
      "Working on cell line: RPE1\n",
      "Checking if score already computed: GEMINI_SCORE\n",
      "Running gemini score...\n",
      "Getting raw counts...\n",
      "Scores exist!\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: GEMINI_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 10720\n",
      "---------------------\n",
      "Working on study: horlbeck_data\n",
      "Working on cell line: JURKAT\n",
      "Checking if score already computed: GEMINI_SCORE\n",
      "Running gemini score...\n",
      "Getting raw counts...\n",
      "Scores exist!\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: GEMINI_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 111156\n",
      "---------------------\n",
      "Working on cell line: K562\n",
      "Checking if score already computed: GEMINI_SCORE\n",
      "Running gemini score...\n",
      "Getting raw counts...\n",
      "Scores exist!\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: GEMINI_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 111156\n",
      "---------------------\n",
      "Working on study: najm_data\n",
      "Working on cell line: HT29\n",
      "Checking if score already computed: GEMINI_SCORE\n",
      "Running gemini score...\n",
      "Getting raw counts...\n",
      "Removing NA replicate from TEnd...\n",
      "Scores exist!\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: GEMINI_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 300\n",
      "---------------------\n",
      "Working on cell line: A549\n",
      "Checking if score already computed: GEMINI_SCORE\n",
      "Running gemini score...\n",
      "Getting raw counts...\n",
      "Removing NA replicate from TEnd...\n",
      "Scores exist!\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: GEMINI_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 300\n",
      "---------------------\n",
      "Working on cell line: OVCAR8\n",
      "Checking if score already computed: GEMINI_SCORE\n",
      "Running gemini score...\n",
      "Getting raw counts...\n",
      "Scores exist!\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: GEMINI_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 300\n",
      "---------------------\n",
      "Working on cell line: A375\n",
      "Checking if score already computed: GEMINI_SCORE\n",
      "Running gemini score...\n",
      "Getting raw counts...\n",
      "Scores exist!\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: GEMINI_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 300\n",
      "---------------------\n",
      "Working on cell line: 786O\n",
      "Checking if score already computed: GEMINI_SCORE\n",
      "Running gemini score...\n",
      "Getting raw counts...\n",
      "Scores exist!\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: GEMINI_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 300\n",
      "---------------------\n",
      "Working on cell line: MELJUSO\n",
      "Checking if score already computed: GEMINI_SCORE\n",
      "Running gemini score...\n",
      "Getting raw counts...\n",
      "Removing NA replicate from TEnd...\n",
      "Scores exist!\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: GEMINI_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 300\n",
      "---------------------\n",
      "Working on study: parrish_data\n",
      "Working on cell line: HELA\n",
      "Checking if score already computed: GEMINI_SCORE\n",
      "Running gemini score...\n",
      "Getting raw counts...\n",
      "Scores exist!\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: GEMINI_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 1030\n",
      "---------------------\n",
      "Working on cell line: PC9\n",
      "Checking if score already computed: GEMINI_SCORE\n",
      "Running gemini score...\n",
      "Getting raw counts...\n",
      "Scores exist!\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: GEMINI_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 1030\n",
      "---------------------\n",
      "Working on study: shantang_data\n",
      "Working on cell line: 22RV1\n",
      "Checking if score already computed: GEMINI_SCORE\n",
      "Running gemini score...\n",
      "Getting raw counts...\n",
      "Scores exist!\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: GEMINI_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 1225\n",
      "---------------------\n",
      "Working on study: wong_data\n",
      "Working on cell line: OVCAR8\n",
      "Checking if score already computed: GEMINI_SCORE\n",
      "Running gemini score...\n",
      "Getting raw counts...\n",
      "Scores exist!\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: GEMINI_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 1225\n",
      "---------------------\n",
      "Working on study: zhao_data\n",
      "Working on cell line: HELA\n",
      "Checking if score already computed: GEMINI_SCORE\n",
      "Running gemini score...\n",
      "Getting raw counts...\n",
      "Scores exist!\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: GEMINI_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 1275\n",
      "---------------------\n",
      "Working on cell line: A549\n",
      "Checking if score already computed: GEMINI_SCORE\n",
      "Running gemini score...\n",
      "Getting raw counts...\n",
      "Scores exist!\n",
      "---------ADDING-TO-DB---------\n",
      "Processing table for: GEMINI_SCORE\n",
      "Beginning transaction...\n",
      "Successfully inserted!\n",
      "Added Record stats...\n",
      "Score insert: 1275\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "for curr_study in available_studies:\n",
    "    print('Working on study: ' + curr_study)\n",
    "\n",
    "    # get study counts and seq\n",
    "    study_counts = counts.loc[counts['study_origin'] == study_name_to_pubmed_id[curr_study]].copy()\n",
    "\n",
    "    curr_seq_ids = np.array(sorted(list(set(study_counts['guide_1_id'].tolist() + study_counts['guide_2_id'].tolist()))))\n",
    "    study_sequences = experiment_design.loc[curr_seq_ids]\n",
    "\n",
    "    # the analysis runs for each individual cell line\n",
    "    available_cell_lines = set(study_counts['cell_line_origin'])\n",
    "\n",
    "    for curr_cl in available_cell_lines:\n",
    "        print('Working on cell line: ' + curr_cl)\n",
    "        curr_counts = study_counts.loc[study_counts['cell_line_origin'] == curr_cl].copy()\n",
    "        \n",
    "        # run GEMINI\n",
    "        if not check_if_added_to_table(curr_counts.copy(), 'GEMINI_SCORE', SLKB_engine):\n",
    "            gemini_res = run_gemini_score(curr_counts.copy(), curr_study, curr_cl, save_dir = 'GEMINI_Files')\n",
    "            add_table_to_db(curr_counts.copy(), gemini_res['GEMINI_SCORE'], 'GEMINI_SCORE', SLKB_engine)\n",
    "        else:\n",
    "            print('Skipping GEMINI score...')\n",
    "            \n",
    "        print('---------------------')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (Conda 2022.05) [python/3.9-2022.05]",
   "language": "python",
   "name": "python39_202205"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
